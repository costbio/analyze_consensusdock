{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "794d62f7",
   "metadata": {},
   "source": [
    "# Consensus Docking Results Analysis\n",
    "\n",
    "This notebook analyzes large-scale consensus docking results to evaluate binding pose consistency and perform cluster-based selectivity analysis.\n",
    "\n",
    "## üöÄ Quick Start Guide\n",
    "\n",
    "**For most users:** Simply run cells 2-4 to load, filter, and start analysis immediately.\n",
    "\n",
    "**First-time users or data updates:** If you need to create/update the data files, run the optimized data preparation script:\n",
    "```bash\n",
    "python parse_prepare.py\n",
    "```\n",
    "This high-performance script uses multiprocessing to efficiently process millions of docking results in minutes instead of hours.\n",
    "\n",
    "## üìä Analysis Overview\n",
    "\n",
    "### Main Analysis Workflow\n",
    "1. **Data Loading** (Step 1) - Smart loading of existing data files\n",
    "2. **Cluster Integration** (Step 2) - Add cavity similarity information  \n",
    "3. **Tool Coverage Filtering** (Step 2.5) - **NEW:** Filter for complete tool coverage\n",
    "4. **Data Quality Check** (Step 3) - Dataset overview of filtered data\n",
    "5. **Tool Reliability Analysis** (Step 4) - Consensus analysis between tools\n",
    "6. **Cluster Analysis** - Binding site similarity and drug selectivity\n",
    "7. **Visualizations** - Comprehensive plots and insights\n",
    "\n",
    "### Key Outputs\n",
    "- **Fair tool comparisons** using only drug-target pairs with complete tool coverage\n",
    "- Pose consistency metrics across docking tools\n",
    "- Drug-target binding success rates\n",
    "- Cluster-based selectivity patterns\n",
    "- Tool agreement analysis\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754698f7",
   "metadata": {},
   "source": [
    "## üì• Step 1: Smart Data Loading\n",
    "\n",
    "This cell automatically detects and loads the best available data source. Run this first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fa8e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# üì• SMART DATA LOADING - START HERE\n",
    "# =============================================================================\n",
    "\n",
    "import os, re\n",
    "import polars as pl\n",
    "from pathlib import Path\n",
    "\n",
    "# Configuration\n",
    "PARQUET_FILE = \"combined_consensus_docking_results.parquet\"\n",
    "CSV_FILE = \"combined_consensus_docking_results.csv\"\n",
    "BASE_FOLDER = \"/media/onur/Elements/cavity_space_consensus_docking/2025_06_29_batch_dock/\"\n",
    "\n",
    "print(\"üîç Checking for existing data files...\")\n",
    "\n",
    "# Smart data loading: try parquet first, then CSV, then create from scratch\n",
    "combined_results = None\n",
    "\n",
    "if os.path.exists(os.path.join(BASE_FOLDER, PARQUET_FILE)):\n",
    "    print(f\"‚úÖ Found Parquet file: {PARQUET_FILE}\")\n",
    "    print(\"üìñ Loading data (this is the fastest option)...\")\n",
    "    combined_results = pl.read_parquet(os.path.join(BASE_FOLDER, PARQUET_FILE))\n",
    "    print(f\"   Shape: {combined_results.shape}\")\n",
    "    print(f\"   Memory: {combined_results.estimated_size() / (1024*1024):.1f} MB\")\n",
    "    print(\"‚úÖ Data loaded successfully!\")\n",
    "\n",
    "elif os.path.exists(os.path.join(BASE_FOLDER, CSV_FILE)):\n",
    "    print(f\"‚úÖ Found CSV file: {CSV_FILE}\")\n",
    "    print(\"üìñ Loading data (slower than Parquet but still good)...\")\n",
    "    combined_results = pl.read_csv(os.path.join(BASE_FOLDER, CSV_FILE))\n",
    "    print(f\"   Shape: {combined_results.shape}\")\n",
    "    print(f\"   Memory: {combined_results.estimated_size() / (1024*1024):.1f} MB\")\n",
    "    print(\"‚úÖ Data loaded successfully!\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå No preprocessed data files found!\")\n",
    "    print(f\"   Looking for: {PARQUET_FILE} or {CSV_FILE}\")\n",
    "    print(\"\\nÔøΩ To create the data files, run the optimized preparation script:\")\n",
    "    print(\"   ```bash\")\n",
    "    print(\"   python parse_prepare.py\")\n",
    "    print(\"   ```\")\n",
    "    print(\"\\n‚ö° This high-performance script features:\")\n",
    "    print(\"   ‚Ä¢ Multiprocessing across all CPU cores\")\n",
    "    print(\"   ‚Ä¢ Progress bars for visual feedback\")\n",
    "    print(\"   ‚Ä¢ Processing rate: ~25,000 records/second\")\n",
    "    print(\"   ‚Ä¢ Creates both CSV and Parquet formats\")\n",
    "    print(\"   ‚Ä¢ Typical runtime: 5-10 minutes for millions of records\")\n",
    "    combined_results = pl.DataFrame()  # Empty dataframe\n",
    "\n",
    "# Quick validation\n",
    "if not combined_results.is_empty():\n",
    "    print(f\"\\nüìä Dataset Overview:\")\n",
    "    print(f\"   Total rows: {combined_results.height:,}\")\n",
    "    print(f\"   Columns: {combined_results.width}\")\n",
    "    print(f\"   Key columns: {combined_results.columns}\")\n",
    "    \n",
    "    # Check for required columns\n",
    "    required_cols = ['drugbank_id', 'uniprot_id', 'RMSD', 'Score1', 'Score2']\n",
    "    missing_cols = [col for col in required_cols if col not in combined_results.columns]\n",
    "    if missing_cols:\n",
    "        print(f\"‚ö†Ô∏è  Missing columns: {missing_cols}\")\n",
    "    else:\n",
    "        print(\"‚úÖ All required columns present\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  No data available for analysis\")\n",
    "    print(\"   Please run: python parse_prepare.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febc9474",
   "metadata": {},
   "source": [
    "## üß¨ Step 2: Cluster Integration\n",
    "\n",
    "Add cavity cluster information for advanced analysis (run once per session)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582dcac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# üóÉÔ∏è STEP 2: CAVITY CLUSTER INTEGRATION\n",
    "# =============================================================================\n",
    "\n",
    "print(\"üóÉÔ∏è CAVITY CLUSTER INTEGRATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if not combined_results.is_empty():\n",
    "    # Check if we already have cluster information\n",
    "    if 'cavity_cluster_id' in combined_results.columns:\n",
    "        non_null_clusters = combined_results['cavity_cluster_id'].drop_nulls().len()\n",
    "        if non_null_clusters > 0:\n",
    "            print(f\"‚úÖ Cluster data already present: {non_null_clusters:,} mapped entries\")\n",
    "            print(\"   Skipping cluster integration...\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è  Cluster column exists but empty - proceeding with integration...\")\n",
    "    \n",
    "    # Proceed with cluster integration if needed\n",
    "    if 'cavity_cluster_id' not in combined_results.columns or combined_results['cavity_cluster_id'].drop_nulls().len() == 0:\n",
    "        try:\n",
    "            print(f\"üìñ Loading cavity cluster data...\")\n",
    "            cluster_file = \"/opt/data/cavity_space/cavity_cluster_similarity07.csv\"\n",
    "            clusters_df = pl.read_csv(cluster_file, separator='\\t')\n",
    "            print(f\"üìñ Loaded {clusters_df.height:,} clusters from CavitySpace\")\n",
    "            \n",
    "            # Extract uniprot_id and cavity_index from source_dir if not already present\n",
    "            print(f\"ÔøΩ Extracting cavity identifiers from source paths...\")\n",
    "            \n",
    "            combined_results = combined_results.with_columns([\n",
    "                # Extract drugbank_id (1st component before first underscore)\n",
    "                pl.col('source_dir').str.split('/').list.last()\n",
    "                .str.extract(r'(DB\\d+)_', group_index=1)\n",
    "                .alias('extracted_drugbank_id'),\n",
    "                \n",
    "                # Extract gene_name (2nd component - can be 'nan' for negative samples)\n",
    "                # Pattern: DB00035_AVPR1B_P47901_cavity_1 (positive) or DB00035_nan_P08173_cavity_3 (negative)\n",
    "                pl.col('source_dir').str.split('/').list.last()\n",
    "                .str.extract(r'DB\\d+_([A-Z0-9]+|nan)_', group_index=1)\n",
    "                .alias('extracted_gene_name'),\n",
    "                \n",
    "                # Extract uniprot_id (component before 'cavity_')\n",
    "                # More flexible pattern to handle both positive and negative samples\n",
    "                pl.col('source_dir').str.split('/').list.last()\n",
    "                .str.extract(r'_([A-Z0-9]+)_cavity_\\d+', group_index=1)\n",
    "                .alias('extracted_uniprot_id'),\n",
    "                \n",
    "                # Extract cavity_index (number after 'cavity_')\n",
    "                pl.col('source_dir').str.split('/').list.last()\n",
    "                .str.extract(r'cavity_(\\d+)', group_index=1)\n",
    "                .cast(pl.Int64, strict=False)\n",
    "                .alias('extracted_cavity_index')\n",
    "            ])\n",
    "            \n",
    "            # Check extraction results\n",
    "            non_null_uniprot = combined_results['extracted_uniprot_id'].drop_nulls().len()\n",
    "            non_null_cavity = combined_results['extracted_cavity_index'].drop_nulls().len()\n",
    "            \n",
    "            print(f\"‚úÖ Extraction results:\")\n",
    "            print(f\"   Extracted uniprot_id: {non_null_uniprot:,} non-null values\")\n",
    "            print(f\"   Extracted cavity_index: {non_null_cavity:,} non-null values\")\n",
    "            \n",
    "            # Show sample extracted data for debugging\n",
    "            sample_data = combined_results.select(['source_dir', 'extracted_uniprot_id', 'extracted_cavity_index']).head(3)\n",
    "            print(f\"   Sample extracted data:\")\n",
    "            print(sample_data)\n",
    "            \n",
    "            if non_null_uniprot > 0 and non_null_cavity > 0:\n",
    "                # Create mapping dictionary from the cluster file\n",
    "                cavity_to_cluster = {}\n",
    "                successful_parses = 0\n",
    "                failed_parses = 0\n",
    "                \n",
    "                print(f\"üîÑ Processing cluster file to create mapping...\")\n",
    "                \n",
    "                for i, row in enumerate(clusters_df.to_dicts()):\n",
    "                    cluster_id = row['id']  # The cluster ID\n",
    "                    cavity_items = row['items']  # Comma-separated cavity IDs\n",
    "                    \n",
    "                    # Split the cavity items and process each one\n",
    "                    if cavity_items and isinstance(cavity_items, str):\n",
    "                        cavity_ids = cavity_items.split(',')\n",
    "                        \n",
    "                        for cavity_id in cavity_ids:\n",
    "                            cavity_id = cavity_id.strip()\n",
    "                            \n",
    "                            # Parse cavity format: AF-{UniProtID}-F{Fragment}-model_v1_C{CavityIndex}\n",
    "                            match = re.match(r'AF-([A-Z0-9]+)-F\\d+-model_v1_C(\\d+)', cavity_id)\n",
    "                            if match:\n",
    "                                uniprot_id, cavity_index = match.groups()\n",
    "                                key = (uniprot_id, int(cavity_index))\n",
    "                                cavity_to_cluster[key] = cluster_id\n",
    "                                successful_parses += 1\n",
    "                            else:\n",
    "                                failed_parses += 1\n",
    "                                if failed_parses <= 5:  # Show first few failures\n",
    "                                    print(f\"   ‚ö†Ô∏è Failed to parse cavity ID: '{cavity_id}'\")\n",
    "                \n",
    "                print(f\"üìä Cluster parsing results:\")\n",
    "                print(f\"   Successfully parsed: {successful_parses:,} cavity IDs\")\n",
    "                print(f\"   Failed to parse: {failed_parses:,} cavity IDs\")\n",
    "                print(f\"   Created mapping for {len(cavity_to_cluster):,} unique cavities\")\n",
    "                \n",
    "                # Show sample mapping entries\n",
    "                sample_keys = list(cavity_to_cluster.keys())[:5]\n",
    "                print(f\"   Sample mappings:\")\n",
    "                for key in sample_keys:\n",
    "                    print(f\"     {key} -> cluster {cavity_to_cluster[key]}\")\n",
    "                \n",
    "                # Check what UniProt IDs we have in our data vs cluster file\n",
    "                our_uniprots = set(combined_results.filter(pl.col('extracted_uniprot_id').is_not_null())['extracted_uniprot_id'].unique().to_list())\n",
    "                cluster_uniprots = set(key[0] for key in cavity_to_cluster.keys())\n",
    "                \n",
    "                print(f\"\\nüîç UniProt ID overlap analysis:\")\n",
    "                print(f\"   UniProts in our data: {len(our_uniprots):,}\")\n",
    "                print(f\"   UniProts in cluster file: {len(cluster_uniprots):,}\")\n",
    "                print(f\"   Overlap: {len(our_uniprots & cluster_uniprots):,}\")\n",
    "                \n",
    "                # Show sample UniProts from each set\n",
    "                print(f\"   Sample from our data: {sorted(list(our_uniprots))[:5]}\")\n",
    "                print(f\"   Sample from clusters: {sorted(list(cluster_uniprots))[:5]}\")\n",
    "                \n",
    "                # Map clusters to our data\n",
    "                def map_cluster(uniprot_id, cavity_index):\n",
    "                    if cavity_index is None or uniprot_id is None:\n",
    "                        return None\n",
    "                    key = (uniprot_id, cavity_index)\n",
    "                    return cavity_to_cluster.get(key)\n",
    "                \n",
    "                print(f\"\\nüîÑ Applying cluster mapping...\")\n",
    "                \n",
    "                combined_results = combined_results.with_columns([\n",
    "                    pl.struct(['extracted_uniprot_id', 'extracted_cavity_index'])\n",
    "                    .map_elements(lambda x: map_cluster(x['extracted_uniprot_id'], x['extracted_cavity_index']), return_dtype=pl.Int64)\n",
    "                    .alias('cavity_cluster_id')\n",
    "                ])\n",
    "                \n",
    "                # Report mapping results\n",
    "                mapped_count = combined_results['cavity_cluster_id'].drop_nulls().len()\n",
    "                total_count = len(combined_results)\n",
    "                unique_clusters = combined_results['cavity_cluster_id'].n_unique()\n",
    "                \n",
    "                print(f\"‚úÖ Cluster mapping complete:\")\n",
    "                print(f\"   Mapped: {mapped_count:,}/{total_count:,} ({mapped_count/total_count*100:.1f}%)\")\n",
    "                print(f\"   Unique clusters: {unique_clusters:,}\")\n",
    "                \n",
    "                if mapped_count > 0:\n",
    "                    # Show sample mapped data\n",
    "                    sample_mapped = combined_results.filter(pl.col('cavity_cluster_id').is_not_null()).select(['extracted_uniprot_id', 'extracted_cavity_index', 'cavity_cluster_id']).head(3)\n",
    "                    print(f\"   Sample mapped data:\")\n",
    "                    print(sample_mapped)\n",
    "                    \n",
    "                # Debug unmapped entries\n",
    "                if mapped_count < total_count:\n",
    "                    print(f\"\\nüîç Debugging unmapped entries:\")\n",
    "                    unmapped = combined_results.filter(pl.col('cavity_cluster_id').is_null())\n",
    "                    sample_unmapped = unmapped.select(['extracted_uniprot_id', 'extracted_cavity_index']).head(5)\n",
    "                    print(f\"   Sample unmapped entries:\")\n",
    "                    print(sample_unmapped)\n",
    "                    \n",
    "                    # Check if these should have mappings\n",
    "                    for row in sample_unmapped.to_dicts():\n",
    "                        uniprot_id = row['extracted_uniprot_id']\n",
    "                        cavity_index = row['extracted_cavity_index']\n",
    "                        key = (uniprot_id, cavity_index)\n",
    "                        if key in cavity_to_cluster:\n",
    "                            print(f\"   ‚ùó Key {key} should map to cluster {cavity_to_cluster[key]} but doesn't!\")\n",
    "                        else:\n",
    "                            print(f\"   ‚úì Key {key} correctly not in cluster mapping\")\n",
    "                \n",
    "            else:\n",
    "                print(\"‚ùå Extraction failed - adding empty cluster column...\")\n",
    "                combined_results = combined_results.with_columns([\n",
    "                    pl.lit(None, dtype=pl.Int64).alias('cavity_cluster_id')\n",
    "                ])\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            print(f\"‚ö†Ô∏è  Cluster file not found: {cluster_file}\")\n",
    "            print(\"   Adding empty cluster column...\")\n",
    "            combined_results = combined_results.with_columns([\n",
    "                pl.lit(None, dtype=pl.Int64).alias('cavity_cluster_id')\n",
    "            ])\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading clusters: {e}\")\n",
    "            print(f\"   Error details: {type(e).__name__}: {str(e)}\")\n",
    "            combined_results = combined_results.with_columns([\n",
    "                pl.lit(None, dtype=pl.Int64).alias('cavity_cluster_id')\n",
    "            ])\n",
    "    \n",
    "    print(f\"üéØ Ready for analysis with shape: {combined_results.shape}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No data available for cluster integration\")\n",
    "    print(\"   Please load data first (Step 1)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c96afb0",
   "metadata": {},
   "source": [
    "## üè∑Ô∏è Step 2.5: Sample Type Annotation (Positive vs Negative)\n",
    "\n",
    "**Critical Context:** The docking results include both:\n",
    "- **Positive samples**: Known drug-target interactions from validated databases\n",
    "- **Negative samples**: Randomly generated drug-target pairs (controls) to test specificity\n",
    "\n",
    "This annotation is essential for proper evaluation:\n",
    "- It enables us to assess how well docking tools distinguish true interactions from random pairings\n",
    "- All subsequent analyses must account for sample type to avoid conflating signal with noise\n",
    "- Performance metrics (ROC, precision-recall) require this ground truth labeling\n",
    "\n",
    "We'll load sample type information from `required_structures_with_negatives.csv` and merge it into our dataset based on UniProt ID, DrugBank ID, and cavity index.\n",
    "\n",
    "**‚ö†Ô∏è Important:** This step must be run BEFORE Step 2.6 (filtering) to enable balanced sample filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdaef57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# üè∑Ô∏è SAMPLE TYPE ANNOTATION (POSITIVE VS NEGATIVE)\n",
    "# =============================================================================\n",
    "\n",
    "if not combined_results.is_empty():\n",
    "    print(\"üè∑Ô∏è Starting sample type annotation...\")\n",
    "    \n",
    "    # Load the sample type metadata\n",
    "    sample_metadata_file = \"/media/onur/Elements/cavity_space_consensus_docking/2025_06_29_batch_dock/required_structures_with_negatives.csv\"\n",
    "    \n",
    "    try:\n",
    "        print(f\"üìñ Loading sample type metadata from:\\n   {sample_metadata_file}\")\n",
    "        \n",
    "        # Load the metadata file\n",
    "        sample_metadata = pl.read_csv(sample_metadata_file)\n",
    "        \n",
    "        print(f\"‚úÖ Loaded {sample_metadata.height:,} rows from metadata file\")\n",
    "        print(f\"   Columns: {sample_metadata.columns}\")\n",
    "        \n",
    "        # Show sample of metadata\n",
    "        print(f\"\\nüìã Sample metadata (positive samples):\")\n",
    "        print(sample_metadata.filter(pl.col('sample_type') == 'positive').head(3))\n",
    "        print(f\"\\nüìã Sample metadata (negative samples):\")\n",
    "        print(sample_metadata.filter(pl.col('sample_type').str.contains('negative')).head(3))\n",
    "        \n",
    "        # Check sample type distribution in metadata\n",
    "        sample_type_counts = sample_metadata.group_by('sample_type').agg(pl.len()).sort('sample_type')\n",
    "        print(f\"\\nüìä Sample type distribution in metadata:\")\n",
    "        print(sample_type_counts)\n",
    "        \n",
    "        # Prepare metadata for merging - select relevant columns\n",
    "        # Note: The metadata uses 'UniProt_ID' and 'Cavity_Index', while combined_results uses 'uniprot_id' and 'extracted_cavity_index'\n",
    "        merge_metadata = sample_metadata.select([\n",
    "            pl.col('UniProt_ID').alias('uniprot_id'),\n",
    "            'drugbank_id',\n",
    "            pl.col('Cavity_Index').alias('cavity_index'),\n",
    "            'sample_type',\n",
    "            'Gene_Name'  # Keep this for additional context\n",
    "        ])\n",
    "        \n",
    "        print(f\"\\nüîÑ Merging sample type information...\")\n",
    "        print(f\"   Merge keys: uniprot_id, drugbank_id, cavity_index\")\n",
    "        \n",
    "        # Check if we have the required columns in combined_results\n",
    "        if 'extracted_cavity_index' in combined_results.columns:\n",
    "            # Use extracted_cavity_index for merging\n",
    "            combined_results = combined_results.with_columns([\n",
    "                pl.col('extracted_cavity_index').alias('cavity_index')\n",
    "            ])\n",
    "        elif 'cavity_index' not in combined_results.columns:\n",
    "            print(\"‚ö†Ô∏è  Warning: No cavity_index column found in combined_results!\")\n",
    "            print(\"   This may affect merge accuracy.\")\n",
    "        \n",
    "        # Before merge - check data availability\n",
    "        pre_merge_rows = combined_results.height\n",
    "        unique_pairs_in_data = combined_results.select(['uniprot_id', 'drugbank_id', 'cavity_index']).unique().height\n",
    "        unique_pairs_in_metadata = merge_metadata.select(['uniprot_id', 'drugbank_id', 'cavity_index']).unique().height\n",
    "        \n",
    "        print(f\"\\nüìä Pre-merge statistics:\")\n",
    "        print(f\"   Combined_results rows: {pre_merge_rows:,}\")\n",
    "        print(f\"   Unique (uniprot, drug, cavity) in data: {unique_pairs_in_data:,}\")\n",
    "        print(f\"   Unique (uniprot, drug, cavity) in metadata: {unique_pairs_in_metadata:,}\")\n",
    "        \n",
    "        # Perform left join to add sample_type to combined_results\n",
    "        combined_results = combined_results.join(\n",
    "            merge_metadata,\n",
    "            on=['uniprot_id', 'drugbank_id', 'cavity_index'],\n",
    "            how='left'\n",
    "        )\n",
    "        \n",
    "        # Check merge results\n",
    "        post_merge_rows = combined_results.height\n",
    "        annotated_rows = combined_results.filter(pl.col('sample_type').is_not_null()).height\n",
    "        \n",
    "        print(f\"\\n‚úÖ Merge completed:\")\n",
    "        print(f\"   Rows after merge: {post_merge_rows:,}\")\n",
    "        print(f\"   Rows with sample_type: {annotated_rows:,} ({annotated_rows/post_merge_rows*100:.1f}%)\")\n",
    "        \n",
    "        if annotated_rows < post_merge_rows:\n",
    "            unannotated_rows = post_merge_rows - annotated_rows\n",
    "            print(f\"   ‚ö†Ô∏è  Unannotated rows: {unannotated_rows:,} ({unannotated_rows/post_merge_rows*100:.1f}%)\")\n",
    "            \n",
    "            # Show sample of unannotated data for debugging\n",
    "            print(f\"\\nüìã Sample unannotated data (first 3 rows):\")\n",
    "            sample_unmapped = combined_results.filter(pl.col('sample_type').is_null()).select([\n",
    "                'uniprot_id', 'drugbank_id', 'cavity_index', 'source_dir'\n",
    "            ]).head(3)\n",
    "            print(sample_unmapped)\n",
    "        \n",
    "        # Show sample type distribution in annotated data\n",
    "        if annotated_rows > 0:\n",
    "            annotated_type_counts = combined_results.filter(\n",
    "                pl.col('sample_type').is_not_null()\n",
    "            ).group_by('sample_type').agg(pl.len()).sort('sample_type')\n",
    "            \n",
    "            print(f\"\\nüìä Sample type distribution in annotated docking results:\")\n",
    "            print(annotated_type_counts)\n",
    "            \n",
    "            # Show sample of annotated data\n",
    "            print(f\"\\nüìã Sample annotated data (positive):\")\n",
    "            sample_mapped = combined_results.filter(\n",
    "                pl.col('sample_type') == 'positive'\n",
    "            ).select(['uniprot_id', 'drugbank_id', 'cavity_index', 'sample_type', 'Gene_Name']).head(3)\n",
    "            print(sample_mapped)\n",
    "            \n",
    "            print(f\"\\nüìã Sample annotated data (negative):\")\n",
    "            sample_mapped = combined_results.filter(\n",
    "                pl.col('sample_type').str.contains('negative')\n",
    "            ).select(['uniprot_id', 'drugbank_id', 'cavity_index', 'sample_type', 'Gene_Name']).head(3)\n",
    "            print(sample_mapped)\n",
    "        \n",
    "        print(f\"\\n‚úÖ Sample type annotation complete!\")\n",
    "        print(f\"   Dataset now includes 'sample_type' column for positive/negative discrimination\")\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ùå Error: Could not find sample metadata file:\")\n",
    "        print(f\"   {sample_metadata_file}\")\n",
    "        print(f\"   Sample type annotation skipped.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error during sample type annotation: {e}\")\n",
    "        print(f\"   Sample type annotation skipped.\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå No data available for sample type annotation\")\n",
    "    print(\"   Please load data first (Step 1 & 2)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b04beb6",
   "metadata": {},
   "source": [
    "## üîç Step 2.6: Filter for Complete Tool Coverage and Balanced Samples\n",
    "\n",
    "**Important Filtering Criteria:**\n",
    "\n",
    "1. **Complete Tool Coverage**: Only include drug-target pairs where **ALL THREE tools** (Gold, Smina, LeDock) made predictions. This eliminates bias from partial tool coverage.\n",
    "\n",
    "2. **Balanced Sample Types**: For each drug, ensure equal representation of positive and negative samples:\n",
    "   - Filter out drugs that have only positive OR only negative samples\n",
    "   - Keep only drugs with both sample types present\n",
    "   - Balance the counts to have equal numbers of positive and negative samples per drug\n",
    "\n",
    "**Prerequisites:** \n",
    "- Step 2.5 (Sample Type Annotation) must be completed first\n",
    "- The `sample_type` column must be present in the dataset\n",
    "\n",
    "These filtering steps ensure fair comparison between tools and valid positive vs negative sample discrimination analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a80403b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# üîç FILTER FOR COMPLETE TOOL COVERAGE AND BALANCED SAMPLES\n",
    "# =============================================================================\n",
    "\n",
    "if not combined_results.is_empty():\n",
    "    print(\"üîç Starting filtering process...\")\n",
    "    print(\"   Criteria: (1) Complete tool coverage, (2) Balanced positive/negative samples\")\n",
    "    \n",
    "    # STEP 1: Filter for final_results source_type only\n",
    "    print(\"\\nüìã Step 1: Filtering for final_results source_type...\")\n",
    "    original_rows = combined_results.height\n",
    "    \n",
    "    if 'source_type' in combined_results.columns:\n",
    "        # Check what source_type values we have\n",
    "        source_types = combined_results['source_type'].unique().to_list()\n",
    "        print(f\"   Available source_types: {source_types}\")\n",
    "        \n",
    "        # Filter for final_results only\n",
    "        combined_results = combined_results.filter(pl.col('source_type') == 'final_results')\n",
    "        filtered_rows = combined_results.height\n",
    "        \n",
    "        print(f\"   Original rows: {original_rows:,}\")\n",
    "        print(f\"   After final_results filter: {filtered_rows:,} ({filtered_rows/original_rows*100:.1f}%)\")\n",
    "    else:\n",
    "        print(\"   ‚ö†Ô∏è No source_type column found, skipping source_type filtering\")\n",
    "    \n",
    "    # STEP 2: Analyze tool coverage\n",
    "    print(\"\\nüìã Step 2: Analyzing tool coverage...\")\n",
    "    \n",
    "    if 'Tool1' in combined_results.columns and 'Tool2' in combined_results.columns:\n",
    "        # Filter out null values from tool lists\n",
    "        tool1_list = combined_results.filter(pl.col('Tool1').is_not_null())['Tool1'].unique().to_list()\n",
    "        tool2_list = combined_results.filter(pl.col('Tool2').is_not_null())['Tool2'].unique().to_list()\n",
    "        \n",
    "        # Combine and sort, excluding any None values\n",
    "        all_tools = tool1_list + tool2_list\n",
    "        all_detected_tools = sorted([tool for tool in set(all_tools) if tool is not None])\n",
    "        \n",
    "        print(f\"   All detected tools: {all_detected_tools}\")\n",
    "        \n",
    "        # Define the three main tools we expect\n",
    "        expected_tools = ['GOLD', 'Smina', 'LeDock']\n",
    "        available_expected_tools = [tool for tool in expected_tools if tool in all_detected_tools]\n",
    "        \n",
    "        print(f\"   Expected tools found: {available_expected_tools}\")\n",
    "        \n",
    "        if len(available_expected_tools) >= 2:  # Need at least 2 tools for comparison\n",
    "            print(f\"\\nüìä Step 3: Checking tool coverage per drug-target pair...\")\n",
    "            \n",
    "            # Group by drug-target pairs and check tool coverage\n",
    "            drug_target_groups = combined_results.group_by(['drugbank_id', 'uniprot_id'])\n",
    "            \n",
    "            complete_coverage_pairs = []\n",
    "            coverage_summary = []\n",
    "            \n",
    "            for group_key, group_data in drug_target_groups:\n",
    "                drug = group_key[0]\n",
    "                target = group_key[1]\n",
    "                \n",
    "                # Get unique tools that made predictions for this drug-target pair\n",
    "                tools_t1 = group_data.filter(pl.col('Tool1').is_not_null())['Tool1'].unique().to_list()\n",
    "                tools_t2 = group_data.filter(pl.col('Tool2').is_not_null())['Tool2'].unique().to_list()\n",
    "                tools_in_group = set(tools_t1 + tools_t2)\n",
    "                tools_present = [tool for tool in available_expected_tools if tool in tools_in_group]\n",
    "                \n",
    "                coverage_summary.append({\n",
    "                    'drug': drug,\n",
    "                    'target': target,\n",
    "                    'tools_present': tools_present,\n",
    "                    'n_tools': len(tools_present),\n",
    "                    'complete_coverage': len(tools_present) == len(available_expected_tools),\n",
    "                    'original_rows': group_data.height\n",
    "                })\n",
    "                \n",
    "                # If all expected tools are present, keep this drug-target pair\n",
    "                if len(tools_present) == len(available_expected_tools):\n",
    "                    complete_coverage_pairs.append((drug, target))\n",
    "            \n",
    "            # STEP 3: Filter for complete coverage pairs\n",
    "            if complete_coverage_pairs:\n",
    "                print(f\"   Found {len(complete_coverage_pairs):,} pairs with complete tool coverage\")\n",
    "                \n",
    "                # Create filter for complete coverage pairs using Polars syntax\n",
    "                complete_filter = pl.lit(False)  # Start with False\n",
    "                \n",
    "                for drug, target in complete_coverage_pairs:\n",
    "                    pair_filter = (pl.col('drugbank_id') == drug) & (pl.col('uniprot_id') == target)\n",
    "                    complete_filter = complete_filter | pair_filter\n",
    "                \n",
    "                # Apply the filter\n",
    "                combined_results = combined_results.filter(complete_filter)\n",
    "                final_rows = combined_results.height\n",
    "                \n",
    "                # Report filtering results\n",
    "                original_pairs = len(coverage_summary)\n",
    "                complete_pairs = len(complete_coverage_pairs)\n",
    "                \n",
    "                print(f\"\\nüìà FILTERING RESULTS:\")\n",
    "                print(\"=\" * 40)\n",
    "                print(f\"üìä Original drug-target pairs: {original_pairs:,}\")\n",
    "                print(f\"‚úÖ Complete coverage pairs: {complete_pairs:,} ({complete_pairs/original_pairs*100:.1f}%)\")\n",
    "                print(f\"üìã After source_type filter: {filtered_rows:,}\")\n",
    "                print(f\"üîÑ Final filtered data: {final_rows:,} ({final_rows/filtered_rows*100:.1f}%)\")\n",
    "                \n",
    "                # Tool coverage distribution\n",
    "                coverage_dist = {}\n",
    "                for item in coverage_summary:\n",
    "                    n_tools = item['n_tools']\n",
    "                    coverage_dist[n_tools] = coverage_dist.get(n_tools, 0) + 1\n",
    "                \n",
    "                print(f\"\\nüéØ TOOL COVERAGE DISTRIBUTION:\")\n",
    "                for n_tools in sorted(coverage_dist.keys(), reverse=True):\n",
    "                    count = coverage_dist[n_tools]\n",
    "                    pct = count / original_pairs * 100\n",
    "                    print(f\"   {n_tools} tools: {count:,} pairs ({pct:.1f}%)\")\n",
    "                \n",
    "                print(f\"\\n‚úÖ Dataset filtered for fair tool comparison\")\n",
    "                print(f\"   Only using drug-target pairs where ALL {len(available_expected_tools)} expected tools made predictions\")\n",
    "                \n",
    "                # STEP 4: Filter for balanced positive/negative samples per drug\n",
    "                print(f\"\\nüìã Step 4: Filtering for balanced positive/negative samples...\")\n",
    "                \n",
    "                if 'sample_type' in combined_results.columns:\n",
    "                    # Check if we have sample type information\n",
    "                    sample_type_counts = combined_results.filter(\n",
    "                        pl.col('sample_type').is_not_null()\n",
    "                    ).group_by('sample_type').agg(pl.len()).sort('sample_type')\n",
    "                    \n",
    "                    print(f\"   Sample type distribution before balancing:\")\n",
    "                    for row in sample_type_counts.iter_rows(named=True):\n",
    "                        print(f\"      {row['sample_type']}: {row['len']:,}\")\n",
    "                    \n",
    "                    # Identify positive and negative sample types\n",
    "                    has_positive = combined_results.filter(\n",
    "                        pl.col('sample_type') == 'positive'\n",
    "                    ).height > 0\n",
    "                    \n",
    "                    has_negative = combined_results.filter(\n",
    "                        pl.col('sample_type').str.contains('negative')\n",
    "                    ).height > 0\n",
    "                    \n",
    "                    if has_positive and has_negative:\n",
    "                        print(f\"   ‚úÖ Both positive and negative samples found\")\n",
    "                        \n",
    "                        # Group by drug and count positive/negative samples\n",
    "                        # We'll count unique (drug, target, cavity) combinations per sample type\n",
    "                        drug_sample_counts = combined_results.filter(\n",
    "                            pl.col('sample_type').is_not_null()\n",
    "                        ).group_by(['drugbank_id', 'sample_type']).agg([\n",
    "                            pl.col('uniprot_id').n_unique().alias('n_targets'),\n",
    "                            pl.col('cavity_index').n_unique().alias('n_cavities'),\n",
    "                            pl.len().alias('n_records')\n",
    "                        ])\n",
    "                        \n",
    "                        # For each drug, check if it has both positive and negative samples\n",
    "                        drugs_with_both = {}\n",
    "                        \n",
    "                        for drug in combined_results['drugbank_id'].unique().to_list():\n",
    "                            drug_samples = drug_sample_counts.filter(\n",
    "                                pl.col('drugbank_id') == drug\n",
    "                            )\n",
    "                            \n",
    "                            pos_count = drug_samples.filter(\n",
    "                                pl.col('sample_type') == 'positive'\n",
    "                            )\n",
    "                            neg_count = drug_samples.filter(\n",
    "                                pl.col('sample_type').str.contains('negative')\n",
    "                            )\n",
    "                            \n",
    "                            has_pos = pos_count.height > 0\n",
    "                            has_neg = neg_count.height > 0\n",
    "                            \n",
    "                            if has_pos and has_neg:\n",
    "                                # Get the counts of unique (target, cavity) combinations\n",
    "                                n_pos = pos_count.select('n_records').sum().item() if has_pos else 0\n",
    "                                n_neg = neg_count.select('n_records').sum().item() if has_neg else 0\n",
    "                                \n",
    "                                drugs_with_both[drug] = {\n",
    "                                    'n_positive': n_pos,\n",
    "                                    'n_negative': n_neg,\n",
    "                                    'min_count': min(n_pos, n_neg)\n",
    "                                }\n",
    "                        \n",
    "                        print(f\"   Drugs with both sample types: {len(drugs_with_both):,}\")\n",
    "                        print(f\"   Drugs filtered out (only one sample type): {combined_results['drugbank_id'].n_unique() - len(drugs_with_both):,}\")\n",
    "                        \n",
    "                        if len(drugs_with_both) > 0:\n",
    "                            # Filter for drugs with both sample types\n",
    "                            valid_drugs = list(drugs_with_both.keys())\n",
    "                            combined_results = combined_results.filter(\n",
    "                                pl.col('drugbank_id').is_in(valid_drugs)\n",
    "                            )\n",
    "                            \n",
    "                            after_drug_filter = combined_results.height\n",
    "                            print(f\"   Rows after drug filtering: {after_drug_filter:,}\")\n",
    "                            \n",
    "                            # Now balance the samples for each drug\n",
    "                            print(f\"\\n   Balancing positive/negative samples for each drug...\")\n",
    "                            \n",
    "                            balanced_chunks = []\n",
    "                            total_pos_kept = 0\n",
    "                            total_neg_kept = 0\n",
    "                            \n",
    "                            for drug, counts in drugs_with_both.items():\n",
    "                                min_count = counts['min_count']\n",
    "                                \n",
    "                                # Get positive samples for this drug\n",
    "                                pos_samples = combined_results.filter(\n",
    "                                    (pl.col('drugbank_id') == drug) &\n",
    "                                    (pl.col('sample_type') == 'positive')\n",
    "                                )\n",
    "                                \n",
    "                                # Get negative samples for this drug\n",
    "                                neg_samples = combined_results.filter(\n",
    "                                    (pl.col('drugbank_id') == drug) &\n",
    "                                    (pl.col('sample_type').str.contains('negative'))\n",
    "                                )\n",
    "                                \n",
    "                                # Take equal number from each (limited by minimum)\n",
    "                                if pos_samples.height > min_count:\n",
    "                                    pos_samples = pos_samples.sample(n=min_count, seed=42)\n",
    "                                if neg_samples.height > min_count:\n",
    "                                    neg_samples = neg_samples.sample(n=min_count, seed=42)\n",
    "                                \n",
    "                                balanced_chunks.append(pos_samples)\n",
    "                                balanced_chunks.append(neg_samples)\n",
    "                                \n",
    "                                total_pos_kept += pos_samples.height\n",
    "                                total_neg_kept += neg_samples.height\n",
    "                            \n",
    "                            # Combine balanced chunks\n",
    "                            if balanced_chunks:\n",
    "                                combined_results = pl.concat(balanced_chunks, how='vertical')\n",
    "                                balanced_rows = combined_results.height\n",
    "                                \n",
    "                                print(f\"   ‚úÖ Balanced sampling complete:\")\n",
    "                                print(f\"      Positive samples kept: {total_pos_kept:,}\")\n",
    "                                print(f\"      Negative samples kept: {total_neg_kept:,}\")\n",
    "                                print(f\"      Total rows: {balanced_rows:,}\")\n",
    "                                print(f\"      Balance ratio: {total_pos_kept/total_neg_kept:.3f}\" if total_neg_kept > 0 else \"      Balance ratio: N/A\")\n",
    "                                \n",
    "                                # Verify final balance\n",
    "                                final_sample_counts = combined_results.group_by('sample_type').agg(pl.len()).sort('sample_type')\n",
    "                                print(f\"\\n   üìä Final sample type distribution:\")\n",
    "                                for row in final_sample_counts.iter_rows(named=True):\n",
    "                                    print(f\"      {row['sample_type']}: {row['len']:,}\")\n",
    "                            else:\n",
    "                                print(f\"   ‚ö†Ô∏è No balanced data could be created\")\n",
    "                        else:\n",
    "                            print(f\"   ‚ö†Ô∏è No drugs have both positive and negative samples\")\n",
    "                            print(f\"      Skipping balanced sampling\")\n",
    "                    elif has_positive:\n",
    "                        print(f\"   ‚ö†Ô∏è Only positive samples found - cannot balance\")\n",
    "                    elif has_negative:\n",
    "                        print(f\"   ‚ö†Ô∏è Only negative samples found - cannot balance\")\n",
    "                    else:\n",
    "                        print(f\"   ‚ö†Ô∏è No valid sample type information found\")\n",
    "                else:\n",
    "                    print(f\"   ‚ö†Ô∏è No sample_type column found - skipping balanced sampling\")\n",
    "                    print(f\"      Run sample type annotation (Step 2.6) first for balanced sampling\")\n",
    "                \n",
    "            else:\n",
    "                print(\"‚ùå No drug-target pairs have complete tool coverage!\")\n",
    "                print(\"   Cannot proceed with fair comparison analysis\")\n",
    "        else:\n",
    "            print(f\"‚ùå Not enough tools found ({len(available_expected_tools)} < 2)\")\n",
    "    else:\n",
    "        print(\"‚ùå Tool1 or Tool2 columns not found\")\n",
    "        \n",
    "    print(f\"\\nüéØ Ready for analysis with shape: {combined_results.shape}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No data available for filtering\")\n",
    "    print(\"   Please load data first (Step 1)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf873fd4",
   "metadata": {},
   "source": [
    "## üìä Step 3: Data Overview & Quality Check\n",
    "\n",
    "Get familiar with the **filtered** dataset structure and check data quality. This step now analyzes the data after filtering for complete tool coverage, ensuring all statistics reflect the dataset used for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc109b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# üìä STEP 3: DATA OVERVIEW & QUALITY CHECK\n",
    "# =============================================================================\n",
    "\n",
    "if not combined_results.is_empty():\n",
    "    print(\"üîç DATASET OVERVIEW\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"üìä Shape: {combined_results.shape} (rows √ó columns)\")\n",
    "    print(f\"üíæ Memory: {combined_results.estimated_size() / (1024*1024):.1f} MB\")\n",
    "    print(f\"üìã Columns: {combined_results.width}\")\n",
    "    \n",
    "    print(f\"\\nüìö Column Names:\")\n",
    "    for i, col in enumerate(combined_results.columns, 1):\n",
    "        print(f\"  {i:2d}. {col}\")\n",
    "    \n",
    "    print(f\"\\nüß¨ KEY DATASET STATISTICS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Core identifiers\n",
    "    print(f\"üî¨ Unique Drug-Target Combinations: {combined_results.select(['drugbank_id', 'uniprot_id']).unique().height:,}\")\n",
    "    print(f\"üíä Unique Drugs (DrugBank IDs): {combined_results['drugbank_id'].n_unique():,}\")\n",
    "    print(f\"üß¨ Unique Proteins (UniProt IDs): {combined_results['uniprot_id'].n_unique():,}\")\n",
    "    \n",
    "    # Check for cavity index information\n",
    "    if 'extracted_cavity_index' in combined_results.columns:\n",
    "        print(f\"üï≥Ô∏è  Unique Cavities: {combined_results['extracted_cavity_index'].n_unique():,}\")\n",
    "    elif 'cavity_index' in combined_results.columns:\n",
    "        print(f\"üï≥Ô∏è  Unique Cavities: {combined_results['cavity_index'].n_unique():,}\")\n",
    "    else:\n",
    "        print(\"üï≥Ô∏è  Cavity information: Not available\")\n",
    "    \n",
    "    # Cluster information\n",
    "    if 'cavity_cluster_id' in combined_results.columns:\n",
    "        cluster_mapped = combined_results['cavity_cluster_id'].drop_nulls().len()\n",
    "        cluster_total = combined_results.height\n",
    "        unique_clusters = combined_results['cavity_cluster_id'].n_unique()\n",
    "        print(f\"üß© Cavity Clusters: {unique_clusters:,} unique clusters\")\n",
    "        print(f\"   Mapped: {cluster_mapped:,}/{cluster_total:,} ({cluster_mapped/cluster_total*100:.1f}%)\")\n",
    "    \n",
    "    # Check for essential analysis columns\n",
    "    print(f\"\\nüîç DATA QUALITY ASSESSMENT\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Check for RMSD columns\n",
    "    rmsd_columns = [col for col in combined_results.columns if 'rmsd' in col.lower()]\n",
    "    if rmsd_columns:\n",
    "        rmsd_col = rmsd_columns[0]\n",
    "        print(f\"‚úÖ RMSD data available: {rmsd_col}\")\n",
    "        \n",
    "        # RMSD statistics\n",
    "        rmsd_stats = combined_results.select([\n",
    "            pl.col(rmsd_col).min().alias('min_rmsd'),\n",
    "            pl.col(rmsd_col).max().alias('max_rmsd'),\n",
    "            pl.col(rmsd_col).mean().alias('mean_rmsd'),\n",
    "            pl.col(rmsd_col).median().alias('median_rmsd'),\n",
    "            (pl.col(rmsd_col) < 2.0).mean().alias('good_poses_pct')\n",
    "        ]).to_pandas().iloc[0]\n",
    "        \n",
    "        print(f\"   Range: {rmsd_stats['min_rmsd']:.2f} - {rmsd_stats['max_rmsd']:.2f} √Ö\")\n",
    "        print(f\"   Mean: {rmsd_stats['mean_rmsd']:.2f} √Ö, Median: {rmsd_stats['median_rmsd']:.2f} √Ö\")\n",
    "        print(f\"   Good poses (RMSD < 2.0 √Ö): {rmsd_stats['good_poses_pct']*100:.1f}%\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  No RMSD columns found - pose consistency analysis may be limited\")\n",
    "    \n",
    "    # Check for score columns\n",
    "    score_columns = [col for col in combined_results.columns if 'score' in col.lower()]\n",
    "    print(f\"‚úÖ Score columns available: {len(score_columns)}\")\n",
    "    for col in score_columns[:5]:  # Show first 5 score columns\n",
    "        print(f\"   - {col}\")\n",
    "    if len(score_columns) > 5:\n",
    "        print(f\"   ... and {len(score_columns) - 5} more\")\n",
    "    \n",
    "    # Tool information\n",
    "    if 'Tool1' in combined_results.columns and 'Tool2' in combined_results.columns:\n",
    "        tool1_unique = combined_results.filter(pl.col('Tool1').is_not_null())['Tool1'].n_unique()\n",
    "        tool2_unique = combined_results.filter(pl.col('Tool2').is_not_null())['Tool2'].n_unique()\n",
    "        print(f\"üîß Tool1 variants: {tool1_unique}\")\n",
    "        print(f\"üîß Tool2 variants: {tool2_unique}\")\n",
    "    \n",
    "    # Source information\n",
    "    if 'source_type' in combined_results.columns:\n",
    "        source_types = combined_results['source_type'].value_counts().to_pandas()\n",
    "        print(f\"üìÅ Source types:\")\n",
    "        for _, row in source_types.iterrows():\n",
    "            print(f\"   - {row['source_type']}: {row['count']:,} rows\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Dataset quality check complete\")\n",
    "    print(f\"üéØ Ready for consensus analysis!\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No data available for overview\")\n",
    "    print(\"   Please load and filter data first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76502af3",
   "metadata": {},
   "source": [
    "## Research Question 1 - Tool Reliability & Consensus Analysis\n",
    "\n",
    "**Research Question 1:** *How reliable is consensus between different docking tools?*\n",
    "\n",
    "This analysis addresses one of the most fundamental questions in computational drug discovery: **When can we trust docking predictions?** \n",
    "\n",
    "**Note:** All analysis now uses the filtered dataset with complete tool coverage, ensuring fair comparisons between tools.\n",
    "\n",
    "### üéØ Analysis Goals:\n",
    "1. **Quantify agreement** between different docking tools (Gold, Smina, LeDock)\n",
    "2. **Identify tool pairs** that show the best/worst consensus\n",
    "3. **Understand when** docking predictions are most trustworthy\n",
    "4. **Establish quality thresholds** for reliable predictions\n",
    "\n",
    "### üìä Key Metrics:\n",
    "- **RMSD between tools** - Lower values indicate better pose agreement\n",
    "- **Tool agreement frequency** - How often tools produce similar results\n",
    "- **Score-RMSD correlation** - Relationship between structural and scoring agreement\n",
    "\n",
    "### üìà Main Visualization:\n",
    "- **Tool Agreement Distribution Plot** - Comprehensive analysis combining RMSD distributions and score patterns\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c346720d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# üõ†Ô∏è SETUP: Import Libraries and Prepare Data for Tool Reliability Analysis\n",
    "# =============================================================================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "from scipy import stats\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"üìö Libraries imported successfully!\")\n",
    "\n",
    "# Check data availability for tool reliability analysis\n",
    "if not combined_results.is_empty():\n",
    "    print(f\"\\nüîç CHECKING FILTERED DATA SUITABILITY FOR TOOL RELIABILITY ANALYSIS\")\n",
    "    print(\"=\" * 70)\n",
    "    print(\"üìã NOTE: Analysis uses filtered data with complete tool coverage\")\n",
    "    \n",
    "    # Check for required columns\n",
    "    required_columns = ['Tool1', 'Tool2', 'Score1', 'Score2', 'RMSD']\n",
    "    available_columns = [col for col in required_columns if col in combined_results.columns]\n",
    "    missing_columns = [col for col in required_columns if col not in combined_results.columns]\n",
    "    \n",
    "    print(f\"‚úÖ Available columns: {available_columns}\")\n",
    "    if missing_columns:\n",
    "        print(f\"‚ö†Ô∏è  Missing columns: {missing_columns}\")\n",
    "        print(\"   Analysis will be adapted based on available data\")\n",
    "    \n",
    "    # Check tool information\n",
    "    if 'Tool1' in combined_results.columns and 'Tool2' in combined_results.columns:\n",
    "        tool1_types = combined_results['Tool1'].unique().to_list()\n",
    "        tool2_types = combined_results['Tool2'].unique().to_list()\n",
    "        all_tools = list(set(tool1_types + tool2_types))\n",
    "        \n",
    "        print(f\"\\nüîß Detected docking tools: {all_tools}\")\n",
    "        print(f\"   Tool1 variants: {tool1_types}\")\n",
    "        print(f\"   Tool2 variants: {tool2_types}\")\n",
    "        \n",
    "        # Check for RMSD data\n",
    "        if 'RMSD' in combined_results.columns:\n",
    "            rmsd_stats = combined_results.select([\n",
    "                pl.col('RMSD').count().alias('total_comparisons'),\n",
    "                pl.col('RMSD').mean().alias('mean_rmsd'),\n",
    "                pl.col('RMSD').std().alias('std_rmsd'),\n",
    "                pl.col('RMSD').min().alias('min_rmsd'),\n",
    "                pl.col('RMSD').max().alias('max_rmsd')\n",
    "            ]).to_pandas().iloc[0]\n",
    "            \n",
    "            print(f\"\\nüìê RMSD Statistics (Tool Agreement Metric):\")\n",
    "            print(f\"   Total pairwise comparisons: {rmsd_stats['total_comparisons']:,}\")\n",
    "            print(f\"   Mean RMSD: {rmsd_stats['mean_rmsd']:.2f} ¬± {rmsd_stats['std_rmsd']:.2f} √Ö\")\n",
    "            print(f\"   Range: {rmsd_stats['min_rmsd']:.2f} - {rmsd_stats['max_rmsd']:.2f} √Ö\")\n",
    "            \n",
    "            # Calculate agreement categories\n",
    "            excellent_agreement = combined_results.filter(pl.col('RMSD') <= 1.0).height\n",
    "            good_agreement = combined_results.filter((pl.col('RMSD') > 1.0) & (pl.col('RMSD') <= 2.0)).height\n",
    "            poor_agreement = combined_results.filter(pl.col('RMSD') > 2.0).height\n",
    "            total_comparisons = combined_results.height\n",
    "            \n",
    "            print(f\"\\nüéØ Tool Agreement Categories:\")\n",
    "            print(f\"   Excellent (RMSD ‚â§ 1.0 √Ö): {excellent_agreement:,} ({excellent_agreement/total_comparisons*100:.1f}%)\")\n",
    "            print(f\"   Good (1.0 < RMSD ‚â§ 2.0 √Ö): {good_agreement:,} ({good_agreement/total_comparisons*100:.1f}%)\")\n",
    "            print(f\"   Poor (RMSD > 2.0 √Ö): {poor_agreement:,} ({poor_agreement/total_comparisons*100:.1f}%)\")\n",
    "            \n",
    "            print(f\"\\n‚úÖ Filtered data is suitable for tool reliability analysis!\")\n",
    "        else:\n",
    "            print(f\"\\n‚ö†Ô∏è  No RMSD data available - analysis will be limited to score comparisons\")\n",
    "    else:\n",
    "        print(f\"\\n‚ùå Missing tool information - cannot perform tool reliability analysis\")\n",
    "        print(\"   Please ensure the dataset contains Tool1 and Tool2 columns\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå No data available for analysis\")\n",
    "    print(\"   Please run Steps 1-3 first to load, filter, and prepare the data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fff2a9",
   "metadata": {},
   "source": [
    "### üìä Tool Agreement & Score Distribution Analysis\n",
    "\n",
    "**Purpose:** Comprehensive analysis of tool agreement and scoring behavior addressing Research Question 1.\n",
    "\n",
    "**Layout Structure:**\n",
    "1. **Top Plot:** RMSD distribution violin plots showing tool agreement quality\n",
    "2. **Three Ridge Plots:** One subplot per tool (GOLD, LeDock, Smina) showing score distributions across tool pairs and RMSD ranges\n",
    "\n",
    "**Analysis Logic:**\n",
    "- **Best Agreement Focus:** For each drug-target pair, only the cavity/pose with the lowest RMSD between tools is considered\n",
    "- **Unique Tool Pairs:** Avoids counting A-B and B-A as separate comparisons\n",
    "- **Tool-Specific Scoring:** Each tool's scores are analyzed separately (never mixed) since each has its own scoring function\n",
    "\n",
    "**Ridge Plot Features:**\n",
    "- **Color-blind friendly palette:** Orange (GOLD), Sky Blue (LeDock), Bluish Green (Smina)\n",
    "- **RMSD Stratification:** Scores grouped by Good (<2√Ö), Medium (2-5√Ö), Poor (>5√Ö) RMSD ranges\n",
    "- **Fixed Scales:** GOLD (0-100), LeDock/Smina (-12 to 5) for consistent comparison\n",
    "- **Clean Design:** No annotations for cleaner, poster-ready appearance\n",
    "\n",
    "**Scientific Rationale:**\n",
    "- **No Score Mixing:** GOLD, Smina, and LeDock each use different scoring functions, so their scores should never be directly compared or combined\n",
    "- **Tool-Specific Insights:** Shows how each tool's scoring function relates to structural agreement quality\n",
    "- **Fair Comparison:** Enables assessment of whether good/poor RMSD agreement corresponds to favorable/unfavorable scores for each individual tool\n",
    "\n",
    "**Interpretation:**\n",
    "- **Agreement Quality:** Lower, narrower RMSD distributions indicate better and more consistent tool agreement\n",
    "- **Score-Quality Relationship:** For each tool, check if good RMSD ranges show more favorable scores than poor ranges\n",
    "- **Tool Behavior:** Compare how different tools' scoring functions relate to structural agreement\n",
    "\n",
    "**Poster-Ready Features:** Color-blind friendly palette, clear borders, proper axis labels with units, and optimized layout for maximum presentation impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb67f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# üìä PLOT 1A: TOOL AGREEMENT DISTRIBUTION ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "if not combined_results.is_empty() and 'RMSD' in combined_results.columns and 'Tool1' in combined_results.columns and 'Tool2' in combined_results.columns:\n",
    "    \n",
    "    print(\"üî• Generating Tool Agreement Distribution Analysis...\")\n",
    "    \n",
    "    # Set up poster-quality plotting parameters\n",
    "    plt.rcParams.update({\n",
    "        'figure.figsize': (16, 20),      # Vertical layout - taller figure\n",
    "        'font.size': 18,                 # Even larger base font size\n",
    "        'axes.titlesize': 22,            # Even larger title font\n",
    "        'axes.labelsize': 20,            # Even larger axis labels\n",
    "        'xtick.labelsize': 16,           # Even larger tick labels\n",
    "        'ytick.labelsize': 16,           # Even larger tick labels\n",
    "        'legend.fontsize': 16,           # Even larger legend font\n",
    "        'figure.titlesize': 26           # Even larger figure title\n",
    "    })\n",
    "    \n",
    "    # Convert to pandas for easier manipulation\n",
    "    df = combined_results.to_pandas()\n",
    "    \n",
    "    # Get all unique tools\n",
    "    all_tools = sorted(list(set(df['Tool1'].unique().tolist() + df['Tool2'].unique().tolist())))\n",
    "    print(f\"üîß Detected tools: {all_tools}\")\n",
    "    \n",
    "    # Check for score columns\n",
    "    score_columns = [col for col in df.columns if any(x in col.lower() for x in ['score', 'energy', 'affinity'])]\n",
    "    print(f\"üìä Available scoring columns: {score_columns}\")\n",
    "    \n",
    "    # Collect RMSD distributions and scores for unique tool pairs\n",
    "    print(\"üìä Computing tool agreement distributions using lowest RMSD per drug-target pair...\")\n",
    "    \n",
    "    tool_pair_data = []\n",
    "    \n",
    "    # Only consider unique pairs (avoid duplicates like A-B and B-A)\n",
    "    from itertools import combinations\n",
    "    unique_tool_pairs = list(combinations(all_tools, 2))\n",
    "    \n",
    "    for tool1, tool2 in unique_tool_pairs:\n",
    "        # Find all comparisons between these two tools (both directions)\n",
    "        mask1 = (df['Tool1'] == tool1) & (df['Tool2'] == tool2)\n",
    "        mask2 = (df['Tool1'] == tool2) & (df['Tool2'] == tool1)\n",
    "        \n",
    "        if mask1.any() or mask2.any():\n",
    "            # We need to track which tool is which for score assignment\n",
    "            # Include score information and tool identity\n",
    "            columns_to_include = ['drugbank_id', 'uniprot_id', 'cavity_index', 'RMSD', 'Tool1', 'Tool2'] + score_columns[:2]\n",
    "            \n",
    "            # Separate the two directions to maintain tool identity\n",
    "            comparisons_direction1 = df.loc[mask1, columns_to_include].copy() if mask1.any() else pd.DataFrame()\n",
    "            comparisons_direction2 = df.loc[mask2, columns_to_include].copy() if mask2.any() else pd.DataFrame()\n",
    "            \n",
    "            # For direction 2, we need to swap the tools and scores to maintain consistency\n",
    "            if not comparisons_direction2.empty:\n",
    "                # Create a copy and swap Tool1/Tool2 and Score1/Score2\n",
    "                comparisons_direction2_swapped = comparisons_direction2.copy()\n",
    "                comparisons_direction2_swapped['Tool1'], comparisons_direction2_swapped['Tool2'] = comparisons_direction2['Tool2'], comparisons_direction2['Tool1']\n",
    "                if 'Score1' in comparisons_direction2_swapped.columns and 'Score2' in comparisons_direction2_swapped.columns:\n",
    "                    comparisons_direction2_swapped['Score1'], comparisons_direction2_swapped['Score2'] = comparisons_direction2['Score2'], comparisons_direction2['Score1']\n",
    "                comparisons_direction2 = comparisons_direction2_swapped\n",
    "            \n",
    "            # Combine both directions\n",
    "            if not comparisons_direction1.empty and not comparisons_direction2.empty:\n",
    "                comparisons = pd.concat([comparisons_direction1, comparisons_direction2])\n",
    "            elif not comparisons_direction1.empty:\n",
    "                comparisons = comparisons_direction1\n",
    "            elif not comparisons_direction2.empty:\n",
    "                comparisons = comparisons_direction2\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "            # Group by unique drug-target combinations and get the lowest RMSD for each\n",
    "            grouped = comparisons.groupby(['drugbank_id', 'uniprot_id'])\n",
    "            \n",
    "            best_agreements = []\n",
    "            for (drug, target), group in grouped:\n",
    "                best_idx = group['RMSD'].idxmin()\n",
    "                best_row = group.loc[best_idx]\n",
    "                \n",
    "                agreement_data = {\n",
    "                    'drug': drug,\n",
    "                    'target': target,\n",
    "                    'rmsd': best_row['RMSD'],\n",
    "                    'tool1_name': best_row['Tool1'],  # This should be tool1\n",
    "                    'tool2_name': best_row['Tool2'],  # This should be tool2\n",
    "                }\n",
    "                \n",
    "                # Add scores for each tool\n",
    "                if 'Score1' in best_row and pd.notna(best_row['Score1']):\n",
    "                    agreement_data['tool1_score'] = best_row['Score1']  # Score for tool1\n",
    "                if 'Score2' in best_row and pd.notna(best_row['Score2']):\n",
    "                    agreement_data['tool2_score'] = best_row['Score2']  # Score for tool2\n",
    "                \n",
    "                best_agreements.append(agreement_data)\n",
    "            \n",
    "            if len(best_agreements) > 0:\n",
    "                rmsds = [item['rmsd'] for item in best_agreements]\n",
    "                \n",
    "                tool_pair_data.append({\n",
    "                    'tool_pair': f\"{tool1} vs {tool2}\",\n",
    "                    'tool1': tool1,\n",
    "                    'tool2': tool2,\n",
    "                    'rmsds': np.array(rmsds),\n",
    "                    'agreements': best_agreements,\n",
    "                    'n_pairs': len(best_agreements),\n",
    "                    'mean_rmsd': np.mean(rmsds),\n",
    "                    'median_rmsd': np.median(rmsds),\n",
    "                    'std_rmsd': np.std(rmsds)\n",
    "                })\n",
    "                print(f\"   {tool1} vs {tool2}: {len(best_agreements):,} unique drug-target pairs, Mean: {np.mean(rmsds):.2f} √Ö\")\n",
    "    \n",
    "    if tool_pair_data:\n",
    "        # Create main figure with custom layout: top plot + 3 horizontal ridge plots\n",
    "        fig = plt.figure(figsize=(15, 25))\n",
    "        gs = fig.add_gridspec(2, 3, height_ratios=[1, 1.5], hspace=0.3, wspace=0.3)\n",
    "        \n",
    "        # ========================================================================\n",
    "        # PLOT 1: RMSD Distribution Violin Plots (Top - spans all columns)\n",
    "        # ========================================================================\n",
    "        ax_rmsd = fig.add_subplot(gs[0, :])\n",
    "        \n",
    "        tool_pair_names = [data['tool_pair'] for data in tool_pair_data]\n",
    "        rmsd_distributions = [data['rmsds'] for data in tool_pair_data]\n",
    "        \n",
    "        # Create violin plot with clear borders\n",
    "        violins = ax_rmsd.violinplot(rmsd_distributions, positions=range(len(tool_pair_names)), \n",
    "                                    showmeans=False, showmedians=False, showextrema=False)\n",
    "        \n",
    "        # Customize violin colors with clear borders\n",
    "        colors = plt.cm.Set3(np.linspace(0, 1, len(tool_pair_names)))\n",
    "        for i, violin in enumerate(violins['bodies']):\n",
    "            violin.set_facecolor(colors[i])\n",
    "            violin.set_alpha(0.7)\n",
    "            violin.set_edgecolor('black')  # Clear borders\n",
    "            violin.set_linewidth(2)       # Thick borders\n",
    "        \n",
    "        ax_rmsd.set_xticks(range(len(tool_pair_names)))\n",
    "        # Simplified x-axis labels - just the tool pair names\n",
    "        simplified_labels = [name.replace(' vs ', '\\nvs\\n') for name in tool_pair_names]\n",
    "        ax_rmsd.set_xticklabels(simplified_labels, rotation=0, ha='center', fontsize=16)\n",
    "        ax_rmsd.set_ylabel('RMSD (√Ö)', fontsize=20, fontweight='bold')  # Add y-axis label\n",
    "        ax_rmsd.grid(True, alpha=0.3)\n",
    "        ax_rmsd.set_ylim(0, min(15, max([data['rmsds'].max() for data in tool_pair_data])))\n",
    "        \n",
    "        # ========================================================================\n",
    "        # PLOTS 2-4: Ridge-style Score Distributions (Bottom - 3 horizontal plots)\n",
    "        # ========================================================================\n",
    "        \n",
    "        # Check if we have score data\n",
    "        has_score_data = any('tool1_score' in agreement or 'tool2_score' in agreement \n",
    "                           for data in tool_pair_data for agreement in data['agreements'])\n",
    "        \n",
    "        if has_score_data and len(tool_pair_data) > 0:\n",
    "            print(\"üìä Creating ridge-style score distribution analysis...\")\n",
    "            \n",
    "            # Define partner tool colors (color-blind friendly palette)\n",
    "            partner_tool_colors = {\n",
    "                'GOLD': '#E69F00',     # Orange (deuteranopia/protanopia safe)\n",
    "                'LeDock': '#56B4E9',   # Sky Blue (tritanopia safe)\n",
    "                'Smina': '#009E73'     # Bluish Green (all color-blind types safe)\n",
    "            }\n",
    "            \n",
    "            # Define RMSD ranges with actual numeric values\n",
    "            rmsd_ranges = [\n",
    "                (0, 2, \"<2√Ö\"),\n",
    "                (2, 5, \"2-5√Ö\"),\n",
    "                (5, float('inf'), \">5√Ö\")\n",
    "            ]\n",
    "            \n",
    "            # Create horizontal ridge plots for each tool\n",
    "            for tool_idx, tool in enumerate(all_tools):\n",
    "                if tool_idx > 2:  # Only use first 3 tools (we have 3 horizontal subplots)\n",
    "                    break\n",
    "                    \n",
    "                ax_tool = fig.add_subplot(gs[1, tool_idx])\n",
    "                \n",
    "                print(f\"   Creating ridge plot for {tool}...\")\n",
    "                \n",
    "                # Collect all score data for this tool across all tool pairs and RMSD ranges\n",
    "                y_position = 0\n",
    "                y_spacing = 0.8  # Overlapping ridges\n",
    "                max_y = 0\n",
    "                ridge_data = []  # Store ridge data for annotations\n",
    "                \n",
    "                # For each tool pair involving this tool\n",
    "                for pair_idx, data in enumerate(tool_pair_data):\n",
    "                    # Check if this tool is tool1 or tool2 in the pair\n",
    "                    if data['tool1'] == tool:\n",
    "                        partner_tool = data['tool2']\n",
    "                        score_key = 'tool1_score'\n",
    "                    elif data['tool2'] == tool:\n",
    "                        partner_tool = data['tool1']\n",
    "                        score_key = 'tool2_score'\n",
    "                    else:\n",
    "                        continue\n",
    "                    \n",
    "                    # Get partner tool color (use partner tool's color, not current tool's color)\n",
    "                    ridge_color = partner_tool_colors.get(partner_tool, '#ADD8E6')\n",
    "                    \n",
    "                    # For each RMSD range\n",
    "                    for range_idx, (rmsd_min, rmsd_max, range_name) in enumerate(rmsd_ranges):\n",
    "                        # Collect scores for this tool in this RMSD range\n",
    "                        tool_scores = []\n",
    "                        for agreement in data['agreements']:\n",
    "                            if (rmsd_min <= agreement['rmsd'] < rmsd_max and \n",
    "                                score_key in agreement and pd.notna(agreement[score_key])):\n",
    "                                tool_scores.append(agreement[score_key])\n",
    "                        \n",
    "                        if len(tool_scores) >= 5:  # Only plot if we have sufficient data\n",
    "                            try:\n",
    "                                from scipy.stats import gaussian_kde\n",
    "                                \n",
    "                                # Create density curve\n",
    "                                kde = gaussian_kde(tool_scores)\n",
    "                                score_range = np.linspace(min(tool_scores), max(tool_scores), 100)\n",
    "                                density = kde(score_range)\n",
    "                                \n",
    "                                # Normalize density for ridge plot appearance\n",
    "                                density = density / density.max() * 0.6  # Scale height\n",
    "                                \n",
    "                                # Plot the ridge with clear borders\n",
    "                                ax_tool.fill_between(score_range, y_position, y_position + density, \n",
    "                                                    alpha=0.8, color=ridge_color, \n",
    "                                                    edgecolor='black', linewidth=1.5)\n",
    "                                \n",
    "                                # Store ridge data for annotation (removed RMSD annotations)\n",
    "                                ridge_data.append({\n",
    "                                    'y_center': y_position + 0.3,\n",
    "                                    'x_center': np.median(tool_scores),\n",
    "                                    'partner_tool': partner_tool\n",
    "                                })\n",
    "                                \n",
    "                                y_position += y_spacing\n",
    "                                max_y = max(max_y, y_position)\n",
    "                                \n",
    "                            except Exception as e:\n",
    "                                print(f\"Warning: Could not create KDE for {tool} vs {partner_tool} in {range_name} range: {e}\")\n",
    "                                continue\n",
    "                \n",
    "                # Customize the subplot - add x-axis label with units\n",
    "                ax_tool.set_ylabel('')  # Remove y-axis title\n",
    "                if tool in ['LeDock', 'Smina']:\n",
    "                    ax_tool.set_xlabel(f'{tool} Score (kcal/mol)', fontsize=18, fontweight='bold')  # Add units\n",
    "                else:  # GOLD has no unit\n",
    "                    ax_tool.set_xlabel(f'{tool} Score', fontsize=18, fontweight='bold')  # No unit for GOLD\n",
    "                ax_tool.grid(True, alpha=0.3)\n",
    "                \n",
    "                # Set appropriate x-axis limits based on tool - extend LeDock/Smina to include positive values\n",
    "                if tool == 'GOLD':\n",
    "                    ax_tool.set_xlim(0, 100)\n",
    "                else:  # LeDock and Smina use negative scores, but extend to positive values up to 5\n",
    "                    ax_tool.set_xlim(-12, 5)\n",
    "                \n",
    "                # Set y-axis limits and remove ticks\n",
    "                if max_y > 0:\n",
    "                    ax_tool.set_ylim(-0.2, max_y + 0.2)\n",
    "                ax_tool.set_yticks([])\n",
    "                \n",
    "                # Remove RMSD range annotations (simplified for cleaner look)\n",
    "                # for ridge_info in ridge_data:\n",
    "                #     annotation_text = f\"{ridge_info['range_name']} vs {ridge_info['partner_tool']}\"\n",
    "                #     ax_tool.text(ridge_info['x_center'], ridge_info['y_center'], annotation_text,\n",
    "                #                ha='center', va='center', fontsize=10, fontweight='bold',\n",
    "                #                color=range_colors.get(ridge_info['range_name'], 'black'),\n",
    "                #                bbox=dict(boxstyle='round,pad=0.2', facecolor='white', alpha=0.8))\n",
    "                \n",
    "                if max_y == 0:  # No data was plotted\n",
    "                    ax_tool.text(0.5, 0.5, f'Insufficient score data\\nfor {tool}', \n",
    "                               ha='center', va='center', transform=ax_tool.transAxes, \n",
    "                               fontsize=16, fontweight='bold')\n",
    "        \n",
    "        else:\n",
    "            # No score data - show message in remaining subplots\n",
    "            for i in range(3):\n",
    "                ax_tool = fig.add_subplot(gs[1, i])\n",
    "                ax_tool.text(0.5, 0.5, 'No score data available', \n",
    "                           ha='center', va='center', transform=ax_tool.transAxes, \n",
    "                           fontsize=18, fontweight='bold')\n",
    "                # Add x-axis labels even when no data\n",
    "                if i < len(all_tools):\n",
    "                    if all_tools[i] in ['LeDock', 'Smina']:\n",
    "                        ax_tool.set_xlabel(f'{all_tools[i]} Score (kcal/mol)', fontsize=18, fontweight='bold')\n",
    "                    else:\n",
    "                        ax_tool.set_xlabel(f'{all_tools[i]} Score', fontsize=18, fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout(pad=1.5)  # Add padding for better spacing\n",
    "        plt.show()\n",
    "        \n",
    "        # Print detailed statistics - also update the printed ranges to use actual values\n",
    "        print(f\"\\nüìà SCORE DISTRIBUTION BY TOOL PAIR AND RMSD RANGE:\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        for data in tool_pair_data:\n",
    "            print(f\"\\nüîß {data['tool_pair']}:\")\n",
    "            \n",
    "            # Define RMSD ranges\n",
    "            rmsd_ranges = [\n",
    "                (0, 2, \"<2√Ö\"),\n",
    "                (2, 5, \"2-5√Ö\"),\n",
    "                (5, float('inf'), \">5√Ö\")\n",
    "            ]\n",
    "            \n",
    "            for i, (min_rmsd, max_rmsd, range_name) in enumerate(rmsd_ranges):\n",
    "                # Count scores for each tool in this range\n",
    "                tool1_scores = []\n",
    "                tool2_scores = []\n",
    "                \n",
    "                for agreement in data['agreements']:\n",
    "                    if min_rmsd <= agreement['rmsd'] < max_rmsd:\n",
    "                        if 'tool1_score' in agreement and pd.notna(agreement['tool1_score']):\n",
    "                            tool1_scores.append(agreement['tool1_score'])\n",
    "                        if 'tool2_score' in agreement and pd.notna(agreement['tool2_score']):\n",
    "                            tool2_scores.append(agreement['tool2_score'])\n",
    "                \n",
    "                print(f\"   {range_name}:\")\n",
    "                if tool1_scores:\n",
    "                    print(f\"     {data['tool1']}: n={len(tool1_scores)}, Mean={np.mean(tool1_scores):.2f}¬±{np.std(tool1_scores):.2f}\")\n",
    "                else:\n",
    "                    print(f\"     {data['tool1']}: No data\")\n",
    "                    \n",
    "                if tool2_scores:\n",
    "                    print(f\"     {data['tool2']}: n={len(tool2_scores)}, Mean={np.mean(tool2_scores):.2f}¬±{np.std(tool2_scores):.2f}\")\n",
    "                else:\n",
    "                    print(f\"     {data['tool2']}: No data\")\n",
    "        \n",
    "        # Summary statistics for RMSD agreement\n",
    "        print(f\"\\nüìà TOOL AGREEMENT SUMMARY:\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Sort by mean agreement (best to worst)\n",
    "        sorted_pairs = sorted(tool_pair_data, key=lambda x: x['mean_rmsd'])\n",
    "        \n",
    "        print(\"üèÜ Tool pairs ranked by agreement (best to worst):\")\n",
    "        for i, data in enumerate(sorted_pairs, 1):\n",
    "            print(f\"   {i}. {data['tool_pair']}: {data['mean_rmsd']:.2f} ¬± {data['std_rmsd']:.2f} √Ö \"\n",
    "                  f\"(median: {data['median_rmsd']:.2f} √Ö, n={data['n_pairs']:,})\")\n",
    "        \n",
    "        # Overall statistics\n",
    "        all_means = [data['mean_rmsd'] for data in tool_pair_data]\n",
    "        best_agreement = min(all_means)\n",
    "        worst_agreement = max(all_means)\n",
    "        \n",
    "        print(f\"\\nüìä Overall agreement statistics:\")\n",
    "        print(f\"   Best tool pair agreement: {best_agreement:.2f} √Ö\")\n",
    "        print(f\"   Worst tool pair agreement: {worst_agreement:.2f} √Ö\")\n",
    "        print(f\"   Average across all pairs: {np.mean(all_means):.2f} ¬± {np.std(all_means):.2f} √Ö\")\n",
    "        \n",
    "    else:\n",
    "        print(\"‚ùå No valid tool pairs found for agreement analysis\")\n",
    "    \n",
    "    # Reset matplotlib parameters to defaults\n",
    "    plt.rcdefaults()\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Cannot generate tool agreement distribution - missing required data\")\n",
    "    print(\"   Required: RMSD, Tool1, Tool2 columns\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c6c921",
   "metadata": {},
   "source": [
    "## Research Question 2: Cluster-Based Distinction of Preferred vs Non-Preferred Cavities\n",
    "\n",
    "This section investigates whether **cavity cluster membership** can distinguish between **preferred and non-preferred binding sites** for each drug-target combination.\n",
    "\n",
    "### Key Research Question:\n",
    "**Can we distinguish between preferred cavities and other cavities based on their cluster membership patterns?**\n",
    "\n",
    "### Analysis Strategy:\n",
    "1. **Define Preferred Cavities**: For each unique drug-uniprot combination, identify preferred cavities using multiple criteria:\n",
    "   - **Lowest RMSD** (best structural agreement between tools)\n",
    "   - **Best Score1** (optimal docking score from primary tool)\n",
    "   - **Best Score2** (optimal docking score from secondary tool)\n",
    "\n",
    "2. **Cluster Comparison**: Compare the cluster membership patterns between:\n",
    "   - **Preferred cavities** (selected by each criterion)\n",
    "   - **Non-preferred cavities** (all other cavities for the same drug-target pair)\n",
    "\n",
    "3. **Statistical Analysis**: Test whether preferred and non-preferred cavities come from significantly different cluster distributions\n",
    "\n",
    "4. **Visualization**: Generate comparative plots showing cluster characteristics for preferred vs non-preferred cavities\n",
    "\n",
    "### Expected Insights:\n",
    "- Whether certain cavity clusters are systematically preferred across drug-target pairs\n",
    "- How different preference criteria (RMSD vs scores) affect cluster selection patterns\n",
    "- Statistical significance of cluster-based cavity preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6ada62",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Research Question 2: Preferred vs Non-Preferred Cavity Analysis ===\")\n",
    "\n",
    "# Convert to pandas for easier manipulation\n",
    "df_rq2 = combined_results.to_pandas()\n",
    "\n",
    "# Check if we have cluster information\n",
    "if 'cavity_cluster_id' not in df_rq2.columns:\n",
    "    print(\"‚ùå No cluster information available - cannot perform cluster-based analysis\")\n",
    "    rq2_analysis = None\n",
    "else:\n",
    "    print(\"‚úÖ Cluster information available - proceeding with analysis\")\n",
    "    \n",
    "    # Remove rows without cluster information\n",
    "    df_rq2_clean = df_rq2.dropna(subset=['cavity_cluster_id']).copy()\n",
    "    print(f\"Dataset for RQ2: {len(df_rq2_clean):,} rows with cluster information\")\n",
    "    \n",
    "    # First, let's extract individual tool scores for each cavity\n",
    "    print(\"\\nüîç Extracting individual tool scores for each cavity...\")\n",
    "    \n",
    "    # Create a comprehensive dataset with all tool scores per cavity\n",
    "    cavity_scores = {}  # Key: (drug, target, cavity), Value: {tool_scores, rmsd_info, cluster}\n",
    "    \n",
    "    for _, row in df_rq2_clean.iterrows():\n",
    "        key = (row['drugbank_id'], row['uniprot_id'], row['cavity_index'])\n",
    "        \n",
    "        if key not in cavity_scores:\n",
    "            cavity_scores[key] = {\n",
    "                'drug': row['drugbank_id'],\n",
    "                'target': row['uniprot_id'],\n",
    "                'cavity_index': row['cavity_index'],\n",
    "                'cluster_id': row['cavity_cluster_id'],\n",
    "                'tool_scores': {},\n",
    "                'rmsd_data': []\n",
    "            }\n",
    "        \n",
    "        # Store individual tool scores\n",
    "        tool1 = row['Tool1']\n",
    "        tool2 = row['Tool2']\n",
    "        \n",
    "        if pd.notna(tool1) and pd.notna(row['Score1']):\n",
    "            cavity_scores[key]['tool_scores'][tool1] = row['Score1']\n",
    "        if pd.notna(tool2) and pd.notna(row['Score2']):\n",
    "            cavity_scores[key]['tool_scores'][tool2] = row['Score2']\n",
    "        \n",
    "        # Store RMSD information\n",
    "        cavity_scores[key]['rmsd_data'].append({\n",
    "            'tool1': tool1,\n",
    "            'tool2': tool2,\n",
    "            'rmsd': row['RMSD']\n",
    "        })\n",
    "    \n",
    "    print(f\"‚úÖ Extracted scores for {len(cavity_scores):,} unique cavities\")\n",
    "    \n",
    "    # Calculate minimum RMSD for each cavity (across all tool pairs)\n",
    "    # This represents the best consensus pose for each cavity\n",
    "    for key in cavity_scores:\n",
    "        rmsd_values = [item['rmsd'] for item in cavity_scores[key]['rmsd_data'] if pd.notna(item['rmsd'])]\n",
    "        cavity_scores[key]['min_rmsd'] = np.min(rmsd_values) if rmsd_values else np.nan\n",
    "        cavity_scores[key]['avg_rmsd'] = np.mean(rmsd_values) if rmsd_values else np.nan  # Keep for reference\n",
    "    \n",
    "    # Define preference criteria with proper tool names\n",
    "    preference_criteria = {\n",
    "        'lowest_rmsd': 'Best Consensus (Min RMSD)',\n",
    "        'best_gold': 'Best GOLD Score',\n",
    "        'best_ledock': 'Best LeDock Score',\n",
    "        'best_smina': 'Best Smina Score'\n",
    "    }\n",
    "    \n",
    "    # Initialize results storage\n",
    "    rq2_analysis = {\n",
    "        'preferred_cavities': {},\n",
    "        'cluster_comparisons': {},\n",
    "        'statistical_tests': {},\n",
    "        'summary_stats': {}\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nAnalyzing {len(preference_criteria)} preference criteria...\")\n",
    "    \n",
    "    # For each preference criterion\n",
    "    for criterion_key, criterion_name in preference_criteria.items():\n",
    "        print(f\"\\n--- Analyzing {criterion_name} preference ---\")\n",
    "        \n",
    "        # Storage for this criterion\n",
    "        preferred_cavities = []\n",
    "        non_preferred_cavities = []\n",
    "        preferred_clusters = []\n",
    "        non_preferred_clusters = []\n",
    "        \n",
    "        # Group cavities by drug-target pairs\n",
    "        drug_target_cavities = {}\n",
    "        for key, cavity_data in cavity_scores.items():\n",
    "            dt_key = (cavity_data['drug'], cavity_data['target'])\n",
    "            if dt_key not in drug_target_cavities:\n",
    "                drug_target_cavities[dt_key] = []\n",
    "            drug_target_cavities[dt_key].append(cavity_data)\n",
    "        \n",
    "        valid_pairs = 0\n",
    "        \n",
    "        for (drug, target), cavities in drug_target_cavities.items():\n",
    "            if len(cavities) < 2:  # Need at least 2 cavities to distinguish preferred vs non-preferred\n",
    "                continue\n",
    "            \n",
    "            # Filter cavities based on available data for this criterion\n",
    "            if criterion_key == 'lowest_rmsd':\n",
    "                valid_cavities = [c for c in cavities if pd.notna(c['min_rmsd'])]\n",
    "                if len(valid_cavities) < 2:\n",
    "                    continue\n",
    "                # Find cavity with lowest minimum RMSD (best consensus)\n",
    "                preferred_cavity = min(valid_cavities, key=lambda x: x['min_rmsd'])\n",
    "            elif criterion_key == 'best_gold':\n",
    "                valid_cavities = [c for c in cavities if 'GOLD' in c['tool_scores']]\n",
    "                if len(valid_cavities) < 2:\n",
    "                    continue\n",
    "                # Find cavity with best (highest) GOLD score\n",
    "                preferred_cavity = max(valid_cavities, key=lambda x: x['tool_scores']['GOLD'])\n",
    "            elif criterion_key == 'best_ledock':\n",
    "                valid_cavities = [c for c in cavities if 'LeDock' in c['tool_scores']]\n",
    "                if len(valid_cavities) < 2:\n",
    "                    continue\n",
    "                # Find cavity with best (most negative) LeDock score\n",
    "                preferred_cavity = min(valid_cavities, key=lambda x: x['tool_scores']['LeDock'])\n",
    "            elif criterion_key == 'best_smina':\n",
    "                valid_cavities = [c for c in cavities if 'Smina' in c['tool_scores']]\n",
    "                if len(valid_cavities) < 2:\n",
    "                    continue\n",
    "                # Find cavity with best (most negative) Smina score\n",
    "                preferred_cavity = min(valid_cavities, key=lambda x: x['tool_scores']['Smina'])\n",
    "            \n",
    "            # Store preferred cavity info\n",
    "            preferred_cavities.append(preferred_cavity)\n",
    "            preferred_clusters.append(preferred_cavity['cluster_id'])\n",
    "            \n",
    "            # Store non-preferred cavity info\n",
    "            non_preferred = [c for c in valid_cavities if c != preferred_cavity]\n",
    "            non_preferred_cavities.extend(non_preferred)\n",
    "            non_preferred_clusters.extend([c['cluster_id'] for c in non_preferred])\n",
    "            \n",
    "            valid_pairs += 1\n",
    "        \n",
    "        # Store results for this criterion\n",
    "        rq2_analysis['preferred_cavities'][criterion_key] = {\n",
    "            'preferred': preferred_cavities,\n",
    "            'non_preferred': non_preferred_cavities,\n",
    "            'preferred_clusters': preferred_clusters,\n",
    "            'non_preferred_clusters': non_preferred_clusters,\n",
    "            'n_drug_target_pairs': valid_pairs\n",
    "        }\n",
    "        \n",
    "        print(f\"   Analyzed {valid_pairs:,} drug-target pairs\")\n",
    "        print(f\"   Preferred cavities: {len(preferred_cavities):,}\")\n",
    "        print(f\"   Non-preferred cavities: {len(non_preferred_cavities):,}\")\n",
    "        print(f\"   Unique preferred clusters: {len(set(preferred_clusters)):,}\")\n",
    "        print(f\"   Unique non-preferred clusters: {len(set(non_preferred_clusters)):,}\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Completed preferred cavity identification for all criteria\")\n",
    "    \n",
    "    # Calculate cluster statistics for comparison\n",
    "    print(f\"\\n=== CLUSTER COMPARISON STATISTICS ===\")\n",
    "    \n",
    "    for criterion_key, criterion_name in preference_criteria.items():\n",
    "        data = rq2_analysis['preferred_cavities'][criterion_key]\n",
    "        \n",
    "        if len(data['preferred_clusters']) == 0:\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\n{criterion_name}:\")\n",
    "        \n",
    "        # Convert to pandas Series for analysis\n",
    "        preferred_clusters_series = pd.Series(data['preferred_clusters'])\n",
    "        non_preferred_clusters_series = pd.Series(data['non_preferred_clusters'])\n",
    "        \n",
    "        # Cluster frequency analysis\n",
    "        preferred_cluster_counts = preferred_clusters_series.value_counts()\n",
    "        non_preferred_cluster_counts = non_preferred_clusters_series.value_counts()\n",
    "        \n",
    "        # Top preferred clusters\n",
    "        top_preferred = preferred_cluster_counts.head(5)\n",
    "        print(f\"   Top 5 preferred clusters: {dict(top_preferred)}\")\n",
    "        \n",
    "        # Statistical comparison using Chi-square test\n",
    "        from scipy.stats import chi2_contingency\n",
    "        \n",
    "        # Create contingency table\n",
    "        all_clusters = set(data['preferred_clusters'] + data['non_preferred_clusters'])\n",
    "        \n",
    "        contingency_data = []\n",
    "        for cluster in all_clusters:\n",
    "            pref_count = preferred_cluster_counts.get(cluster, 0)\n",
    "            non_pref_count = non_preferred_cluster_counts.get(cluster, 0)\n",
    "            contingency_data.append([pref_count, non_pref_count])\n",
    "        \n",
    "        if len(contingency_data) > 1:\n",
    "            contingency_table = np.array(contingency_data)\n",
    "            \n",
    "            # Perform chi-square test\n",
    "            try:\n",
    "                chi2, p_value, dof, expected = chi2_contingency(contingency_table)\n",
    "                \n",
    "                rq2_analysis['statistical_tests'][criterion_key] = {\n",
    "                    'chi2_statistic': chi2,\n",
    "                    'p_value': p_value,\n",
    "                    'degrees_of_freedom': dof,\n",
    "                    'significant': p_value < 0.05\n",
    "                }\n",
    "                \n",
    "                print(f\"   Chi-square test: œá¬≤ = {chi2:.3f}, p = {p_value:.6f}\")\n",
    "                print(f\"   {'‚úÖ Significant' if p_value < 0.05 else '‚ùå Not significant'} difference in cluster distributions\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ö†Ô∏è Could not perform chi-square test: {e}\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Statistical analysis completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523de80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# üìä RQ2: Violin Plots for Preferred vs Non-Preferred Cavities (Individual Tool Scores)\n",
    "# ===============================================================================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Check if RQ2 analysis exists\n",
    "if 'rq2_analysis' not in globals() or rq2_analysis is None:\n",
    "    print(\"‚ùå RQ2 analysis not found. Please run the previous RQ2 analysis cell first.\")\n",
    "else:\n",
    "    print(\"‚úÖ RQ2 analysis found. Creating violin plots...\")\n",
    "    \n",
    "    # Set up poster-quality plotting parameters (matching RQ1)\n",
    "    plt.rcParams.update({\n",
    "        'font.size': 24,                 # Larger base font size\n",
    "        'axes.titlesize': 28,            # Larger title font\n",
    "        'axes.labelsize': 22,            # Larger axis labels\n",
    "        'xtick.labelsize': 22,           # Larger tick labels\n",
    "        'ytick.labelsize': 20,           # Larger tick labels\n",
    "        'legend.fontsize': 22,           # Larger legend font\n",
    "        'figure.titlesize': 32           # Larger figure title\n",
    "    })\n",
    "    \n",
    "    # Define preference criteria with their corresponding metrics\n",
    "    preference_criteria = {\n",
    "        'lowest_rmsd': {'name': 'Best Consensus\\n(Min RMSD)', 'metric': 'RMSD (√Ö)'},\n",
    "        'best_gold': {'name': 'Best GOLD\\nScore', 'metric': 'GOLD Score'},\n",
    "        'best_ledock': {'name': 'Best LeDock\\nScore', 'metric': 'LeDock Score (kcal/mol)'},\n",
    "        'best_smina': {'name': 'Best Smina\\nScore', 'metric': 'Smina Score (kcal/mol)'}\n",
    "    }\n",
    "    \n",
    "    # Count how many criteria have data\n",
    "    valid_criteria = []\n",
    "    for criterion_key, criterion_info in preference_criteria.items():\n",
    "        if criterion_key in rq2_analysis['preferred_cavities'] and len(rq2_analysis['preferred_cavities'][criterion_key]['preferred']) > 0:\n",
    "            valid_criteria.append((criterion_key, criterion_info))\n",
    "    \n",
    "    if len(valid_criteria) == 0:\n",
    "        print(\"‚ùå No valid criteria with data found\")\n",
    "    else:\n",
    "        # Create 2x2 subplot grid\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "        axes = axes.flatten()  # Flatten for easy indexing\n",
    "        \n",
    "        # Loop over each valid preference criterion\n",
    "        for idx, (criterion_key, criterion_info) in enumerate(valid_criteria):\n",
    "            if idx >= 4:  # Only show first 4 criteria\n",
    "                break\n",
    "                \n",
    "            ax = axes[idx]\n",
    "            data = rq2_analysis['preferred_cavities'][criterion_key]\n",
    "            criterion_name = criterion_info['name']\n",
    "            metric = criterion_info['metric']\n",
    "            \n",
    "            # Prepare data for this specific metric\n",
    "            metric_data = []\n",
    "            \n",
    "            if metric == 'RMSD (√Ö)':\n",
    "                # RMSD data - use minimum RMSD for each cavity\n",
    "                for cavity in data['preferred']:\n",
    "                    if 'min_rmsd' in cavity and pd.notna(cavity['min_rmsd']):\n",
    "                        metric_data.append({'Preference': 'Preferred', 'Value': cavity['min_rmsd']})\n",
    "                for cavity in data['non_preferred']:\n",
    "                    if 'min_rmsd' in cavity and pd.notna(cavity['min_rmsd']):\n",
    "                        metric_data.append({'Preference': 'Non-Preferred', 'Value': cavity['min_rmsd']})\n",
    "            \n",
    "            elif metric == 'GOLD Score':\n",
    "                # GOLD scores\n",
    "                for cavity in data['preferred']:\n",
    "                    if 'tool_scores' in cavity and 'GOLD' in cavity['tool_scores']:\n",
    "                        metric_data.append({'Preference': 'Preferred', 'Value': cavity['tool_scores']['GOLD']})\n",
    "                for cavity in data['non_preferred']:\n",
    "                    if 'tool_scores' in cavity and 'GOLD' in cavity['tool_scores']:\n",
    "                        metric_data.append({'Preference': 'Non-Preferred', 'Value': cavity['tool_scores']['GOLD']})\n",
    "            \n",
    "            elif metric == 'LeDock Score (kcal/mol)':\n",
    "                # LeDock scores\n",
    "                for cavity in data['preferred']:\n",
    "                    if 'tool_scores' in cavity and 'LeDock' in cavity['tool_scores']:\n",
    "                        metric_data.append({'Preference': 'Preferred', 'Value': cavity['tool_scores']['LeDock']})\n",
    "                for cavity in data['non_preferred']:\n",
    "                    if 'tool_scores' in cavity and 'LeDock' in cavity['tool_scores']:\n",
    "                        metric_data.append({'Preference': 'Non-Preferred', 'Value': cavity['tool_scores']['LeDock']})\n",
    "            \n",
    "            elif metric == 'Smina Score (kcal/mol)':\n",
    "                # Smina scores\n",
    "                for cavity in data['preferred']:\n",
    "                    if 'tool_scores' in cavity and 'Smina' in cavity['tool_scores']:\n",
    "                        metric_data.append({'Preference': 'Preferred', 'Value': cavity['tool_scores']['Smina']})\n",
    "                for cavity in data['non_preferred']:\n",
    "                    if 'tool_scores' in cavity and 'Smina' in cavity['tool_scores']:\n",
    "                        metric_data.append({'Preference': 'Non-Preferred', 'Value': cavity['tool_scores']['Smina']})\n",
    "            \n",
    "            # Plot if we have data\n",
    "            if len(metric_data) > 0:\n",
    "                df_metric = pd.DataFrame(metric_data)\n",
    "                \n",
    "                # Check if we have both preferred and non-preferred data\n",
    "                prefs = df_metric['Preference'].unique()\n",
    "                if len(prefs) > 1:\n",
    "                    try:\n",
    "                        # Create split violin plot using seaborn\n",
    "                        df_metric['dummy'] = 'All'\n",
    "                        sns.violinplot(\n",
    "                            data=df_metric,\n",
    "                            y='Value',\n",
    "                            x='dummy',\n",
    "                            hue='Preference',\n",
    "                            ax=ax,\n",
    "                            palette=['lightcoral', 'lightblue'],\n",
    "                            inner='quartile',\n",
    "                            split=True\n",
    "                        )\n",
    "                        \n",
    "                        # Customize subplot\n",
    "                        ax.set_title(f'{criterion_name}', fontsize=24, fontweight='bold', pad=20)\n",
    "                        ax.set_ylabel(metric, fontsize=22, fontweight='bold')\n",
    "                        ax.set_xlabel(\"\")  # Remove x-axis label\n",
    "                        ax.set_xticklabels([])  # Remove x-axis tick labels\n",
    "                        ax.grid(True, alpha=0.3)\n",
    "                        \n",
    "                        # Remove legend (it's clear from context)\n",
    "                        if ax.legend_:\n",
    "                            ax.legend_.remove()\n",
    "                        \n",
    "                        # Set appropriate y-axis limits\n",
    "                        if metric == 'RMSD (√Ö)':\n",
    "                            ax.set_ylim(0, max(15, df_metric['Value'].max() * 1.1))\n",
    "                        elif metric == 'GOLD Score':\n",
    "                            ax.set_ylim(0, max(100, df_metric['Value'].max() * 1.1))\n",
    "                        elif metric in ['LeDock Score (kcal/mol)', 'Smina Score (kcal/mol)']:\n",
    "                            ax.set_ylim(min(-15, df_metric['Value'].min() * 1.1), \n",
    "                                       max(5, df_metric['Value'].max() * 1.1))\n",
    "                        \n",
    "                        # Enhanced statistical testing for non-normal data\n",
    "                        preferred_vals = df_metric[df_metric['Preference'] == 'Preferred']['Value'].values\n",
    "                        non_preferred_vals = df_metric[df_metric['Preference'] == 'Non-Preferred']['Value'].values\n",
    "                        \n",
    "                        if len(preferred_vals) > 0 and len(non_preferred_vals) > 0:\n",
    "                            try:\n",
    "                                # Mann-Whitney U test (appropriate for non-normal data)\n",
    "                                stat, p_val = stats.mannwhitneyu(preferred_vals, non_preferred_vals, alternative='two-sided')\n",
    "                                \n",
    "                                # Calculate effect size (rank biserial correlation)\n",
    "                                n1, n2 = len(preferred_vals), len(non_preferred_vals)\n",
    "                                effect_size = 1 - (2 * stat) / (n1 * n2)\n",
    "                                \n",
    "                                # Interpret effect size\n",
    "                                if abs(effect_size) < 0.1:\n",
    "                                    effect_interpretation = \"negligible\"\n",
    "                                elif abs(effect_size) < 0.3:\n",
    "                                    effect_interpretation = \"small\"\n",
    "                                elif abs(effect_size) < 0.5:\n",
    "                                    effect_interpretation = \"medium\"\n",
    "                                else:\n",
    "                                    effect_interpretation = \"large\"\n",
    "                                \n",
    "                                # Determine significance\n",
    "                                if p_val < 0.001:\n",
    "                                    significance = \"***\"\n",
    "                                elif p_val < 0.01:\n",
    "                                    significance = \"**\"\n",
    "                                elif p_val < 0.05:\n",
    "                                    significance = \"*\"\n",
    "                                else:\n",
    "                                    significance = \"ns\"\n",
    "                                \n",
    "                                # Add statistical annotation with effect size\n",
    "                                ax.text(0.5, 0.95, f'p = {p_val:.3f} {significance}', \n",
    "                                       transform=ax.transAxes, ha='center', va='top', \n",
    "                                       fontsize=18, fontweight='bold')\n",
    "                                ax.text(0.5, 0.88, f'effect size = {effect_size:.3f} ({effect_interpretation})', \n",
    "                                       transform=ax.transAxes, ha='center', va='top', \n",
    "                                       fontsize=16, style='italic')\n",
    "                                \n",
    "                            except Exception as e:\n",
    "                                print(f\"‚ö†Ô∏è Statistical test failed for {criterion_name} - {metric}: {e}\")\n",
    "                        \n",
    "                        print(f\"‚úÖ Created split violin plot for {criterion_name}\")\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f\"‚ùå Error creating violin plot for {criterion_name}: {e}\")\n",
    "                        ax.text(0.5, 0.5, f'Error creating plot', \n",
    "                               ha='center', va='center', transform=ax.transAxes, \n",
    "                               fontsize=20, fontweight='bold')\n",
    "                else:\n",
    "                    ax.text(0.5, 0.5, f'Only {prefs[0]} data available', \n",
    "                           ha='center', va='center', transform=ax.transAxes, \n",
    "                           fontsize=20, fontweight='bold')\n",
    "            else:\n",
    "                ax.text(0.5, 0.5, f'No data available', \n",
    "                       ha='center', va='center', transform=ax.transAxes, \n",
    "                       fontsize=20, fontweight='bold')\n",
    "        \n",
    "        # Hide any unused subplots\n",
    "        for idx in range(len(valid_criteria), 4):\n",
    "            axes[idx].set_visible(False)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Print comprehensive summary statistics with improved statistical analysis\n",
    "        print(f\"\\nüìä COMPREHENSIVE SUMMARY STATISTICS:\")\n",
    "        print(\"=\" * 80)\n",
    "        print(\"Statistical Analysis Notes:\")\n",
    "        print(\"‚Ä¢ Mann-Whitney U test used (appropriate for non-normal distributions)\")\n",
    "        print(\"‚Ä¢ Effect size calculated using rank biserial correlation\")\n",
    "        print(\"‚Ä¢ Effect size interpretation: negligible (<0.1), small (0.1-0.3), medium (0.3-0.5), large (>0.5)\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        for criterion_key, criterion_info in valid_criteria:\n",
    "            data = rq2_analysis['preferred_cavities'][criterion_key]\n",
    "            criterion_name = criterion_info['name'].replace('\\n', ' ')  # Remove newlines for clean printing\n",
    "            metric = criterion_info['metric']\n",
    "            \n",
    "            print(f\"\\n{criterion_name} - {metric}:\")\n",
    "            print(f\"  Drug-target pairs analyzed: {data['n_drug_target_pairs']:,}\")\n",
    "            print(f\"  Preferred cavities: {len(data['preferred']):,}\")\n",
    "            print(f\"  Non-preferred cavities: {len(data['non_preferred']):,}\")\n",
    "            \n",
    "            # Get the appropriate statistics based on the metric\n",
    "            if metric == 'RMSD (√Ö)':\n",
    "                # Min RMSD statistics\n",
    "                pref_vals = [c['min_rmsd'] for c in data['preferred'] if 'min_rmsd' in c and pd.notna(c['min_rmsd'])]\n",
    "                non_pref_vals = [c['min_rmsd'] for c in data['non_preferred'] if 'min_rmsd' in c and pd.notna(c['min_rmsd'])]\n",
    "                unit = \"√Ö\"\n",
    "            elif metric == 'GOLD Score':\n",
    "                # GOLD Score statistics\n",
    "                pref_vals = [c['tool_scores']['GOLD'] for c in data['preferred'] if 'tool_scores' in c and 'GOLD' in c['tool_scores']]\n",
    "                non_pref_vals = [c['tool_scores']['GOLD'] for c in data['non_preferred'] if 'tool_scores' in c and 'GOLD' in c['tool_scores']]\n",
    "                unit = \"\"\n",
    "            elif metric == 'LeDock Score (kcal/mol)':\n",
    "                # LeDock Score statistics\n",
    "                pref_vals = [c['tool_scores']['LeDock'] for c in data['preferred'] if 'tool_scores' in c and 'LeDock' in c['tool_scores']]\n",
    "                non_pref_vals = [c['tool_scores']['LeDock'] for c in data['non_preferred'] if 'tool_scores' in c and 'LeDock' in c['tool_scores']]\n",
    "                unit = \"kcal/mol\"\n",
    "            elif metric == 'Smina Score (kcal/mol)':\n",
    "                # Smina Score statistics\n",
    "                pref_vals = [c['tool_scores']['Smina'] for c in data['preferred'] if 'tool_scores' in c and 'Smina' in c['tool_scores']]\n",
    "                non_pref_vals = [c['tool_scores']['Smina'] for c in data['non_preferred'] if 'tool_scores' in c and 'Smina' in c['tool_scores']]\n",
    "                unit = \"kcal/mol\"\n",
    "            \n",
    "            if len(pref_vals) > 0 and len(non_pref_vals) > 0:\n",
    "                print(f\"\\n  {metric} Statistics:\")\n",
    "                print(f\"    Preferred: n={len(pref_vals)}, median={np.median(pref_vals):.3f} {unit} (IQR: {np.percentile(pref_vals, 25):.3f}-{np.percentile(pref_vals, 75):.3f})\")\n",
    "                print(f\"    Non-Preferred: n={len(non_pref_vals)}, median={np.median(non_pref_vals):.3f} {unit} (IQR: {np.percentile(non_pref_vals, 25):.3f}-{np.percentile(non_pref_vals, 75):.3f})\")\n",
    "        \n",
    "        # Reset matplotlib parameters\n",
    "        plt.rcdefaults()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc42844a",
   "metadata": {},
   "source": [
    "## Research Question 3: Do Cavity Clusters Separate Preferred from Non-Preferred Cavities?\n",
    "\n",
    "**Research Question 3:** *Within each drug-target interaction, do preferred and non-preferred cavities belong to the same or different cavity clusters?*\n",
    "\n",
    "### üéØ Specific Analysis Goal:\n",
    "For each **drugbank_id - uniprot_id** combination (drug-target pair) with multiple cavities:\n",
    "1. **Identify the preferred cavity** based on each scoring criterion (lowest RMSD, best GOLD/LeDock/Smina scores)\n",
    "2. **Compare cluster membership** between the preferred cavity and all non-preferred cavities\n",
    "3. **Determine cluster separation**: Does the preferred cavity belong to a different cluster than the non-preferred cavities?\n",
    "4. **Calculate separation rates** and test for statistical significance\n",
    "\n",
    "### üìä Key Metrics:\n",
    "- **Cluster separation rate**: Percentage of drug-target pairs where preferred cavity is in a different cluster\n",
    "- **Statistical significance**: Binomial test against 50% random separation expectation\n",
    "- **Separation patterns**: Analysis across different preference criteria\n",
    "\n",
    "### üß© Analysis Logic:\n",
    "- **Same cluster**: Preferred cavity shares its cluster ID with at least one non-preferred cavity\n",
    "- **Different clusters**: Preferred cavity has a unique cluster ID from all non-preferred cavities\n",
    "- **Separation rate**: Proportion of drug-target pairs showing different clusters\n",
    "\n",
    "### üìà Main Visualizations:\n",
    "- **Separation rate bar plots** showing cluster separation effectiveness for each criterion\n",
    "- **Count plots** showing distribution of same vs different cluster cases\n",
    "- **Statistical significance indicators** for each preference criterion\n",
    "\n",
    "This analysis directly addresses whether cavity clustering is useful for distinguishing high-quality binding sites from lower-quality alternatives in drug discovery.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d5cd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# üî¨ RQ3: Cluster Separation Analysis - Do Preferred and Non-Preferred Cavities \n",
    "#      Belong to Same or Different Clusters?\n",
    "# =============================================================================\n",
    "\n",
    "print(\"üîç RESEARCH QUESTION 3: Do cavity clusters separate preferred from non-preferred cavities?\")\n",
    "print(\"=\" * 85)\n",
    "print(\"üéØ SPECIFIC QUESTION: Within each drug-target pair, do preferred and non-preferred\")\n",
    "print(\"   cavities belong to the same cluster or different clusters?\")\n",
    "\n",
    "# Check if RQ2 analysis exists and cavity cluster data is available\n",
    "if 'rq2_analysis' not in globals() or rq2_analysis is None:\n",
    "    print(\"‚ùå RQ2 analysis not found. Please run the RQ2 analysis first.\")\n",
    "elif 'cavity_cluster_id' not in combined_results.columns:\n",
    "    print(\"‚ùå Cavity cluster data not found. Please ensure cavity cluster information is loaded.\")\n",
    "else:\n",
    "    print(\"‚úÖ RQ2 analysis and cavity cluster data found. Proceeding with RQ3 cluster separation analysis...\")\n",
    "    \n",
    "    # Initialize RQ3 analysis storage\n",
    "    rq3_analysis = {\n",
    "        'drug_target_analysis': {},\n",
    "        'cluster_separation_stats': {},\n",
    "        'detailed_results': {}\n",
    "    }\n",
    "    \n",
    "    # Define the same preference criteria as RQ2\n",
    "    preference_criteria = {\n",
    "        'lowest_rmsd': {'name': 'Best Consensus (Min RMSD)', 'metric': 'RMSD (√Ö)'},\n",
    "        'best_gold': {'name': 'Best GOLD Score', 'metric': 'GOLD Score'},\n",
    "        'best_ledock': {'name': 'Best LeDock Score', 'metric': 'LeDock Score (kcal/mol)'},\n",
    "        'best_smina': {'name': 'Best Smina Score', 'metric': 'Smina Score (kcal/mol)'}\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nüß© Analyzing cluster separation for {len(preference_criteria)} preference criteria...\")\n",
    "    print(\"üìã Analysis approach:\")\n",
    "    print(\"   1. For each drug-target pair with multiple cavities\")\n",
    "    print(\"   2. Identify the preferred cavity based on each criterion\")\n",
    "    print(\"   3. Check if preferred cavity's cluster differs from non-preferred cavities' clusters\")\n",
    "    print(\"   4. Calculate separation rates and statistical significance\")\n",
    "    \n",
    "    # For each preference criterion, analyze cluster separation within drug-target pairs\n",
    "    for criterion_key, criterion_info in preference_criteria.items():\n",
    "        print(f\"\\n--- Analyzing {criterion_info['name']} ---\")\n",
    "        \n",
    "        # Get the preferred and non-preferred cavity data from RQ2\n",
    "        if criterion_key not in rq2_analysis['preferred_cavities']:\n",
    "            print(f\"   ‚ö†Ô∏è No RQ2 data available for {criterion_key}\")\n",
    "            continue\n",
    "            \n",
    "        rq2_data = rq2_analysis['preferred_cavities'][criterion_key]\n",
    "        \n",
    "        # Prepare data structure for this criterion\n",
    "        drug_target_cluster_analysis = {}\n",
    "        \n",
    "        # Group cavities by drug-target pairs\n",
    "        dt_pairs = {}\n",
    "        \n",
    "        # Process preferred cavities\n",
    "        for cavity in rq2_data['preferred']:\n",
    "            dt_key = (cavity['drug'], cavity['target'])\n",
    "            if dt_key not in dt_pairs:\n",
    "                dt_pairs[dt_key] = {'preferred': None, 'non_preferred': []}\n",
    "            dt_pairs[dt_key]['preferred'] = cavity\n",
    "        \n",
    "        # Process non-preferred cavities\n",
    "        for cavity in rq2_data['non_preferred']:\n",
    "            dt_key = (cavity['drug'], cavity['target'])\n",
    "            if dt_key not in dt_pairs:\n",
    "                dt_pairs[dt_key] = {'preferred': None, 'non_preferred': []}\n",
    "            dt_pairs[dt_key]['non_preferred'].append(cavity)\n",
    "        \n",
    "        # Analyze cluster separation for each drug-target pair\n",
    "        separation_results = []\n",
    "        valid_pairs = 0\n",
    "        \n",
    "        for dt_key, pair_data in dt_pairs.items():\n",
    "            drug, target = dt_key\n",
    "            \n",
    "            # Skip if no preferred cavity or no non-preferred cavities\n",
    "            if pair_data['preferred'] is None or len(pair_data['non_preferred']) == 0:\n",
    "                continue\n",
    "            \n",
    "            preferred_cavity = pair_data['preferred']\n",
    "            non_preferred_cavities = pair_data['non_preferred']\n",
    "            \n",
    "            # Check if cluster data is available\n",
    "            if 'cluster_id' not in preferred_cavity or pd.isna(preferred_cavity['cluster_id']):\n",
    "                continue\n",
    "            \n",
    "            preferred_cluster = preferred_cavity['cluster_id']\n",
    "            non_preferred_clusters = [c['cluster_id'] for c in non_preferred_cavities \n",
    "                                    if 'cluster_id' in c and pd.notna(c['cluster_id'])]\n",
    "            \n",
    "            if len(non_preferred_clusters) == 0:\n",
    "                continue\n",
    "            \n",
    "            # Determine separation status\n",
    "            if preferred_cluster in non_preferred_clusters:\n",
    "                separation_status = 'same_cluster'\n",
    "            else:\n",
    "                separation_status = 'different_cluster'\n",
    "            \n",
    "            separation_results.append({\n",
    "                'drug': drug,\n",
    "                'target': target,\n",
    "                'preferred_cluster': preferred_cluster,\n",
    "                'non_preferred_clusters': non_preferred_clusters,\n",
    "                'separation_status': separation_status,\n",
    "                'n_non_preferred': len(non_preferred_clusters),\n",
    "                'unique_non_preferred_clusters': len(set(non_preferred_clusters))\n",
    "            })\n",
    "            \n",
    "            valid_pairs += 1\n",
    "        \n",
    "        # Calculate statistics\n",
    "        if len(separation_results) > 0:\n",
    "            same_cluster_count = sum(1 for r in separation_results if r['separation_status'] == 'same_cluster')\n",
    "            different_cluster_count = sum(1 for r in separation_results if r['separation_status'] == 'different_cluster')\n",
    "            total_pairs = same_cluster_count + different_cluster_count\n",
    "            separation_rate = different_cluster_count / total_pairs if total_pairs > 0 else 0\n",
    "            \n",
    "            # Store results\n",
    "            rq3_analysis['drug_target_analysis'][criterion_key] = separation_results\n",
    "            rq3_analysis['cluster_separation_stats'][criterion_key] = {\n",
    "                'total_pairs': total_pairs,\n",
    "                'same_cluster': same_cluster_count,\n",
    "                'different_cluster': different_cluster_count,\n",
    "                'separation_rate': separation_rate\n",
    "            }\n",
    "            \n",
    "            print(f\"   Valid drug-target pairs analyzed: {total_pairs}\")\n",
    "            print(f\"   Same cluster (preferred shares cluster with non-preferred): {same_cluster_count} ({same_cluster_count/total_pairs*100:.1f}%)\")\n",
    "            print(f\"   Different clusters (preferred in unique cluster): {different_cluster_count} ({different_cluster_count/total_pairs*100:.1f}%)\")\n",
    "            print(f\"   Cluster separation rate: {separation_rate:.3f}\")\n",
    "            \n",
    "            # Statistical significance test\n",
    "            # Binomial test: null hypothesis is 50% separation rate (random)\n",
    "            from scipy.stats import binomtest\n",
    "            p_value = binomtest(different_cluster_count, total_pairs, 0.5, alternative='two-sided').pvalue\n",
    "            \n",
    "            rq3_analysis['cluster_separation_stats'][criterion_key]['binomial_test_p'] = p_value\n",
    "            rq3_analysis['cluster_separation_stats'][criterion_key]['significant'] = p_value < 0.05\n",
    "            \n",
    "            print(f\"   üìä Binomial test (H0: separation rate = 50%): p = {p_value:.6f}\")\n",
    "            print(f\"   üìä Result: {'‚úÖ Significant separation' if p_value < 0.05 else '‚ùå No significant separation'}\")\n",
    "            \n",
    "        else:\n",
    "            print(f\"   ‚ö†Ô∏è No valid drug-target pairs found for analysis\")\n",
    "    \n",
    "    # Summary of findings\n",
    "    print(f\"\\nüìä RQ3 CLUSTER SEPARATION ANALYSIS SUMMARY:\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    valid_criteria = [k for k in rq3_analysis['cluster_separation_stats'] \n",
    "                     if rq3_analysis['cluster_separation_stats'][k]['total_pairs'] > 0]\n",
    "    \n",
    "    if len(valid_criteria) > 0:\n",
    "        print(f\"‚úÖ Successfully analyzed {len(valid_criteria)} preference criteria\")\n",
    "        \n",
    "        # Show summary statistics\n",
    "        for criterion_key in valid_criteria:\n",
    "            stats = rq3_analysis['cluster_separation_stats'][criterion_key]\n",
    "            criterion_name = preference_criteria[criterion_key]['name']\n",
    "            \n",
    "            print(f\"\\n{criterion_name}:\")\n",
    "            print(f\"  Separation rate: {stats['separation_rate']:.3f}\")\n",
    "            print(f\"  Statistical significance: {'‚úÖ Yes' if stats['significant'] else '‚ùå No'} (p = {stats['binomial_test_p']:.6f})\")\n",
    "        \n",
    "        # Overall conclusion\n",
    "        significant_criteria = [k for k in valid_criteria \n",
    "                              if rq3_analysis['cluster_separation_stats'][k]['significant']]\n",
    "        \n",
    "        print(f\"\\nüéØ OVERALL CONCLUSION:\")\n",
    "        if len(significant_criteria) > 0:\n",
    "            print(f\"   ‚úÖ {len(significant_criteria)} out of {len(valid_criteria)} criteria show significant cluster separation\")\n",
    "            print(f\"   üî• Cavity clusters CAN effectively separate preferred from non-preferred cavities\")\n",
    "        else:\n",
    "            print(f\"   ‚ùå No criteria show significant cluster separation\")\n",
    "            print(f\"   üî• Cavity clusters do NOT effectively separate preferred from non-preferred cavities\")\n",
    "        \n",
    "        print(f\"\\nüéØ Ready for RQ3 visualization...\")\n",
    "        \n",
    "    else:\n",
    "        print(\"‚ùå No valid criteria found for cluster separation analysis\")\n",
    "        print(\"   Please check data availability and RQ2 analysis results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521f4117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# üìä RQ3: Cluster Separation Analysis for Preferred vs Non-Preferred Cavities\n",
    "# =============================================================================\n",
    "\n",
    "print(\"üìä Analyzing cluster separation for preferred vs non-preferred cavities...\")\n",
    "print(\"üéØ Research Question: Do preferred and non-preferred cavities belong to same or different clusters?\")\n",
    "\n",
    "# Check if RQ3 analysis exists\n",
    "if 'rq3_analysis' not in globals() or rq3_analysis is None:\n",
    "    print(\"‚ùå RQ3 analysis not found. Please run the previous RQ3 analysis cell first.\")\n",
    "else:\n",
    "    print(\"‚úÖ RQ3 analysis found. Analyzing cluster separation within drug-target pairs...\")\n",
    "    \n",
    "    # Initialize cluster separation analysis\n",
    "    cluster_separation_analysis = {\n",
    "        'same_cluster': {},\n",
    "        'different_cluster': {},\n",
    "        'separation_rates': {},\n",
    "        'statistical_tests': {}\n",
    "    }\n",
    "    \n",
    "    # Define the same preference criteria as before\n",
    "    preference_criteria = {\n",
    "        'lowest_rmsd': {'name': 'Best Consensus (Min RMSD)', 'metric': 'RMSD (√Ö)'},\n",
    "        'best_gold': {'name': 'Best GOLD Score', 'metric': 'GOLD Score'},\n",
    "        'best_ledock': {'name': 'Best LeDock Score', 'metric': 'LeDock Score (kcal/mol)'},\n",
    "        'best_smina': {'name': 'Best Smina Score', 'metric': 'Smina Score (kcal/mol)'}\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nüîç Analyzing cluster separation for {len(preference_criteria)} preference criteria...\")\n",
    "    \n",
    "    # For each preference criterion, analyze cluster separation\n",
    "    for criterion_key, criterion_info in preference_criteria.items():\n",
    "        print(f\"\\n--- Analyzing {criterion_info['name']} ---\")\n",
    "        \n",
    "        # Get the RQ2 data for this criterion\n",
    "        if criterion_key not in rq2_analysis['preferred_cavities']:\n",
    "            print(f\"   ‚ö†Ô∏è No RQ2 data available for {criterion_key}\")\n",
    "            continue\n",
    "            \n",
    "        rq2_data = rq2_analysis['preferred_cavities'][criterion_key]\n",
    "        \n",
    "        # Group cavities by drug-target pairs to analyze cluster separation\n",
    "        drug_target_cavities = {}\n",
    "        for key, cavity_data in cavity_scores.items():\n",
    "            dt_key = (cavity_data['drug'], cavity_data['target'])\n",
    "            if dt_key not in drug_target_cavities:\n",
    "                drug_target_cavities[dt_key] = []\n",
    "            drug_target_cavities[dt_key].append(cavity_data)\n",
    "        \n",
    "        # Analyze cluster separation for each drug-target pair\n",
    "        same_cluster_count = 0\n",
    "        different_cluster_count = 0\n",
    "        separation_details = []\n",
    "        \n",
    "        for (drug, target), cavities in drug_target_cavities.items():\n",
    "            if len(cavities) < 2:  # Need at least 2 cavities to analyze separation\n",
    "                continue\n",
    "            \n",
    "            # Find the preferred cavity for this drug-target pair and criterion\n",
    "            preferred_cavity = None\n",
    "            for cavity in rq2_data['preferred']:\n",
    "                if cavity['drug'] == drug and cavity['target'] == target:\n",
    "                    preferred_cavity = cavity\n",
    "                    break\n",
    "            \n",
    "            if preferred_cavity is None:\n",
    "                continue\n",
    "            \n",
    "            # Get non-preferred cavities for this drug-target pair\n",
    "            non_preferred_cavities = []\n",
    "            for cavity in rq2_data['non_preferred']:\n",
    "                if cavity['drug'] == drug and cavity['target'] == target:\n",
    "                    non_preferred_cavities.append(cavity)\n",
    "            \n",
    "            if len(non_preferred_cavities) == 0:\n",
    "                continue\n",
    "            \n",
    "            # Check cluster separation\n",
    "            preferred_cluster = preferred_cavity['cluster_id']\n",
    "            non_preferred_clusters = [c['cluster_id'] for c in non_preferred_cavities if pd.notna(c['cluster_id'])]\n",
    "            \n",
    "            if pd.notna(preferred_cluster) and len(non_preferred_clusters) > 0:\n",
    "                # Check if preferred cavity is in a different cluster from ALL non-preferred cavities\n",
    "                if preferred_cluster in non_preferred_clusters:\n",
    "                    same_cluster_count += 1\n",
    "                    separation_status = 'same_cluster'\n",
    "                else:\n",
    "                    different_cluster_count += 1\n",
    "                    separation_status = 'different_cluster'\n",
    "                \n",
    "                separation_details.append({\n",
    "                    'drug': drug,\n",
    "                    'target': target,\n",
    "                    'preferred_cluster': preferred_cluster,\n",
    "                    'non_preferred_clusters': non_preferred_clusters,\n",
    "                    'separation_status': separation_status,\n",
    "                    'n_cavities': len(cavities),\n",
    "                    'n_non_preferred': len(non_preferred_cavities)\n",
    "                })\n",
    "        \n",
    "        # Store results for this criterion\n",
    "        cluster_separation_analysis['same_cluster'][criterion_key] = same_cluster_count\n",
    "        cluster_separation_analysis['different_cluster'][criterion_key] = different_cluster_count\n",
    "        \n",
    "        total_analyzed = same_cluster_count + different_cluster_count\n",
    "        if total_analyzed > 0:\n",
    "            separation_rate = different_cluster_count / total_analyzed\n",
    "            cluster_separation_analysis['separation_rates'][criterion_key] = separation_rate\n",
    "            \n",
    "            print(f\"   Drug-target pairs analyzed: {total_analyzed}\")\n",
    "            print(f\"   Same cluster (preferred = non-preferred): {same_cluster_count} ({same_cluster_count/total_analyzed*100:.1f}%)\")\n",
    "            print(f\"   Different clusters (preferred ‚â† non-preferred): {different_cluster_count} ({different_cluster_count/total_analyzed*100:.1f}%)\")\n",
    "            print(f\"   Cluster separation rate: {separation_rate:.3f}\")\n",
    "            \n",
    "            # Statistical test: binomial test against null hypothesis of 50% separation\n",
    "            from scipy.stats import binomtest\n",
    "            \n",
    "            # Test if separation rate is significantly different from 50% (random)\n",
    "            p_value = binomtest(different_cluster_count, total_analyzed, 0.5, alternative='two-sided').pvalue\n",
    "            \n",
    "            cluster_separation_analysis['statistical_tests'][criterion_key] = {\n",
    "                'binomial_test_p': p_value,\n",
    "                'significant': p_value < 0.05,\n",
    "                'separation_rate': separation_rate,\n",
    "                'total_pairs': total_analyzed\n",
    "            }\n",
    "            \n",
    "            print(f\"   üìä Binomial test (H0: separation rate = 50%): p = {p_value:.6f}\")\n",
    "            print(f\"   üìä {'‚úÖ Significant' if p_value < 0.05 else '‚ùå Not significant'} deviation from random\")\n",
    "            \n",
    "        else:\n",
    "            print(f\"   ‚ö†Ô∏è No valid drug-target pairs found for analysis\")\n",
    "    \n",
    "    # Create visualization: Bar plot showing separation rates\n",
    "    print(f\"\\nüìä Creating cluster separation visualization...\")\n",
    "    \n",
    "    # Set up plotting parameters\n",
    "    plt.rcParams.update({\n",
    "        'font.size': 16,\n",
    "        'axes.titlesize': 20,\n",
    "        'axes.labelsize': 16,\n",
    "        'xtick.labelsize': 14,\n",
    "        'ytick.labelsize': 14,\n",
    "        'legend.fontsize': 14\n",
    "    })\n",
    "    \n",
    "    # Prepare data for plotting\n",
    "    criteria_names = []\n",
    "    separation_rates = []\n",
    "    same_cluster_counts = []\n",
    "    different_cluster_counts = []\n",
    "    significance_markers = []\n",
    "    \n",
    "    for criterion_key, criterion_info in preference_criteria.items():\n",
    "        if criterion_key in cluster_separation_analysis['separation_rates']:\n",
    "            criteria_names.append(criterion_info['name'])\n",
    "            separation_rates.append(cluster_separation_analysis['separation_rates'][criterion_key])\n",
    "            same_cluster_counts.append(cluster_separation_analysis['same_cluster'][criterion_key])\n",
    "            different_cluster_counts.append(cluster_separation_analysis['different_cluster'][criterion_key])\n",
    "            \n",
    "            # Add significance marker\n",
    "            if criterion_key in cluster_separation_analysis['statistical_tests']:\n",
    "                p_val = cluster_separation_analysis['statistical_tests'][criterion_key]['binomial_test_p']\n",
    "                if p_val < 0.001:\n",
    "                    significance_markers.append('***')\n",
    "                elif p_val < 0.01:\n",
    "                    significance_markers.append('**')\n",
    "                elif p_val < 0.05:\n",
    "                    significance_markers.append('*')\n",
    "                else:\n",
    "                    significance_markers.append('ns')\n",
    "            else:\n",
    "                significance_markers.append('ns')\n",
    "    \n",
    "    if len(criteria_names) > 0:\n",
    "        # Create stacked bar plot\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "        \n",
    "        # Plot 1: Separation rates\n",
    "        bars1 = ax1.bar(criteria_names, separation_rates, color='lightblue', edgecolor='black', linewidth=1)\n",
    "        ax1.axhline(y=0.5, color='red', linestyle='--', alpha=0.7, label='Random expectation (50%)')\n",
    "        ax1.set_ylabel('Cluster Separation Rate', fontweight='bold')\n",
    "        ax1.set_title('RQ3: Cluster Separation Rates\\n(Preferred vs Non-Preferred Cavities)', fontweight='bold')\n",
    "        ax1.set_ylim(0, 1)\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        ax1.legend()\n",
    "        \n",
    "        # Add significance markers\n",
    "        for i, (rate, sig) in enumerate(zip(separation_rates, significance_markers)):\n",
    "            ax1.text(i, rate + 0.05, sig, ha='center', va='bottom', fontweight='bold', fontsize=14)\n",
    "        \n",
    "        # Rotate x-axis labels for better readability\n",
    "        ax1.set_xticklabels(criteria_names, rotation=45, ha='right')\n",
    "        \n",
    "        # Plot 2: Counts (stacked bar)\n",
    "        width = 0.6\n",
    "        bars2 = ax2.bar(criteria_names, same_cluster_counts, width, label='Same Cluster', color='lightcoral', edgecolor='black')\n",
    "        bars3 = ax2.bar(criteria_names, different_cluster_counts, width, bottom=same_cluster_counts, \n",
    "                       label='Different Clusters', color='lightgreen', edgecolor='black')\n",
    "        \n",
    "        ax2.set_ylabel('Number of Drug-Target Pairs', fontweight='bold')\n",
    "        ax2.set_title('RQ3: Cluster Separation Counts\\n(Preferred vs Non-Preferred Cavities)', fontweight='bold')\n",
    "        ax2.legend()\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add count labels on bars\n",
    "        for i, (same, diff) in enumerate(zip(same_cluster_counts, different_cluster_counts)):\n",
    "            total = same + diff\n",
    "            if same > 0:\n",
    "                ax2.text(i, same/2, str(same), ha='center', va='center', fontweight='bold')\n",
    "            if diff > 0:\n",
    "                ax2.text(i, same + diff/2, str(diff), ha='center', va='center', fontweight='bold')\n",
    "        \n",
    "        # Rotate x-axis labels\n",
    "        ax2.set_xticklabels(criteria_names, rotation=45, ha='right')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Print comprehensive summary\n",
    "        print(f\"\\nüìä RQ3 CLUSTER SEPARATION SUMMARY:\")\n",
    "        print(\"=\" * 70)\n",
    "        print(\"üìã Analysis Summary:\")\n",
    "        print(\"‚Ä¢ For each drug-target pair, compared cluster IDs of preferred vs non-preferred cavities\")\n",
    "        print(\"‚Ä¢ 'Same cluster': Preferred cavity shares cluster with at least one non-preferred cavity\")\n",
    "        print(\"‚Ä¢ 'Different clusters': Preferred cavity is in a unique cluster from all non-preferred cavities\")\n",
    "        print(\"‚Ä¢ Binomial test: Tests if separation rate differs significantly from 50% (random)\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        for criterion_key, criterion_info in preference_criteria.items():\n",
    "            if criterion_key in cluster_separation_analysis['separation_rates']:\n",
    "                criterion_name = criterion_info['name']\n",
    "                same_count = cluster_separation_analysis['same_cluster'][criterion_key]\n",
    "                diff_count = cluster_separation_analysis['different_cluster'][criterion_key]\n",
    "                total = same_count + diff_count\n",
    "                sep_rate = cluster_separation_analysis['separation_rates'][criterion_key]\n",
    "                \n",
    "                print(f\"\\n{criterion_name}:\")\n",
    "                print(f\"  Total drug-target pairs: {total}\")\n",
    "                print(f\"  Same cluster: {same_count} ({same_count/total*100:.1f}%)\")\n",
    "                print(f\"  Different clusters: {diff_count} ({diff_count/total*100:.1f}%)\")\n",
    "                print(f\"  Separation rate: {sep_rate:.3f}\")\n",
    "                \n",
    "                if criterion_key in cluster_separation_analysis['statistical_tests']:\n",
    "                    test_data = cluster_separation_analysis['statistical_tests'][criterion_key]\n",
    "                    print(f\"  üìä Binomial test p-value: {test_data['binomial_test_p']:.6f}\")\n",
    "                    print(f\"  üìä Significantly different from random: {'‚úÖ Yes' if test_data['significant'] else '‚ùå No'}\")\n",
    "        \n",
    "        # Overall conclusion\n",
    "        significant_criteria = [k for k in cluster_separation_analysis['statistical_tests'] \n",
    "                              if cluster_separation_analysis['statistical_tests'][k]['significant']]\n",
    "        \n",
    "        print(f\"\\n‚úÖ RQ3 CONCLUSION:\")\n",
    "        if len(significant_criteria) > 0:\n",
    "            print(f\"üéØ Cavity clusters DO show significant separation for {len(significant_criteria)} out of {len(criteria_names)} criteria\")\n",
    "            print(f\"üî• Significant criteria: {[preference_criteria[k]['name'] for k in significant_criteria]}\")\n",
    "        else:\n",
    "            print(f\"üéØ Cavity clusters do NOT show significant separation for any criteria\")\n",
    "        \n",
    "        # Store results globally for potential further analysis\n",
    "        globals()['cluster_separation_analysis'] = cluster_separation_analysis\n",
    "        \n",
    "    else:\n",
    "        print(\"‚ùå No valid criteria found for cluster separation analysis\")\n",
    "    \n",
    "    # Reset matplotlib parameters\n",
    "    plt.rcdefaults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdef493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# üìä RQ3: KDE Plots for Cluster Ratio Distributions\n",
    "# =============================================================================\n",
    "\n",
    "print(\"üìä Creating KDE plots for cluster ratio distributions...\")\n",
    "print(\"üéØ Analysis: For each drug-target pair, calculate ratios of non-preferred cavities\")\n",
    "print(\"   in same vs different clusters compared to the preferred cavity\")\n",
    "\n",
    "# Check if RQ3 analysis exists\n",
    "if 'rq3_analysis' not in globals() or rq3_analysis is None:\n",
    "    print(\"‚ùå RQ3 analysis not found. Please run the previous RQ3 analysis cell first.\")\n",
    "else:\n",
    "    print(\"‚úÖ RQ3 analysis found. Calculating cluster ratios for each drug-target pair...\")\n",
    "    \n",
    "    # Set up poster-quality plotting parameters\n",
    "    plt.rcParams.update({\n",
    "        'font.size': 20,                 # Larger base font size\n",
    "        'axes.titlesize': 22,            # Larger title font\n",
    "        'axes.labelsize': 20,            # Larger axis labels\n",
    "        'xtick.labelsize': 18,           # Larger tick labels\n",
    "        'ytick.labelsize': 18,           # Larger tick labels\n",
    "        'legend.fontsize': 18,           # Larger legend font\n",
    "        'figure.titlesize': 24           # Larger figure title\n",
    "    })\n",
    "    \n",
    "    # Define the preference criteria\n",
    "    preference_criteria = {\n",
    "        'lowest_rmsd': {'name': 'Best Consensus\\n(Min RMSD)', 'metric': 'RMSD (√Ö)'},\n",
    "        'best_gold': {'name': 'Best GOLD\\nScore', 'metric': 'GOLD Score'},\n",
    "        'best_ledock': {'name': 'Best LeDock\\nScore', 'metric': 'LeDock Score'},\n",
    "        'best_smina': {'name': 'Best Smina\\nScore', 'metric': 'Smina Score'}\n",
    "    }\n",
    "    \n",
    "    # Calculate cluster ratios for each drug-target pair\n",
    "    ratio_data = {}\n",
    "    \n",
    "    for criterion_key, criterion_info in preference_criteria.items():\n",
    "        print(f\"\\n--- Calculating ratios for {criterion_info['name'].replace(chr(10), ' ')} ---\")\n",
    "        \n",
    "        # Get the drug-target analysis from RQ3\n",
    "        if criterion_key not in rq3_analysis['drug_target_analysis']:\n",
    "            print(f\"   ‚ö†Ô∏è No analysis data available for {criterion_key}\")\n",
    "            continue\n",
    "        \n",
    "        separation_results = rq3_analysis['drug_target_analysis'][criterion_key]\n",
    "        \n",
    "        # Calculate ratios for each drug-target pair\n",
    "        same_cluster_ratios = []\n",
    "        different_cluster_ratios = []\n",
    "        \n",
    "        for result in separation_results:\n",
    "            drug = result['drug']\n",
    "            target = result['target']\n",
    "            preferred_cluster = result['preferred_cluster']\n",
    "            non_preferred_clusters = result['non_preferred_clusters']\n",
    "            \n",
    "            # Count non-preferred cavities in same vs different clusters\n",
    "            same_cluster_count = non_preferred_clusters.count(preferred_cluster)\n",
    "            different_cluster_count = len(non_preferred_clusters) - same_cluster_count\n",
    "            total_non_preferred = len(non_preferred_clusters)\n",
    "            \n",
    "            # Calculate ratios\n",
    "            if total_non_preferred > 0:\n",
    "                same_cluster_ratio = same_cluster_count / total_non_preferred\n",
    "                different_cluster_ratio = different_cluster_count / total_non_preferred\n",
    "                \n",
    "                same_cluster_ratios.append(same_cluster_ratio)\n",
    "                different_cluster_ratios.append(different_cluster_ratio)\n",
    "        \n",
    "        # Store ratio data\n",
    "        ratio_data[criterion_key] = {\n",
    "            'same_cluster_ratios': same_cluster_ratios,\n",
    "            'different_cluster_ratios': different_cluster_ratios,\n",
    "            'n_drug_target_pairs': len(same_cluster_ratios)\n",
    "        }\n",
    "        \n",
    "        print(f\"   Drug-target pairs analyzed: {len(same_cluster_ratios)}\")\n",
    "        if len(same_cluster_ratios) > 0:\n",
    "            print(f\"   Same cluster ratios: mean={np.mean(same_cluster_ratios):.3f}, std={np.std(same_cluster_ratios):.3f}\")\n",
    "            print(f\"   Different cluster ratios: mean={np.mean(different_cluster_ratios):.3f}, std={np.std(different_cluster_ratios):.3f}\")\n",
    "    \n",
    "    # Create split violin plots\n",
    "    valid_criteria = [(k, v) for k, v in preference_criteria.items() if k in ratio_data and ratio_data[k]['n_drug_target_pairs'] > 0]\n",
    "    \n",
    "    if len(valid_criteria) == 0:\n",
    "        print(\"‚ùå No valid criteria with ratio data found\")\n",
    "    else:\n",
    "        print(f\"\\n‚úÖ Found {len(valid_criteria)} criteria with ratio data\")\n",
    "        \n",
    "        # Create 2x2 subplot grid for ratio distribution plots\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "        axes = axes.flatten()  # Flatten for easy indexing\n",
    "        \n",
    "        # Loop over each valid preference criterion\n",
    "        for idx, (criterion_key, criterion_info) in enumerate(valid_criteria):\n",
    "            if idx >= 4:  # Only show first 4 criteria\n",
    "                break\n",
    "                \n",
    "            ax = axes[idx]\n",
    "            ratios = ratio_data[criterion_key]\n",
    "            criterion_name = criterion_info['name']\n",
    "            \n",
    "            # Prepare data for split violin plot\n",
    "            plot_data = []\n",
    "            \n",
    "            # Add same cluster ratios\n",
    "            for ratio in ratios['same_cluster_ratios']:\n",
    "                plot_data.append({'Cluster_Type': 'Same Cluster', 'Ratio': ratio})\n",
    "            \n",
    "            # Add different cluster ratios\n",
    "            for ratio in ratios['different_cluster_ratios']:\n",
    "                plot_data.append({'Cluster_Type': 'Different Cluster', 'Ratio': ratio})\n",
    "            \n",
    "            # Convert to DataFrame\n",
    "            if len(plot_data) > 0:\n",
    "                df_ratios = pd.DataFrame(plot_data)\n",
    "                \n",
    "                # Check if we have both types of data\n",
    "                ratio_types = df_ratios['Cluster_Type'].unique()\n",
    "                if len(ratio_types) > 1:\n",
    "                    try:\n",
    "                        # Create KDE plot using seaborn with clear outlines\n",
    "                        # First create the filled areas\n",
    "                        sns.kdeplot(\n",
    "                            data=df_ratios,\n",
    "                            x='Ratio',\n",
    "                            hue='Cluster_Type',\n",
    "                            ax=ax,\n",
    "                            palette=['lightcoral', 'lightblue'],\n",
    "                            fill=True,\n",
    "                            alpha=0.6,\n",
    "                            common_norm=False,\n",
    "                            legend=False  # We'll add legend manually\n",
    "                        )\n",
    "                        \n",
    "                        # Then add the outlines with distinct colors\n",
    "                        for cluster_type, color in zip(['Same Cluster', 'Different Cluster'], ['darkred', 'darkblue']):\n",
    "                            subset = df_ratios[df_ratios['Cluster_Type'] == cluster_type]\n",
    "                            sns.kdeplot(\n",
    "                                data=subset,\n",
    "                                x='Ratio',\n",
    "                                ax=ax,\n",
    "                                color=color,\n",
    "                                fill=False,\n",
    "                                linewidth=3,\n",
    "                                label=cluster_type\n",
    "                            )\n",
    "                        \n",
    "                        # Customize subplot\n",
    "                        ax.set_title(f'{criterion_name}', fontsize=22, fontweight='bold', pad=20)\n",
    "                        ax.set_xlabel('Ratio of Non-Preferred Cavities', fontsize=20, fontweight='bold')\n",
    "                        ax.set_ylabel('Density', fontsize=20, fontweight='bold')\n",
    "                        ax.grid(True, alpha=0.3)\n",
    "                        ax.set_xlim(0, 1.05)  # Ratios are between 0 and 1\n",
    "                        \n",
    "                        # Add vertical line at 0.5 for reference\n",
    "                        ax.axvline(x=0.5, color='red', linestyle='--', alpha=0.7, linewidth=2, label='Equal Split (0.5)')\n",
    "                        \n",
    "                        # Customize legend\n",
    "                        handles, labels = ax.get_legend_handles_labels()\n",
    "                        ax.legend(handles, labels, loc='best', fontsize=12)\n",
    "                        \n",
    "                        # Statistical comparison\n",
    "                        same_ratios = np.array(ratios['same_cluster_ratios'])\n",
    "                        diff_ratios = np.array(ratios['different_cluster_ratios'])\n",
    "                        \n",
    "                        if len(same_ratios) > 0 and len(diff_ratios) > 0:\n",
    "                            # Mann-Whitney U test\n",
    "                            from scipy.stats import mannwhitneyu\n",
    "                            try:\n",
    "                                stat, p_val = mannwhitneyu(same_ratios, diff_ratios, alternative='two-sided')\n",
    "                                \n",
    "                                # Determine significance\n",
    "                                if p_val < 0.001:\n",
    "                                    significance = \"***\"\n",
    "                                elif p_val < 0.01:\n",
    "                                    significance = \"**\"\n",
    "                                elif p_val < 0.05:\n",
    "                                    significance = \"*\"\n",
    "                                else:\n",
    "                                    significance = \"ns\"\n",
    "                                \n",
    "                                # Add statistical annotation\n",
    "                                ax.text(0.5, 0.95, f'p = {p_val:.3f} {significance}', \n",
    "                                       transform=ax.transAxes, ha='center', va='top', \n",
    "                                       fontsize=18, fontweight='bold', bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8))\n",
    "                                \n",
    "                            except Exception as e:\n",
    "                                print(f\"   ‚ö†Ô∏è Statistical test failed for {criterion_name}: {e}\")\n",
    "                        \n",
    "                        print(f\"‚úÖ Created ratio KDE plot for {criterion_name.replace(chr(10), ' ')}\")\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f\"‚ùå Error creating ratio KDE plot for {criterion_name}: {e}\")\n",
    "                        ax.text(0.5, 0.5, f'Error creating plot\\n{str(e)[:50]}...', \n",
    "                               ha='center', va='center', transform=ax.transAxes, \n",
    "                               fontsize=16, fontweight='bold')\n",
    "                else:\n",
    "                    ax.text(0.5, 0.5, f'Only {ratio_types[0]} data available', \n",
    "                           ha='center', va='center', transform=ax.transAxes, \n",
    "                           fontsize=18, fontweight='bold')\n",
    "            else:\n",
    "                ax.text(0.5, 0.5, f'No ratio data available', \n",
    "                       ha='center', va='center', transform=ax.transAxes, \n",
    "                       fontsize=18, fontweight='bold')\n",
    "        \n",
    "        # Hide any unused subplots\n",
    "        for idx in range(len(valid_criteria), 4):\n",
    "            axes[idx].set_visible(False)\n",
    "        \n",
    "        # Add overall title\n",
    "        fig.suptitle('Same vs Different Cluster Ratios for Each Drug-Target Pair', \n",
    "                    fontsize=24, fontweight='bold', y=0.98)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.subplots_adjust(top=0.88)  # Make room for suptitle\n",
    "        plt.show()\n",
    "        \n",
    "        # Print comprehensive summary statistics\n",
    "        print(f\"\\nüìä RQ3 CLUSTER RATIO ANALYSIS SUMMARY:\")\n",
    "        print(\"=\" * 90)\n",
    "        print(\"üìã Analysis Logic:\")\n",
    "        print(\"‚Ä¢ For each drug-target pair with multiple cavities:\")\n",
    "        print(\"  - Identify 1 preferred cavity (based on each criterion)\")\n",
    "        print(\"  - Calculate ratios of non-preferred cavities in same vs different clusters\")\n",
    "        print(\"  - Same cluster ratio: (# non-preferred in preferred's cluster) / (total # non-preferred)\")\n",
    "        print(\"  - Different cluster ratio: (# non-preferred in other clusters) / (total # non-preferred)\")\n",
    "        print(\"‚Ä¢ Statistical test: Mann-Whitney U test comparing same vs different cluster ratios\")\n",
    "        print(\"=\" * 90)\n",
    "        \n",
    "        for criterion_key, criterion_info in valid_criteria:\n",
    "            ratios = ratio_data[criterion_key]\n",
    "            criterion_name = criterion_info['name'].replace('\\n', ' ')\n",
    "            \n",
    "            same_ratios = np.array(ratios['same_cluster_ratios'])\n",
    "            diff_ratios = np.array(ratios['different_cluster_ratios'])\n",
    "            \n",
    "            print(f\"\\n{criterion_name}:\")\n",
    "            print(f\"  Drug-target pairs analyzed: {ratios['n_drug_target_pairs']}\")\n",
    "            print(f\"  Same cluster ratios: mean={np.mean(same_ratios):.3f}, median={np.median(same_ratios):.3f}\")\n",
    "            print(f\"  Different cluster ratios: mean={np.mean(diff_ratios):.3f}, median={np.median(diff_ratios):.3f}\")\n",
    "            \n",
    "            # Statistical comparison\n",
    "            if len(same_ratios) > 0 and len(diff_ratios) > 0:\n",
    "                from scipy.stats import mannwhitneyu\n",
    "                try:\n",
    "                    stat, p_val = mannwhitneyu(same_ratios, diff_ratios, alternative='two-sided')\n",
    "                    print(f\"  üìä Mann-Whitney U test p-value: {p_val:.6f}\")\n",
    "                    print(f\"  üìä Significant difference: {'‚úÖ Yes' if p_val < 0.05 else '‚ùå No'}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"  ‚ö†Ô∏è Statistical test failed: {e}\")\n",
    "        \n",
    "        # Overall interpretation\n",
    "        print(f\"\\n‚úÖ RQ3 INTERPRETATION:\")\n",
    "        print(\"üéØ If cavities cluster meaningfully:\")\n",
    "        print(\"   - Same cluster ratios should be LOW (preferred and non-preferred in different clusters)\")\n",
    "        print(\"   - Different cluster ratios should be HIGH (good separation)\")\n",
    "        print(\"üéØ If clustering is random:\")\n",
    "        print(\"   - Both ratios should be around 0.5 (no meaningful separation)\")\n",
    "        \n",
    "        # Store results globally\n",
    "        globals()['cluster_ratio_analysis'] = ratio_data\n",
    "        \n",
    "    # Reset matplotlib parameters\n",
    "    plt.rcdefaults()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d21c41f",
   "metadata": {},
   "source": [
    "## Research Question 4: Can Scoring Metrics Separate Positive from Negative Samples?\n",
    "\n",
    "**Research Question 4:** *Do Best RMSD, Best GOLD score, Best SMINA score, or Best LeDock score effectively separate positive (known drug-target) from negative (balanced negative) samples?*\n",
    "\n",
    "### üéØ Specific Analysis Goal:\n",
    "For each scoring metric:\n",
    "1. **Extract best scores** for each drug-target-cavity combination\n",
    "2. **Compare score distributions** between positive and negative samples\n",
    "3. **Calculate separation metrics**: Effect size (Cohen's d), AUC-ROC\n",
    "4. **Test statistical significance**: Mann-Whitney U test, Kolmogorov-Smirnov test\n",
    "5. **Visualize separation**: Distribution plots, ROC curves\n",
    "\n",
    "### üìä Key Metrics:\n",
    "- **Effect Size (Cohen's d)**: Standardized mean difference between positive and negative samples\n",
    "- **AUC-ROC**: Area under the receiver operating characteristic curve\n",
    "- **Mann-Whitney U p-value**: Statistical significance of distribution differences\n",
    "- **Separation quality**: Poor (AUC < 0.6), Fair (0.6-0.7), Good (0.7-0.8), Excellent (> 0.8)\n",
    "\n",
    "### üß© Scoring Metrics to Test:\n",
    "1. **Best RMSD** (√Ö): Lower is better (closer structural agreement)\n",
    "2. **Best GOLD Score**: Higher is better (stronger predicted binding)\n",
    "3. **Best SMINA Score** (kcal/mol): Lower (more negative) is better\n",
    "4. **Best LeDock Score** (kcal/mol): Lower (more negative) is better\n",
    "\n",
    "### üìà Main Visualizations:\n",
    "- **Violin plots** showing score distributions for positive vs negative samples\n",
    "- **ROC curves** demonstrating classification performance\n",
    "- **Box plots** with statistical significance markers\n",
    "- **Density plots** with overlays for direct comparison\n",
    "\n",
    "This analysis addresses whether computational docking scores can distinguish true drug-target interactions from non-interacting decoys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63750a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# üî¨ RQ4: Scoring Metrics Separation Analysis - Positive vs Negative Samples\n",
    "# =============================================================================\n",
    "\n",
    "print(\"üîç RESEARCH QUESTION 4: Can scoring metrics separate positive from negative samples?\")\n",
    "print(\"=\" * 85)\n",
    "print(\"üéØ SPECIFIC QUESTION: Do Best RMSD, Best GOLD, Best SMINA, or Best LeDock scores\")\n",
    "print(\"   effectively distinguish known drug-target interactions from negative controls?\")\n",
    "\n",
    "# Check if sample_type column exists\n",
    "if 'sample_type' not in combined_results.columns:\n",
    "    print(\"‚ùå Sample type annotation not found. Please run the sample type annotation cell first.\")\n",
    "else:\n",
    "    # Check if we have both positive and negative samples\n",
    "    sample_types = combined_results['sample_type'].unique().to_list()\n",
    "    print(f\"\\nüìä Sample types found: {sample_types}\")\n",
    "    \n",
    "    has_positive = 'positive' in sample_types\n",
    "    has_negative = any('negative' in str(st).lower() for st in sample_types if st is not None)\n",
    "    \n",
    "    if not has_positive:\n",
    "        print(\"‚ùå No positive samples found in the dataset\")\n",
    "    elif not has_negative:\n",
    "        print(\"‚ùå No negative samples found in the dataset\")\n",
    "        print(\"   Note: Negative sample data may need to be loaded. See earlier diagnostics.\")\n",
    "    else:\n",
    "        print(\"‚úÖ Both positive and negative samples found. Proceeding with RQ4 analysis...\")\n",
    "        \n",
    "        # Initialize RQ4 analysis storage\n",
    "        rq4_analysis = {\n",
    "            'score_distributions': {},\n",
    "            'statistical_tests': {},\n",
    "            'effect_sizes': {},\n",
    "            'roc_analysis': {},\n",
    "            'best_scores_by_sample': {}\n",
    "        }\n",
    "        \n",
    "        # Define scoring metrics to analyze\n",
    "        scoring_metrics = {\n",
    "            'best_rmsd': {\n",
    "                'name': 'Best RMSD',\n",
    "                'column': 'RMSD',\n",
    "                'aggregation': 'min',  # Lower is better\n",
    "                'unit': '√Ö',\n",
    "                'better_direction': 'lower'\n",
    "            },\n",
    "            'best_gold': {\n",
    "                'name': 'Best GOLD Score',\n",
    "                'column': 'Score2',  # GOLD is typically Score2\n",
    "                'aggregation': 'max',  # Higher is better\n",
    "                'unit': '',\n",
    "                'better_direction': 'higher'\n",
    "            },\n",
    "            'best_smina': {\n",
    "                'name': 'Best SMINA Score',\n",
    "                'column': 'Score1',  # SMINA is typically Score1\n",
    "                'aggregation': 'min',  # More negative is better\n",
    "                'unit': 'kcal/mol',\n",
    "                'better_direction': 'lower'\n",
    "            },\n",
    "            'best_ledock': {\n",
    "                'name': 'Best LeDock Score',\n",
    "                'column': 'LeDock_Score',\n",
    "                'aggregation': 'min',  # More negative is better\n",
    "                'unit': 'kcal/mol',\n",
    "                'better_direction': 'lower'\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        print(f\"\\nüîç Analyzing {len(scoring_metrics)} scoring metrics...\")\n",
    "        print(\"üìã Analysis steps:\")\n",
    "        print(\"   1. Extract best scores for each drug-target-cavity combination\")\n",
    "        print(\"   2. Separate by positive vs negative sample type\")\n",
    "        print(\"   3. Calculate statistical measures and effect sizes\")\n",
    "        print(\"   4. Perform ROC analysis for classification performance\")\n",
    "        \n",
    "        # For each scoring metric, extract best scores and analyze separation\n",
    "        for metric_key, metric_info in scoring_metrics.items():\n",
    "            print(f\"\\n{'='*80}\")\n",
    "            print(f\"Analyzing: {metric_info['name']}\")\n",
    "            print(f\"{'='*80}\")\n",
    "            \n",
    "            column = metric_info['column']\n",
    "            \n",
    "            # Check if column exists\n",
    "            if column not in combined_results.columns:\n",
    "                print(f\"   ‚ö†Ô∏è Column '{column}' not found. Skipping {metric_info['name']}\")\n",
    "                continue\n",
    "            \n",
    "            # Filter for non-null scores and valid sample types\n",
    "            valid_data = combined_results.filter(\n",
    "                (pl.col(column).is_not_null()) &\n",
    "                (pl.col('sample_type').is_not_null())\n",
    "            )\n",
    "            \n",
    "            if valid_data.is_empty():\n",
    "                print(f\"   ‚ö†Ô∏è No valid data for {metric_info['name']}\")\n",
    "                continue\n",
    "            \n",
    "            # Get best score for each drug-target-cavity combination\n",
    "            group_cols = ['drugbank_id', 'uniprot_id', 'cavity_index', 'sample_type']\n",
    "            \n",
    "            if metric_info['aggregation'] == 'min':\n",
    "                best_scores = valid_data.group_by(group_cols).agg([\n",
    "                    pl.col(column).min().alias('best_score')\n",
    "                ])\n",
    "            else:  # max\n",
    "                best_scores = valid_data.group_by(group_cols).agg([\n",
    "                    pl.col(column).max().alias('best_score')\n",
    "                ])\n",
    "            \n",
    "            # Separate positive and negative samples\n",
    "            positive_scores = best_scores.filter(\n",
    "                pl.col('sample_type') == 'positive'\n",
    "            )['best_score'].to_numpy()\n",
    "            \n",
    "            negative_scores = best_scores.filter(\n",
    "                pl.col('sample_type').str.contains('negative')\n",
    "            )['best_score'].to_numpy()\n",
    "            \n",
    "            # Remove NaN values\n",
    "            positive_scores = positive_scores[~np.isnan(positive_scores)]\n",
    "            negative_scores = negative_scores[~np.isnan(negative_scores)]\n",
    "            \n",
    "            print(f\"   Positive samples: {len(positive_scores):,} drug-target-cavity combinations\")\n",
    "            print(f\"   Negative samples: {len(negative_scores):,} drug-target-cavity combinations\")\n",
    "            \n",
    "            if len(positive_scores) == 0 or len(negative_scores) == 0:\n",
    "                print(f\"   ‚ö†Ô∏è Insufficient data for comparison\")\n",
    "                continue\n",
    "            \n",
    "            # Store distributions\n",
    "            rq4_analysis['score_distributions'][metric_key] = {\n",
    "                'positive': positive_scores,\n",
    "                'negative': negative_scores,\n",
    "                'metric_info': metric_info\n",
    "            }\n",
    "            \n",
    "            # Calculate descriptive statistics\n",
    "            pos_mean = np.mean(positive_scores)\n",
    "            pos_std = np.std(positive_scores)\n",
    "            pos_median = np.median(positive_scores)\n",
    "            \n",
    "            neg_mean = np.mean(negative_scores)\n",
    "            neg_std = np.std(negative_scores)\n",
    "            neg_median = np.median(negative_scores)\n",
    "            \n",
    "            print(f\"\\n   üìä Positive samples:\")\n",
    "            print(f\"      Mean: {pos_mean:.3f} {metric_info['unit']}\")\n",
    "            print(f\"      Std:  {pos_std:.3f}\")\n",
    "            print(f\"      Median: {pos_median:.3f} {metric_info['unit']}\")\n",
    "            \n",
    "            print(f\"\\n   üìä Negative samples:\")\n",
    "            print(f\"      Mean: {neg_mean:.3f} {metric_info['unit']}\")\n",
    "            print(f\"      Std:  {neg_std:.3f}\")\n",
    "            print(f\"      Median: {neg_median:.3f} {metric_info['unit']}\")\n",
    "            \n",
    "            # Calculate effect size (Cohen's d)\n",
    "            pooled_std = np.sqrt((pos_std**2 + neg_std**2) / 2)\n",
    "            cohens_d = (pos_mean - neg_mean) / pooled_std if pooled_std > 0 else 0\n",
    "            \n",
    "            rq4_analysis['effect_sizes'][metric_key] = {\n",
    "                'cohens_d': cohens_d,\n",
    "                'interpretation': 'small' if abs(cohens_d) < 0.5 else 'medium' if abs(cohens_d) < 0.8 else 'large'\n",
    "            }\n",
    "            \n",
    "            print(f\"\\n   üìä Effect Size (Cohen's d): {cohens_d:.3f}\")\n",
    "            print(f\"      Interpretation: {rq4_analysis['effect_sizes'][metric_key]['interpretation']}\")\n",
    "            \n",
    "            # Statistical tests\n",
    "            from scipy.stats import mannwhitneyu, ks_2samp\n",
    "            \n",
    "            # Mann-Whitney U test\n",
    "            mw_stat, mw_pval = mannwhitneyu(positive_scores, negative_scores, alternative='two-sided')\n",
    "            \n",
    "            # Kolmogorov-Smirnov test\n",
    "            ks_stat, ks_pval = ks_2samp(positive_scores, negative_scores)\n",
    "            \n",
    "            rq4_analysis['statistical_tests'][metric_key] = {\n",
    "                'mann_whitney': {'statistic': mw_stat, 'p_value': mw_pval},\n",
    "                'kolmogorov_smirnov': {'statistic': ks_stat, 'p_value': ks_pval}\n",
    "            }\n",
    "            \n",
    "            print(f\"\\n   üìä Statistical Tests:\")\n",
    "            print(f\"      Mann-Whitney U: p = {mw_pval:.6f} {'***' if mw_pval < 0.001 else '**' if mw_pval < 0.01 else '*' if mw_pval < 0.05 else 'ns'}\")\n",
    "            print(f\"      Kolmogorov-Smirnov: p = {ks_pval:.6f} {'***' if ks_pval < 0.001 else '**' if ks_pval < 0.01 else '*' if ks_pval < 0.05 else 'ns'}\")\n",
    "            \n",
    "            # ROC Analysis\n",
    "            from sklearn.metrics import roc_curve, auc\n",
    "            \n",
    "            # Prepare labels (1 for positive, 0 for negative)\n",
    "            y_true = np.concatenate([\n",
    "                np.ones(len(positive_scores)),\n",
    "                np.zeros(len(negative_scores))\n",
    "            ])\n",
    "            \n",
    "            # Prepare scores (need to flip if lower is better)\n",
    "            if metric_info['better_direction'] == 'lower':\n",
    "                # For metrics where lower is better (RMSD, SMINA, LeDock),\n",
    "                # use negative scores so that better scores are higher\n",
    "                y_scores = np.concatenate([\n",
    "                    -positive_scores,\n",
    "                    -negative_scores\n",
    "                ])\n",
    "            else:\n",
    "                # For metrics where higher is better (GOLD)\n",
    "                y_scores = np.concatenate([\n",
    "                    positive_scores,\n",
    "                    negative_scores\n",
    "                ])\n",
    "            \n",
    "            # Calculate ROC curve\n",
    "            fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            \n",
    "            rq4_analysis['roc_analysis'][metric_key] = {\n",
    "                'fpr': fpr,\n",
    "                'tpr': tpr,\n",
    "                'thresholds': thresholds,\n",
    "                'auc': roc_auc\n",
    "            }\n",
    "            \n",
    "            # Interpret AUC\n",
    "            if roc_auc < 0.6:\n",
    "                auc_interpretation = 'Poor'\n",
    "            elif roc_auc < 0.7:\n",
    "                auc_interpretation = 'Fair'\n",
    "            elif roc_auc < 0.8:\n",
    "                auc_interpretation = 'Good'\n",
    "            elif roc_auc < 0.9:\n",
    "                auc_interpretation = 'Excellent'\n",
    "            else:\n",
    "                auc_interpretation = 'Outstanding'\n",
    "            \n",
    "            print(f\"\\n   üìä ROC Analysis:\")\n",
    "            print(f\"      AUC-ROC: {roc_auc:.3f}\")\n",
    "            print(f\"      Classification quality: {auc_interpretation}\")\n",
    "        \n",
    "        print(f\"\\n‚úÖ RQ4 Analysis Complete!\")\n",
    "        print(f\"   Analyzed {len(rq4_analysis['score_distributions'])} scoring metrics\")\n",
    "        \n",
    "        # Store globally\n",
    "        globals()['rq4_analysis'] = rq4_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a939facf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# üìä RQ4: Visualization - Distribution Plots and ROC Curves\n",
    "# =============================================================================\n",
    "\n",
    "print(\"üìä Creating visualizations for RQ4: Positive vs Negative Sample Separation...\")\n",
    "\n",
    "# Check if RQ4 analysis exists\n",
    "if 'rq4_analysis' not in globals() or rq4_analysis is None:\n",
    "    print(\"‚ùå RQ4 analysis not found. Please run the previous RQ4 analysis cell first.\")\n",
    "else:\n",
    "    print(\"‚úÖ RQ4 analysis found. Creating comprehensive visualizations...\")\n",
    "    \n",
    "    # Set up poster-quality plotting parameters\n",
    "    plt.rcParams.update({\n",
    "        'font.size': 16,\n",
    "        'axes.titlesize': 18,\n",
    "        'axes.labelsize': 16,\n",
    "        'xtick.labelsize': 14,\n",
    "        'ytick.labelsize': 14,\n",
    "        'legend.fontsize': 14\n",
    "    })\n",
    "    \n",
    "    # Get valid metrics\n",
    "    valid_metrics = [(k, v) for k, v in rq4_analysis['score_distributions'].items()]\n",
    "    \n",
    "    if len(valid_metrics) == 0:\n",
    "        print(\"‚ùå No valid metrics found for visualization\")\n",
    "    else:\n",
    "        print(f\"‚úÖ Found {len(valid_metrics)} metrics to visualize\")\n",
    "        \n",
    "        # Create figure with subplots: Distribution plots (top) and ROC curves (bottom)\n",
    "        n_metrics = len(valid_metrics)\n",
    "        fig = plt.figure(figsize=(20, 12))\n",
    "        \n",
    "        # Create grid: 2 rows (distributions, ROC curves)\n",
    "        gs = fig.add_gridspec(2, n_metrics, hspace=0.3, wspace=0.3)\n",
    "        \n",
    "        # Loop through each metric\n",
    "        for idx, (metric_key, dist_data) in enumerate(valid_metrics):\n",
    "            metric_info = dist_data['metric_info']\n",
    "            positive_scores = dist_data['positive']\n",
    "            negative_scores = dist_data['negative']\n",
    "            \n",
    "            # === Top row: Violin/Box plots ===\n",
    "            ax_dist = fig.add_subplot(gs[0, idx])\n",
    "            \n",
    "            # Prepare data for plotting\n",
    "            plot_data = []\n",
    "            for score in positive_scores:\n",
    "                plot_data.append({'Sample Type': 'Positive', 'Score': score})\n",
    "            for score in negative_scores:\n",
    "                plot_data.append({'Sample Type': 'Negative', 'Score': score})\n",
    "            \n",
    "            df_plot = pd.DataFrame(plot_data)\n",
    "            \n",
    "            # Create violin plot\n",
    "            sns.violinplot(\n",
    "                data=df_plot,\n",
    "                x='Sample Type',\n",
    "                y='Score',\n",
    "                ax=ax_dist,\n",
    "                palette=['lightgreen', 'lightcoral'],\n",
    "                inner='box',\n",
    "                cut=0\n",
    "            )\n",
    "            \n",
    "            # Customize distribution plot\n",
    "            ax_dist.set_title(f'{metric_info[\"name\"]}', fontsize=18, fontweight='bold')\n",
    "            ax_dist.set_ylabel(f'Score ({metric_info[\"unit\"]})', fontsize=16, fontweight='bold')\n",
    "            ax_dist.set_xlabel('Sample Type', fontsize=16, fontweight='bold')\n",
    "            ax_dist.grid(True, alpha=0.3, axis='y')\n",
    "            \n",
    "            # Add statistical significance\n",
    "            if metric_key in rq4_analysis['statistical_tests']:\n",
    "                p_val = rq4_analysis['statistical_tests'][metric_key]['mann_whitney']['p_value']\n",
    "                if p_val < 0.001:\n",
    "                    sig_marker = '***'\n",
    "                elif p_val < 0.01:\n",
    "                    sig_marker = '**'\n",
    "                elif p_val < 0.05:\n",
    "                    sig_marker = '*'\n",
    "                else:\n",
    "                    sig_marker = 'ns'\n",
    "                \n",
    "                # Add significance annotation\n",
    "                y_max = df_plot['Score'].max()\n",
    "                y_min = df_plot['Score'].min()\n",
    "                y_range = y_max - y_min\n",
    "                \n",
    "                ax_dist.plot([0, 1], [y_max + 0.05 * y_range, y_max + 0.05 * y_range], \n",
    "                           'k-', linewidth=2)\n",
    "                ax_dist.text(0.5, y_max + 0.07 * y_range, sig_marker, \n",
    "                           ha='center', va='bottom', fontsize=16, fontweight='bold')\n",
    "            \n",
    "            # Add effect size\n",
    "            if metric_key in rq4_analysis['effect_sizes']:\n",
    "                cohens_d = rq4_analysis['effect_sizes'][metric_key]['cohens_d']\n",
    "                ax_dist.text(0.02, 0.98, f\"Cohen's d = {cohens_d:.3f}\", \n",
    "                           transform=ax_dist.transAxes, ha='left', va='top',\n",
    "                           fontsize=12, bbox=dict(boxstyle=\"round,pad=0.3\", \n",
    "                           facecolor=\"white\", alpha=0.8))\n",
    "            \n",
    "            # === Bottom row: ROC curves ===\n",
    "            ax_roc = fig.add_subplot(gs[1, idx])\n",
    "            \n",
    "            if metric_key in rq4_analysis['roc_analysis']:\n",
    "                roc_data = rq4_analysis['roc_analysis'][metric_key]\n",
    "                fpr = roc_data['fpr']\n",
    "                tpr = roc_data['tpr']\n",
    "                roc_auc = roc_data['auc']\n",
    "                \n",
    "                # Plot ROC curve\n",
    "                ax_roc.plot(fpr, tpr, color='darkblue', linewidth=3, \n",
    "                          label=f'AUC = {roc_auc:.3f}')\n",
    "                \n",
    "                # Plot diagonal (random classifier)\n",
    "                ax_roc.plot([0, 1], [0, 1], 'k--', linewidth=2, alpha=0.5, \n",
    "                          label='Random (AUC = 0.50)')\n",
    "                \n",
    "                # Customize ROC plot\n",
    "                ax_roc.set_xlabel('False Positive Rate', fontsize=16, fontweight='bold')\n",
    "                ax_roc.set_ylabel('True Positive Rate', fontsize=16, fontweight='bold')\n",
    "                ax_roc.set_title(f'ROC Curve - {metric_info[\"name\"]}', \n",
    "                               fontsize=18, fontweight='bold')\n",
    "                ax_roc.grid(True, alpha=0.3)\n",
    "                ax_roc.legend(loc='lower right', fontsize=12)\n",
    "                ax_roc.set_xlim([0, 1])\n",
    "                ax_roc.set_ylim([0, 1])\n",
    "                \n",
    "                # Add AUC interpretation\n",
    "                if roc_auc < 0.6:\n",
    "                    auc_interp = 'Poor'\n",
    "                    color = 'red'\n",
    "                elif roc_auc < 0.7:\n",
    "                    auc_interp = 'Fair'\n",
    "                    color = 'orange'\n",
    "                elif roc_auc < 0.8:\n",
    "                    auc_interp = 'Good'\n",
    "                    color = 'yellow'\n",
    "                elif roc_auc < 0.9:\n",
    "                    auc_interp = 'Excellent'\n",
    "                    color = 'lightgreen'\n",
    "                else:\n",
    "                    auc_interp = 'Outstanding'\n",
    "                    color = 'darkgreen'\n",
    "                \n",
    "                ax_roc.text(0.98, 0.02, auc_interp, transform=ax_roc.transAxes,\n",
    "                          ha='right', va='bottom', fontsize=14, fontweight='bold',\n",
    "                          bbox=dict(boxstyle=\"round,pad=0.5\", facecolor=color, alpha=0.7))\n",
    "        \n",
    "        # Add overall title\n",
    "        fig.suptitle('RQ4: Scoring Metrics Separation - Positive vs Negative Samples', \n",
    "                    fontsize=22, fontweight='bold', y=0.98)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.subplots_adjust(top=0.95)\n",
    "        plt.show()\n",
    "        \n",
    "        # Print comprehensive summary\n",
    "        print(f\"\\nüìä RQ4 SEPARATION ANALYSIS SUMMARY:\")\n",
    "        print(\"=\" * 90)\n",
    "        \n",
    "        for metric_key, dist_data in valid_metrics:\n",
    "            metric_info = dist_data['metric_info']\n",
    "            print(f\"\\n{metric_info['name']} ({metric_info['unit']}):\")\n",
    "            \n",
    "            # Effect size\n",
    "            if metric_key in rq4_analysis['effect_sizes']:\n",
    "                cohens_d = rq4_analysis['effect_sizes'][metric_key]['cohens_d']\n",
    "                interpretation = rq4_analysis['effect_sizes'][metric_key]['interpretation']\n",
    "                print(f\"  Effect Size: Cohen's d = {cohens_d:.3f} ({interpretation})\")\n",
    "            \n",
    "            # Statistical tests\n",
    "            if metric_key in rq4_analysis['statistical_tests']:\n",
    "                mw_pval = rq4_analysis['statistical_tests'][metric_key]['mann_whitney']['p_value']\n",
    "                ks_pval = rq4_analysis['statistical_tests'][metric_key]['kolmogorov_smirnov']['p_value']\n",
    "                print(f\"  Mann-Whitney U p-value: {mw_pval:.6f}\")\n",
    "                print(f\"  Kolmogorov-Smirnov p-value: {ks_pval:.6f}\")\n",
    "            \n",
    "            # ROC AUC\n",
    "            if metric_key in rq4_analysis['roc_analysis']:\n",
    "                roc_auc = rq4_analysis['roc_analysis'][metric_key]['auc']\n",
    "                if roc_auc < 0.6:\n",
    "                    quality = 'Poor'\n",
    "                elif roc_auc < 0.7:\n",
    "                    quality = 'Fair'\n",
    "                elif roc_auc < 0.8:\n",
    "                    quality = 'Good'\n",
    "                elif roc_auc < 0.9:\n",
    "                    quality = 'Excellent'\n",
    "                else:\n",
    "                    quality = 'Outstanding'\n",
    "                print(f\"  AUC-ROC: {roc_auc:.3f} ({quality} separation)\")\n",
    "        \n",
    "        print(f\"\\n{'='*90}\")\n",
    "        print(\"‚úÖ RQ4 INTERPRETATION:\")\n",
    "        print(\"üéØ High AUC (> 0.7): Scoring metric can distinguish positive from negative samples\")\n",
    "        print(\"üéØ Low AUC (< 0.6): Scoring metric has poor discriminative power\")\n",
    "        print(\"üéØ Large effect size: Substantial difference in score distributions\")\n",
    "        print(\"üéØ Significant p-value: Distributions are statistically different\")\n",
    "        \n",
    "    # Reset matplotlib parameters\n",
    "    plt.rcdefaults()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "teachopencadd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
