#!/usr/bin/env python3
"""
Batch Consensus Docking Script - Main Workflow
This script performs the actual docking jobs using pre-generated mappings.
Only small molecule drugs are processed, as the docking workflow is optimized for small molecules.

Prerequisites:
    1. Run prepare_uniprot_mapping.py first to generate uniprot_gene_mapping.csv
    2. Run extract_cavities.py to generate cavity_mapping.csv
    3. Run identify_required_structures.py to identify required structures (RECOMMENDED)
    4. Run extract_alphafold_models.py to get full AlphaFold structures (RECOMMENDED)
    5. Run fix_required_pdbs.py to add hydrogens to required structures (RECOMMENDED)
    6. Optionally run convert_pdb_to_pdbqt.py for better performance
    7. Ensure all required paths and dependencies are correctly configured

Usage:
    python batch_dock.py

Input:
    - uniprot_gene_mapping.csv: UniProt mapping file (generated by prepare_uniprot_mapping.py)
    - cavity_mapping.csv: Cavity mapping file (generated by extract_cavities.py)
    - small_molecule_drug_links.csv: Small molecule drugs from DrugBank
    - fixed_mapping.csv: Fixed structures mapping file (preferred, generated by fix_required_pdbs.py)
    - alphafold_mapping.csv: AlphaFold mapping file (alternative, generated by extract_alphafold_models.py)
    - pdbqt_mapping.csv: PDBQT mapping file (optional, generated by convert_pdb_to_pdbqt.py)
    - Drug-to-protein interaction TSV file
    - Processed ligand SDF folder

Output:
    - Docking results in consensus_docking_results/ folder
    - Log file: docking_automation.log
"""

import os
import sys
import pandas as pd
import subprocess
import re
import time
import logging
import os
import sys
import pandas as pd
import subprocess
import re
import time
import logging
import glob
import multiprocessing
import signal
import psutil
import shutil
import threading
import queue
from collections import deque
from tqdm import tqdm
from pathlib import Path
from concurrent.futures import ProcessPoolExecutor, as_completed

# --- Configuration ---
# --- IMPORTANT: ADJUST THESE PATHS AS PER YOUR SYSTEM ---
CONSENSUS_DOCKER_SCRIPT = "/home/onur/repos/consensus_docking/consensus_docker.py"
PROCESSED_LIGAND_SDF_FOLDER = "/media/onur/Elements/cavity_space_consensus_docking/drugbank_approved_split" # The output folder from your RDKit 3D processing script
DRUG_TO_PROTEIN_TSV = "/opt/data/multiscale_interactome_data/1_drug_to_protein.tsv"
SMALL_MOLECULE_DRUGS_CSV = "/opt/data/drugbank/small_molecule_drug_links.csv"  # Small molecule drugs only
UNIPROT_MAPPING_CSV = "uniprot_gene_mapping.csv" # Input file from prepare_uniprot_mapping.py
CAVITY_MAPPING_CSV = "cavity_mapping.csv" # Input file from extract_cavities.py
FIXED_MAPPING_CSV = "fixed_mapping.csv" # Preferred input from fix_required_pdbs.py
ALPHAFOLD_MAPPING_CSV = "alphafold_mapping.csv" # Alternative input from extract_alphafold_models.py
PDBQT_MAPPING_CSV = "pdbqt_mapping.csv" # Input file from convert_pdb_to_pdbqt.py (optional)
LOG_FILE = "docking_automation.log"
# --- TEST MODE: Set to True to run only 3 docking jobs for testing ---
TEST_MODE = False
MAX_TEST_JOBS = 40
# --- CONFIRMATION PROMPT: Set to True to skip user confirmation when not in TEST_MODE ---
SKIP_CONFIRMATION = True  # Set to True for nohup/batch execution
# --- DOCKING TOOLS SELECTION ---
# Set to True to enable each docking tool, False to disable
USE_SMINA = True                # Enable/disable Smina docking
USE_GOLD = False                 # Enable/disable Gold docking  
USE_LEDOCK = False               # Enable/disable LeDock docking
USE_RMSD_CALCULATION = False     # Enable/disable final RMSD calculation

# --- ADAPTIVE EXHAUSTIVENESS AND UPDATE MODE ---
USE_ADAPTIVE_EXHAUSTIVENESS = True  # Use adaptive exhaustiveness for Smina (new feature)
UPDATE_SMINA_ONLY = True            # If True, only update Smina results, preserve Gold/LeDock
FORCE_RMSD_RECALCULATION = True     # If True, force RMSD recalculation even if final results exist

# --- DYNAMIC RESOURCE MANAGEMENT ---
# NEW: Real-time job submission based on CPU availability (no batching)
# Optimized for 64-core systems: submits jobs one-by-one when CPU < threshold
# Takes into account actual CPU cores used per job (exhaustiveness parameter)
ENABLE_DYNAMIC_RESOURCE_MANAGEMENT = True  # Enable adaptive parallelism based on system load
CPU_THRESHOLD = 60.0                       # Submit new jobs only when CPU < this % 
MEMORY_THRESHOLD = 85.0                    # Reduce parallelism if memory usage exceeds this %
RESOURCE_CHECK_INTERVAL = 2               # Check system resources every N seconds (faster for real-time)
MIN_PARALLEL_JOBS = 1                      # Minimum number of parallel jobs
MAX_PARALLEL_JOBS_ADAPTIVE = 4             # Conservative maximum (will be calculated based on exhaustiveness)
ADAPTIVE_SCALING_FACTOR = 0.8              # Factor to reduce jobs when resources are high

# --- THREE-STAGE DOCKING CONFIGURATION ---
# Stage 1: Smina only (high exhaustiveness = high CPU usage per job, low parallelism)
SMINA_MAX_PARALLEL_JOBS = 4     # Maximum parallel jobs for smina stage
SMINA_EXHAUSTIVENESS = 16       # High exhaustiveness for smina (CPU cores used per job)
SMINA_TIMEOUT = 3000           # Timeout for smina jobs in seconds (50 minutes)
# Stage 2: Gold (single-threaded, high parallelism possible)
GOLD_MAX_PARALLEL_JOBS = 60     # Maximum parallel jobs for gold stage
GOLD_EXHAUSTIVENESS = 12        # Kept for compatibility but ignored by Gold (single-threaded)
GOLD_TIMEOUT = 600              # Timeout for gold jobs in seconds (10 minutes)
# Stage 3: LeDock (single-threaded, high parallelism possible)
LEDOCK_MAX_PARALLEL_JOBS = 60   # Maximum parallel jobs for ledock stage
LEDOCK_EXHAUSTIVENESS = 12      # Kept for compatibility but ignored by LeDock (single-threaded)
LEDOCK_TIMEOUT = 600            # Timeout for ledock jobs in seconds (10 minutes)
# Stage 4: RMSD calculation (if all tools completed but final results missing)
RMSD_MAX_PARALLEL_JOBS = 60     # Maximum parallel jobs for RMSD calculation
RMSD_TIMEOUT = 3000              # Timeout for RMSD calculation in seconds (50 minutes)
# --- Consensus Docker Fixed Arguments (from your example) ---
SMINA_PATH = "/opt/anaconda3/envs/teachopencadd/bin/smina"
LEDOCK_PATH = "/home/onur/software/ledock_linux_x86"
LEPRO_PATH = "/home/onur/software/lepro_linux_x86"
GOLD_PATH = "/opt/goldsuite-5.3.0/bin/gold_auto"
NUM_THREADS = 60
CUTOFF_VALUE = -7

# Set up logging
logging.basicConfig(filename=LOG_FILE, level=logging.DEBUG,
                    format='%(asctime)s - %(levelname)s - %(message)s')
console_handler = logging.StreamHandler(sys.stdout)
console_handler.setLevel(logging.DEBUG)
formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
console_handler.setFormatter(formatter)
logging.getLogger().addHandler(console_handler)

logging.info("Starting batch consensus docking workflow.")
if TEST_MODE:
    logging.info(f"*** RUNNING IN TEST MODE - LIMITED TO {MAX_TEST_JOBS} DOCKING JOBS ***")
else:
    logging.info("*** RUNNING IN PRODUCTION MODE ***")
if SKIP_CONFIRMATION:
    logging.info("*** SKIP_CONFIRMATION ENABLED - NO USER PROMPT REQUIRED ***")

# Log which tools are enabled
enabled_tools = []
if USE_SMINA:
    enabled_tools.append("SMINA")
if USE_GOLD:
    enabled_tools.append("GOLD")
if USE_LEDOCK:
    enabled_tools.append("LEDOCK")
if USE_RMSD_CALCULATION:
    enabled_tools.append("RMSD")

logging.info(f"*** ENABLED DOCKING TOOLS: {', '.join(enabled_tools) if enabled_tools else 'NONE'} ***")

if USE_SMINA:
    logging.info(f"*** STAGE 1: SMINA - UP TO {SMINA_MAX_PARALLEL_JOBS} CONCURRENT JOBS, EXHAUSTIVENESS {SMINA_EXHAUSTIVENESS}, TIMEOUT {SMINA_TIMEOUT/60:.1f} MINUTES ***")
else:
    logging.info("*** STAGE 1: SMINA - DISABLED ***")

if USE_GOLD:
    logging.info(f"*** STAGE 2: GOLD - UP TO {GOLD_MAX_PARALLEL_JOBS} CONCURRENT JOBS, EXHAUSTIVENESS {GOLD_EXHAUSTIVENESS}, TIMEOUT {GOLD_TIMEOUT/60:.1f} MINUTES ***")
else:
    logging.info("*** STAGE 2: GOLD - DISABLED ***")

if USE_LEDOCK:
    logging.info(f"*** STAGE 3: LEDOCK - UP TO {LEDOCK_MAX_PARALLEL_JOBS} CONCURRENT JOBS, EXHAUSTIVENESS {LEDOCK_EXHAUSTIVENESS}, TIMEOUT {LEDOCK_TIMEOUT/60:.1f} MINUTES ***")
else:
    logging.info("*** STAGE 3: LEDOCK - DISABLED ***")

if USE_RMSD_CALCULATION:
    logging.info(f"*** STAGE 4: RMSD CALCULATION - UP TO {RMSD_MAX_PARALLEL_JOBS} CONCURRENT JOBS, TIMEOUT {RMSD_TIMEOUT/60:.1f} MINUTES ***")
else:
    logging.info("*** STAGE 4: RMSD CALCULATION - DISABLED ***")
logging.info(f"Consensus Docker Script: {CONSENSUS_DOCKER_SCRIPT}")
logging.info(f"Processed Ligand SDF Folder: {PROCESSED_LIGAND_SDF_FOLDER}")
logging.info(f"Drug-to-Protein TSV: {DRUG_TO_PROTEIN_TSV}")
logging.info(f"UniProt Mapping CSV: {UNIPROT_MAPPING_CSV}")
logging.info(f"Cavity Mapping CSV: {CAVITY_MAPPING_CSV}")
logging.info(f"PDBQT Mapping CSV: {PDBQT_MAPPING_CSV}")
if os.path.exists(PDBQT_MAPPING_CSV):
    logging.info("PDBQT mapping found - will use pre-converted PDBQT files for faster docking")
else:
    logging.info("PDBQT mapping not found - will use PDB files (slower conversion during docking)")

# Log configuration at startup
logging.info("=== BATCH DOCK CONFIGURATION ===")
logging.info(f"USE_SMINA: {USE_SMINA}")
logging.info(f"USE_GOLD: {USE_GOLD}")
logging.info(f"USE_LEDOCK: {USE_LEDOCK}")
logging.info(f"USE_RMSD_CALCULATION: {USE_RMSD_CALCULATION}")
if not USE_RMSD_CALCULATION:
    logging.info("*** RMSD CALCULATION DISABLED - Using --skip_rmsd flag for all docking tools ***")
logging.info(f"USE_ADAPTIVE_EXHAUSTIVENESS: {USE_ADAPTIVE_EXHAUSTIVENESS}")
logging.info(f"UPDATE_SMINA_ONLY: {UPDATE_SMINA_ONLY}")
logging.info(f"FORCE_RMSD_RECALCULATION: {FORCE_RMSD_RECALCULATION}")
logging.info(f"TEST_MODE: {TEST_MODE}")
logging.info(f"SKIP_CONFIRMATION: {SKIP_CONFIRMATION}")
logging.info("=" * 35)

# Validate that at least one tool is enabled
if not any([USE_SMINA, USE_GOLD, USE_LEDOCK]):
    logging.warning("WARNING: No docking tools are enabled! At least one of USE_SMINA, USE_GOLD, or USE_LEDOCK should be True.")
    if not USE_RMSD_CALCULATION:
        logging.error("ERROR: No tools are enabled at all. Please enable at least one docking tool or RMSD calculation.")
        sys.exit(1)

class ResourceMonitor:
    """Monitors system resources and provides recommendations for parallel job execution."""
    
    def __init__(self, cpu_threshold=85.0, memory_threshold=85.0, check_interval=10):
        self.cpu_threshold = cpu_threshold
        self.memory_threshold = memory_threshold
        self.check_interval = check_interval
        self.cpu_history = deque(maxlen=5)  # Keep last 5 measurements
        self.memory_history = deque(maxlen=5)
        self.monitoring = False
        self.monitor_thread = None
        self.resource_queue = queue.Queue()
        
    def start_monitoring(self):
        """Start background resource monitoring."""
        if not self.monitoring:
            self.monitoring = True
            self.monitor_thread = threading.Thread(target=self._monitor_loop, daemon=True)
            self.monitor_thread.start()
            logging.info("Resource monitoring started")
    
    def stop_monitoring(self):
        """Stop background resource monitoring."""
        self.monitoring = False
        if self.monitor_thread and self.monitor_thread.is_alive():
            self.monitor_thread.join(timeout=5)
        logging.info("Resource monitoring stopped")
    
    def _monitor_loop(self):
        """Background monitoring loop."""
        while self.monitoring:
            try:
                cpu_percent = psutil.cpu_percent(interval=1)
                memory_percent = psutil.virtual_memory().percent
                
                self.cpu_history.append(cpu_percent)
                self.memory_history.append(memory_percent)
                
                # Put current stats in queue for main thread
                self.resource_queue.put({
                    'cpu': cpu_percent,
                    'memory': memory_percent,
                    'timestamp': time.time()
                })
                
                time.sleep(self.check_interval)
            except Exception as e:
                logging.warning(f"Resource monitoring error: {e}")
                time.sleep(self.check_interval)
    
    def get_current_usage(self):
        """Get current resource usage."""
        return {
            'cpu': psutil.cpu_percent(interval=0.1),
            'memory': psutil.virtual_memory().percent
        }
    
    def get_average_usage(self):
        """Get average resource usage from recent history."""
        if not self.cpu_history or not self.memory_history:
            return self.get_current_usage()
        
        return {
            'cpu': sum(self.cpu_history) / len(self.cpu_history),
            'memory': sum(self.memory_history) / len(self.memory_history)
        }
    
    def recommend_workers(self, current_workers, min_workers=1, max_workers=None, scaling_factor=0.7):
        """
        Recommend number of workers based on current resource usage.
        
        Args:
            current_workers: Current number of active workers
            min_workers: Minimum workers to maintain
            max_workers: Maximum workers allowed
            scaling_factor: Factor for scaling adjustments
        
        Returns:
            Recommended number of workers
        """
        if max_workers is None:
            max_workers = multiprocessing.cpu_count()
        
        usage = self.get_average_usage()
        cpu_usage = usage['cpu']
        memory_usage = usage['memory']
        
        # Determine if we should scale up or down
        if cpu_usage > self.cpu_threshold or memory_usage > self.memory_threshold:
            # High resource usage - scale down
            new_workers = max(min_workers, int(current_workers * scaling_factor))
            action = "scale_down"
            reason = f"High usage: CPU={cpu_usage:.1f}%, Memory={memory_usage:.1f}%"
        elif cpu_usage < self.cpu_threshold * 0.6 and memory_usage < self.memory_threshold * 0.6:
            # Low resource usage - consider scaling up
            new_workers = min(max_workers, current_workers + 1)
            action = "scale_up"
            reason = f"Low usage: CPU={cpu_usage:.1f}%, Memory={memory_usage:.1f}%"
        else:
            # Moderate usage - maintain current level
            new_workers = current_workers
            action = "maintain"
            reason = f"Moderate usage: CPU={cpu_usage:.1f}%, Memory={memory_usage:.1f}%"
        
        return {
            'recommended_workers': new_workers,
            'current_workers': current_workers,
            'action': action,
            'reason': reason,
            'cpu_usage': cpu_usage,
            'memory_usage': memory_usage
        }


def log_resource_usage():
    """Log current system resource usage."""
    try:
        cpu_percent = psutil.cpu_percent(interval=0.1)
        memory = psutil.virtual_memory()
        disk = psutil.disk_usage('/')
        
        logging.info(f"System Resources - CPU: {cpu_percent:.1f}%, "
                    f"Memory: {memory.percent:.1f}% ({memory.used/1024**3:.1f}GB/"
                    f"{memory.total/1024**3:.1f}GB), "
                    f"Disk: {disk.percent:.1f}%")
    except Exception as e:
        logging.warning(f"Could not log resource usage: {e}")


def init_worker():
    """Initialize worker process for multiprocessing pools."""
    signal.signal(signal.SIGINT, signal.SIG_IGN)


def load_uniprot_mapping(mapping_file):
    """
    Load pre-generated UniProt mapping from CSV file.
    
    Args:
        mapping_file (str): Path to the UniProt mapping CSV file
        
    Returns:
        pd.DataFrame: DataFrame with UniProt mapping data
    """
    if not os.path.exists(mapping_file):
        logging.critical(f"UniProt mapping file not found: {mapping_file}")
        logging.critical("Please run prepare_uniprot_mapping.py first to generate the mapping file.")
        sys.exit(1)
    
    try:
        df = pd.read_csv(mapping_file)
        required_columns = ['Entry', 'Mapped_Gene_Name']
        missing_columns = [col for col in required_columns if col not in df.columns]
        
        if missing_columns:
            logging.critical(f"Required columns missing from mapping file: {missing_columns}")
            logging.critical("Please regenerate the mapping file using prepare_uniprot_mapping.py")
            sys.exit(1)
        
        logging.info(f"Loaded UniProt mapping with {len(df)} entries from {mapping_file}")
        return df[['Entry', 'Mapped_Gene_Name']]
        
    except Exception as e:
        logging.critical(f"Error loading UniProt mapping file: {e}")
        sys.exit(1)

def load_small_molecule_drugs():
    """
    Load small molecule drugs list from DrugBank.
    
    Returns:
        set: Set of small molecule drug IDs
    """
    if not os.path.exists(SMALL_MOLECULE_DRUGS_CSV):
        logging.critical(f"Small molecule drugs CSV not found: {SMALL_MOLECULE_DRUGS_CSV}")
        sys.exit(1)
    
    try:
        df = pd.read_csv(SMALL_MOLECULE_DRUGS_CSV)
        small_molecule_ids = set(df['DrugBank ID'].unique())
        logging.info(f"Loaded {len(small_molecule_ids)} small molecule drug IDs")
        return small_molecule_ids
    except Exception as e:
        logging.critical(f"Error loading small molecule drugs: {e}")
        sys.exit(1)

def load_best_mapping_with_pdbqt():
    """
    Load the best available mapping file with PDBQT paths.
    Prioritizes fixed PDB mapping, then AlphaFold mapping, then original cavity mapping.
    
    Returns
    -------
    dict: Dictionary mapping UniProt IDs to lists of (receptor_pdb, pocket_pdb, receptor_pdbqt) tuples
    str: Source file used
    """
    # Define priority order
    mapping_files = [
        (FIXED_MAPPING_CSV, "fixed structures mapping"),
        (ALPHAFOLD_MAPPING_CSV, "AlphaFold mapping"),
        (CAVITY_MAPPING_CSV, "original cavity mapping")
    ]
    
    mapping_file = None
    mapping_type = None
    
    # Find the best available mapping file
    for file_path, file_type in mapping_files:
        if os.path.exists(file_path):
            mapping_file = file_path
            mapping_type = file_type
            logging.info(f"Using {mapping_type}: {mapping_file}")
            break
    
    if not mapping_file:
        logging.critical("No mapping file found!")
        logging.critical("Please run extract_cavities.py and fix_required_pdbs.py first.")
        sys.exit(1)
    
    # Load the mapping with PDBQT support
    pdbqt_file = PDBQT_MAPPING_CSV if os.path.exists(PDBQT_MAPPING_CSV) else None
    mapping_dict = load_cavity_mapping(mapping_file, pdbqt_file)
    
    return mapping_dict, mapping_file

def load_cavity_mapping(mapping_file, pdbqt_mapping_file=None):
    """
    Load cavity mapping from a pre-generated CSV file, optionally with PDBQT paths.
    
    Args:
        mapping_file (str): Path to the cavity mapping CSV file
        pdbqt_mapping_file (str, optional): Path to the PDBQT mapping CSV file
        
    Returns:
        dict: Dictionary mapping UniProt IDs to lists of (receptor_pdb, pocket_pdb, receptor_pdbqt) tuples
    """
    if not os.path.exists(mapping_file):
        logging.critical(f"Cavity mapping file not found: {mapping_file}")
        logging.critical("Please run extract_cavities.py first to generate the cavity mapping file.")
        sys.exit(1)
    
    try:
        df = pd.read_csv(mapping_file)
        required_columns = ['UniProt_ID', 'Receptor_PDB', 'Pocket_PDB']
        missing_columns = [col for col in required_columns if col not in df.columns]
        
        if missing_columns:
            logging.critical(f"Required columns missing from cavity mapping file: {missing_columns}")
            logging.critical("Please regenerate the cavity mapping file using extract_cavities.py")
            sys.exit(1)
        
        # Load PDBQT mapping if available
        pdbqt_mapping = {}
        if pdbqt_mapping_file and os.path.exists(pdbqt_mapping_file):
            logging.info(f"Loading PDBQT mapping from {pdbqt_mapping_file}")
            try:
                pdbqt_df = pd.read_csv(pdbqt_mapping_file)
                if 'Receptor_PDB' in pdbqt_df.columns and 'Receptor_PDBQT' in pdbqt_df.columns:
                    # Create mapping from PDB path to PDBQT path
                    pdbqt_mapping = dict(zip(pdbqt_df['Receptor_PDB'], pdbqt_df['Receptor_PDBQT']))
                    logging.info(f"Loaded {len(pdbqt_mapping)} PDBQT mappings")
                else:
                    logging.warning("PDBQT mapping file missing required columns, ignoring PDBQT files")
            except Exception as e:
                logging.warning(f"Error loading PDBQT mapping: {e}. Continuing without PDBQT files.")
        
        pdb_info = {}
        for _, row in df.iterrows():
            uniprot_id = row['UniProt_ID']
            receptor_pdb = row['Receptor_PDB']
            pocket_pdb = row['Pocket_PDB']
            
            # Verify that the files still exist
            if not os.path.exists(receptor_pdb):
                logging.warning(f"Receptor PDB file not found: {receptor_pdb}")
                continue
            if not os.path.exists(pocket_pdb):
                logging.warning(f"Pocket PDB file not found: {pocket_pdb}")
                continue
            
            # Get corresponding PDBQT file if available
            receptor_pdbqt = pdbqt_mapping.get(receptor_pdb)
            if receptor_pdbqt and not os.path.exists(receptor_pdbqt):
                logging.warning(f"PDBQT file not found: {receptor_pdbqt}, will use PDB file")
                receptor_pdbqt = None
            
            if uniprot_id not in pdb_info:
                pdb_info[uniprot_id] = []
            pdb_info[uniprot_id].append((receptor_pdb, pocket_pdb, receptor_pdbqt))
        
        total_pairs = sum(len(pairs) for pairs in pdb_info.values())
        pdbqt_pairs = sum(1 for pairs in pdb_info.values() for _, _, pdbqt in pairs if pdbqt)
        
        logging.info(f"Loaded cavity mapping for {len(pdb_info)} UniProt IDs with {total_pairs} cavity pairs from {mapping_file}")
        logging.info(f"Found {pdbqt_pairs} cavity pairs with pre-converted PDBQT files")
        
        # Debug: Show some sample UniProt IDs for debugging
        sample_ids = list(pdb_info.keys())[:5]
        logging.info(f"Sample UniProt IDs in cavity mapping: {sample_ids}")
        
        return pdb_info
        
    except Exception as e:
        logging.critical(f"Error loading cavity mapping file: {e}")
        sys.exit(1)

def run_stage_jobs_adaptive(stage_name, jobs, job_function, resource_monitor=None):
    """
    Run jobs with real-time adaptive parallelism based on CPU availability.
    Submits jobs one-by-one when CPU capacity is available, accounting for exhaustiveness.
    
    Args:
        stage_name: Name of the docking stage
        jobs: List of jobs to execute
        job_function: Function to execute each job
        resource_monitor: ResourceMonitor instance for adaptive scaling
    
    Returns:
        Statistics dictionary compatible with run_stage_jobs
    """
    if not ENABLE_DYNAMIC_RESOURCE_MANAGEMENT or resource_monitor is None:
        # Fall back to legacy function with proper parameters
        return run_stage_jobs(
            job_data_list=jobs,
            stage_name=stage_name,
            job_function=job_function,
            max_workers=SMINA_MAX_PARALLEL_JOBS,
            timeout=SMINA_TIMEOUT,
            exhaustiveness=SMINA_EXHAUSTIVENESS
        )
    
    # Determine CPU cores per job based on stage configuration
    total_cpu_cores = 64  # Your system has 64 cores
    if "smina" in stage_name.lower():
        cores_per_job = SMINA_EXHAUSTIVENESS if not USE_ADAPTIVE_EXHAUSTIVENESS else 16  # Conservative estimate for adaptive
        timeout = SMINA_TIMEOUT
        exhaustiveness = SMINA_EXHAUSTIVENESS
    elif "gold" in stage_name.lower():
        cores_per_job = 1  # Gold is single-threaded, uses 1 CPU core per job
        timeout = GOLD_TIMEOUT
        exhaustiveness = GOLD_EXHAUSTIVENESS  # Will be ignored by Gold, but kept for compatibility
    elif "ledock" in stage_name.lower():
        cores_per_job = 1  # LeDock is single-threaded, uses 1 CPU core per job  
        timeout = LEDOCK_TIMEOUT
        exhaustiveness = LEDOCK_EXHAUSTIVENESS  # Will be ignored by LeDock, but kept for compatibility
    else:
        cores_per_job = 1  # Default for single-threaded tools
        timeout = 600
        exhaustiveness = 8
    
    # Calculate theoretical maximum concurrent jobs based on CPU cores
    theoretical_max_jobs = max(1, total_cpu_cores // cores_per_job)
    # Be conservative - use 75% of theoretical maximum
    safe_max_jobs = max(1, int(theoretical_max_jobs * 0.75))
    
    logging.info(f"Starting real-time adaptive execution for {stage_name} with {len(jobs)} jobs")
    if "smina" in stage_name.lower():
        logging.info(f"Smina cores per job: {cores_per_job} (exhaustiveness={SMINA_EXHAUSTIVENESS}), Theoretical max concurrent: {theoretical_max_jobs}, Safe max: {safe_max_jobs}")
    else:
        logging.info(f"Estimated cores per job: {cores_per_job} (exhaustiveness not applicable), Theoretical max concurrent: {theoretical_max_jobs}, Safe max: {safe_max_jobs}")
    logging.info(f"Target CPU utilization: Keep below {CPU_THRESHOLD}%")
    
    resource_monitor.start_monitoring()
    
    try:
        from concurrent.futures import ThreadPoolExecutor, as_completed
        
        total_jobs = len(jobs)
        remaining_jobs = jobs.copy()
        completed_jobs = 0
        failed_jobs = 0
        skipped_jobs = 0
        timeout_jobs = 0
        stage_start_time = time.time()
        
        # Track active jobs with a ThreadPoolExecutor for non-blocking submission
        active_futures = {}  # future -> job_data mapping
        last_resource_check = time.time()
        resource_check_interval = 3.0  # Check every 3 seconds
        last_submission_time = 0
        min_submission_interval = 5.0  # Wait at least 5 seconds between submissions
        
        # Initial resource check
        log_resource_usage()
        
        with ThreadPoolExecutor(max_workers=safe_max_jobs) as executor:
            while remaining_jobs or active_futures:
                current_time = time.time()
                
                # Check if we should submit new jobs based on CPU availability
                if (remaining_jobs and 
                    current_time - last_resource_check >= resource_check_interval and
                    current_time - last_submission_time >= min_submission_interval):
                    
                    cpu_usage = psutil.cpu_percent(interval=1.0)  # Longer interval for more stable reading
                    memory_usage = psutil.virtual_memory().percent
                    current_active = len(active_futures)
                    
                    # Calculate estimated CPU usage if we add one more job
                    estimated_cores_used = current_active * cores_per_job
                    additional_cores_needed = cores_per_job
                    total_estimated_cores = estimated_cores_used + additional_cores_needed
                    estimated_cpu_usage_if_submit = (total_estimated_cores / total_cpu_cores) * 100
                    
                    # Conservative submission criteria:
                    # 1. Current CPU usage is below threshold
                    # 2. Adding one more job won't exceed theoretical capacity
                    # 3. Memory usage is acceptable
                    # 4. We haven't exceeded our safe maximum
                    can_submit = (
                        cpu_usage < CPU_THRESHOLD and 
                        memory_usage < MEMORY_THRESHOLD and 
                        current_active < safe_max_jobs and
                        estimated_cpu_usage_if_submit < 90 and  # Don't exceed 90% theoretical usage
                        total_estimated_cores <= total_cpu_cores
                    )
                    
                    if can_submit:
                        # Submit a new job
                        job_data = remaining_jobs.pop(0)
                        
                        # Add timeout and exhaustiveness to job data
                        job_data_copy = job_data.copy()
                        job_data_copy['timeout'] = timeout
                        job_data_copy['exhaustiveness'] = exhaustiveness
                        
                        future = executor.submit(job_function, job_data_copy)
                        active_futures[future] = job_data
                        last_submission_time = current_time
                        
                        logging.info(f"Submitted job {job_data['job_idx']}: "
                                   f"CPU={cpu_usage:.1f}%, Active={current_active+1}/{safe_max_jobs}, "
                                   f"Est.cores={total_estimated_cores}/{total_cpu_cores}, "
                                   f"Remaining={len(remaining_jobs)}")
                    else:
                        # Log why we can't submit
                        if cpu_usage >= CPU_THRESHOLD:
                            reason = f"CPU too high ({cpu_usage:.1f}% >= {CPU_THRESHOLD}%)"
                        elif current_active >= safe_max_jobs:
                            reason = f"At max concurrent jobs ({current_active}/{safe_max_jobs})"
                        elif estimated_cpu_usage_if_submit >= 90:
                            reason = f"Would exceed CPU capacity ({estimated_cpu_usage_if_submit:.1f}%)"
                        else:
                            reason = f"Memory too high ({memory_usage:.1f}%)"
                        
                        if current_time - last_resource_check >= 30:  # Log every 30 seconds when waiting
                            logging.info(f"Waiting to submit: {reason}. Active: {current_active}, "
                                       f"CPU: {cpu_usage:.1f}%, Est.cores: {estimated_cores_used}/{total_cpu_cores}")
                    
                    last_resource_check = current_time
                
                # Process completed jobs (non-blocking)
                completed_futures = []
                for future in active_futures:
                    if future.done():
                        completed_futures.append(future)
                
                for future in completed_futures:
                    job_data = active_futures.pop(future)
                    try:
                        result = future.result()
                        if result['success']:
                            if result['action'] == 'skipped':
                                skipped_jobs += 1
                            else:
                                completed_jobs += 1
                        else:
                            if result['action'] == 'timeout':
                                timeout_jobs += 1
                            else:
                                failed_jobs += 1
                        
                        # Log progress every 5 completed jobs
                        total_processed = completed_jobs + failed_jobs + skipped_jobs + timeout_jobs
                        if total_processed % 5 == 0:
                            progress_pct = (total_processed / total_jobs) * 100
                            logging.info(f"{stage_name} progress: {total_processed}/{total_jobs} "
                                       f"({progress_pct:.1f}%) - Active: {len(active_futures)}")
                            log_resource_usage()
                        
                    except Exception as e:
                        failed_jobs += 1
                        logging.error(f"Job {job_data['job_idx']} failed with exception: {e}")
                
                # Small sleep to prevent busy waiting
                time.sleep(0.5)
        
        stage_elapsed_time = time.time() - stage_start_time
        total_processed = completed_jobs + failed_jobs + skipped_jobs + timeout_jobs
        
        logging.info(f"Real-time adaptive {stage_name} completed in {stage_elapsed_time/60:.1f} minutes:")
        logging.info(f"  Completed: {completed_jobs}, Failed: {failed_jobs}, "
                    f"Skipped: {skipped_jobs}, Timeout: {timeout_jobs}")
        logging.info(f"  Total processed: {total_processed}/{total_jobs}")
        
        # Return stats in expected format for compatibility
        return {
            'completed': completed_jobs,
            'failed': failed_jobs,
            'skipped': skipped_jobs,
            'timeout': timeout_jobs,
            'elapsed_time': stage_elapsed_time,
            'unique_processes': safe_max_jobs
        }
        
    finally:
        resource_monitor.stop_monitoring()


def clean_smina_results_only(output_folder):
    """
    Clean only Smina results and final results from an output folder,
    preserving Gold and LeDock results.
    
    Args:
        output_folder (str): Path to the docking output folder
        
    Returns:
        bool: True if cleaning was successful, False otherwise
    """
    try:
        # Remove Smina subfolder if it exists
        smina_folder = os.path.join(output_folder, 'smina')
        if os.path.exists(smina_folder):
            shutil.rmtree(smina_folder)
            logging.debug(f"Removed Smina results folder: {smina_folder}")
        
        # Remove final results file to force recalculation
        final_results_file = os.path.join(output_folder, 'final_results.csv')
        if os.path.exists(final_results_file):
            os.remove(final_results_file)
            logging.debug(f"Removed final results file: {final_results_file}")
        
        # Also remove any other final result variants
        for filename in ['results.csv', 'consensus_results.csv']:
            file_path = os.path.join(output_folder, filename)
            if os.path.exists(file_path):
                os.remove(file_path)
                logging.debug(f"Removed results file: {file_path}")
        
        return True
        
    except Exception as e:
        logging.warning(f"Error cleaning Smina results from {output_folder}: {e}")
        return False

def check_tool_completion(output_folder, tool_name):
    """
    Check if a specific docking tool has completed successfully.
    
    Args:
        output_folder (str): Path to the docking output folder
        tool_name (str): Name of the tool ('smina', 'gold', 'ledock')
        
    Returns:
        bool: True if the tool has completed with valid results, False otherwise
    """
    # Convert to absolute path if not already
    output_folder = os.path.abspath(output_folder)
    
    if not os.path.exists(output_folder):
        logging.info(f"Output folder does not exist: {output_folder}")
        return False
    
    # Check if tool subfolder exists
    tool_folder = os.path.join(output_folder, tool_name)
    if not os.path.exists(tool_folder):
        logging.info(f"Tool subfolder does not exist: {tool_folder}")
        return False
        
    # Check for tool-specific results file
    results_file = os.path.join(tool_folder, "results.csv")
    if os.path.exists(results_file):
        logging.info(f"Found results file for {tool_name}: {results_file}")
        # Attempt to read the header line to verify it's a valid CSV
        try:
            with open(results_file, 'r') as f:
                header = f.readline().strip()
                # Just check if the header exists and appears to be a CSV
                if header and ',' in header:
                    logging.info(f"Results file contains CSV data with header: {header[:50]}...")
                    return True
                else:
                    # Even if the file doesn't have a proper header, if it exists we'll consider it complete
                    # This handles cases where valid docking runs produced minimal or no results
                    logging.info(f"Results file exists but may not have a typical CSV header. Considering job complete anyway.")
                    return True
        except Exception as e:
            logging.warning(f"Error reading results file: {e}")
            # If we can't read the file for some reason, still consider it complete
            # This is more permissive than before, preventing unnecessary re-runs
            logging.info(f"Considering job complete despite error reading file")
            return True
    else:
        logging.info(f"Results file not found: {results_file}")
        return False

def check_final_results_completion(output_folder):
    """
    Check if final consensus results with RMSD calculations are complete.
    
    Args:
        output_folder (str): Path to the docking output folder
        
    Returns:
        bool: True if final results are complete, False otherwise
    """
    if not os.path.exists(output_folder):
        return False
    
    # Check for final results file with RMSD data
    final_results_file = os.path.join(output_folder, "final_results.csv")
    if os.path.exists(final_results_file) and os.path.getsize(final_results_file) > 200:
        # Verify that the file contains RMSD data
        try:
            with open(final_results_file, 'r') as f:
                header = f.readline().strip()
                if 'rmsd' in header.lower() or 'consensus' in header.lower():
                    return True
        except:
            pass
    
    return False

def get_job_completion_status(output_folder):
    """
    Get the completion status of all docking tools and final results.
    
    Args:
        output_folder (str): Path to the docking output folder
        
    Returns:
        dict: Dictionary with completion status for each tool and final results
    """
    return {
        'smina': check_tool_completion(output_folder, 'smina'),
        'gold': check_tool_completion(output_folder, 'gold'),
        'ledock': check_tool_completion(output_folder, 'ledock'),
        'final_results': check_final_results_completion(output_folder)
    }

# --- NOTE: Cavity extraction is now handled by extract_cavities.py ---
# Run extract_cavities.py first to generate cavity_mapping.csv before running this script

def run_command_with_timeout(command, timeout_seconds, cwd=None):
    """
    Run a command with proper timeout handling that kills all child processes.
    
    Parameters
    ----------
    command : list
        Command to run as a list of strings
    timeout_seconds : int
        Timeout in seconds
    cwd : str, optional
        Working directory
        
    Returns
    -------
    tuple
        (success, returncode, stdout, stderr, timed_out)
    """
    import signal
    import psutil
    
    def kill_process_tree(proc):
        """Kill a process and all its children"""
        try:
            # Get all child processes
            children = []
            if hasattr(proc, 'pid'):
                try:
                    parent = psutil.Process(proc.pid)
                    children = parent.children(recursive=True)
                except (psutil.NoSuchProcess, psutil.AccessDenied):
                    pass
            
            # Kill children first
            for child in children:
                try:
                    child.terminate()
                except (psutil.NoSuchProcess, psutil.AccessDenied):
                    pass
            
            # Wait for children to terminate
            gone, still_alive = psutil.wait_procs(children, timeout=5)
            
            # Force kill any remaining children
            for child in still_alive:
                try:
                    child.kill()
                except (psutil.NoSuchProcess, psutil.AccessDenied):
                    pass
            
            # Kill the parent process
            if hasattr(proc, 'pid'):
                try:
                    proc.terminate()
                    proc.wait(timeout=5)
                except (subprocess.TimeoutExpired, psutil.NoSuchProcess):
                    try:
                        proc.kill()
                    except (psutil.NoSuchProcess, psutil.AccessDenied):
                        pass
                        
        except Exception as e:
            logging.warning(f"Error killing process tree: {e}")
    
    proc = None
    try:
        # Start the process with a new process group
        proc = subprocess.Popen(
            command,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
            cwd=cwd,
            preexec_fn=os.setsid if hasattr(os, 'setsid') else None
        )
        
        # Wait for completion with timeout
        try:
            stdout, stderr = proc.communicate(timeout=timeout_seconds)
            return True, proc.returncode, stdout, stderr, False
        except subprocess.TimeoutExpired:
            # Process timed out, kill it and all children
            logging.warning(f"Command timed out after {timeout_seconds} seconds, killing process tree...")
            kill_process_tree(proc)
            return False, -1, "", f"Process timed out after {timeout_seconds} seconds", True
            
    except Exception as e:
        if proc:
            kill_process_tree(proc)
        return False, -1, "", f"Error running command: {e}", False

def run_single_smina_job(job_data):
    """
    Run a single smina docking job - Stage 1 of three-stage docking.
    
    Parameters
    ----------
    job_data : dict
        Dictionary containing all job parameters
        
    Returns
    -------
    dict
        Results of the smina docking job
    """
    # Extract job parameters
    job_idx = job_data['job_idx']
    drugbank_id = job_data['drugbank_id']
    uniprot_id = job_data['uniprot_id']
    gene_name = job_data['gene_name']
    ligand_sdf = job_data['ligand_sdf']
    receptor_pdb = job_data['receptor_pdb']
    receptor_pdbqt = job_data['receptor_pdbqt']
    pocket_pdb = job_data['pocket_pdb']
    current_outfolder = job_data['current_outfolder']
    
    # Get configuration from job_data
    CONSENSUS_DOCKER_SCRIPT = job_data['consensus_docker_script']
    SMINA_PATH = job_data['smina_path']
    NUM_THREADS = job_data['num_threads']
    CUTOFF_VALUE = job_data['cutoff_value']
    EXHAUSTIVENESS = job_data.get('exhaustiveness', 8)  # Default to 8 if not set
    USE_ADAPTIVE_EXHAUSTIVENESS = job_data.get('use_adaptive_exhaustiveness', False)
    UPDATE_SMINA_ONLY = job_data.get('update_smina_only', False)
    
    process_id = os.getpid()
    
    try:
        # If UPDATE_SMINA_ONLY mode, clean existing Smina results first
        if UPDATE_SMINA_ONLY:
            clean_smina_results_only(current_outfolder)
            logging.info(f"Job {job_idx}: Cleaned existing Smina results for update mode")
        
        # Check if smina output already exists (after potential cleaning)
        smina_completion = check_tool_completion(current_outfolder, 'smina')
        logging.info(f"Job {job_idx}: Smina completion check: {smina_completion} for {current_outfolder}")
        if smina_completion and not UPDATE_SMINA_ONLY:
            return {
                'success': True,
                'job_idx': job_idx,
                'drugbank_id': drugbank_id,
                'uniprot_id': uniprot_id,
                'gene_name': gene_name,
                'pocket_pdb': pocket_pdb,
                'current_outfolder': current_outfolder,
                'action': 'skipped',
                'message': 'Smina job already completed with valid output',
                'process_id': process_id
            }
        
        # Build the smina-only command
        command = [
            "python", CONSENSUS_DOCKER_SCRIPT,
            "--use_smina",
            "--overwrite",  # Allow writing to existing directory
            "--outfolder", current_outfolder,
            "--smina_path", SMINA_PATH,
            "--ligand_sdf", ligand_sdf,
            "--receptor_pdb", receptor_pdb,
            "--pocket_pdb", pocket_pdb,
            "--num_threads", str(NUM_THREADS),
            "--cutoff_value", str(CUTOFF_VALUE)
        ]
        
        # Skip RMSD calculation if USE_RMSD_CALCULATION is False
        if not job_data.get('use_rmsd_calculation', True):
            command.append("--skip_rmsd")
        
        # Add adaptive exhaustiveness or regular exhaustiveness
        if USE_ADAPTIVE_EXHAUSTIVENESS:
            command.append("--adaptive_exhaustiveness")
            logging.debug(f"Job {job_idx}: Using adaptive exhaustiveness for Smina")
        else:
            command.extend(["--exhaustiveness", str(EXHAUSTIVENESS)])
            logging.debug(f"Job {job_idx}: Using fixed exhaustiveness {EXHAUSTIVENESS} for Smina")
        
        # Add PDBQT file if available for faster processing
        if receptor_pdbqt and os.path.exists(receptor_pdbqt):
            command.extend(["--receptor_pdbqt", receptor_pdbqt])
        
        # Run the command with timeout
        timeout_seconds = job_data.get('timeout', 600)  # Default 10 minutes
        success, returncode, stdout, stderr, timed_out = run_command_with_timeout(
            command, timeout_seconds
        )
        
        if timed_out:
            return {
                'success': False,
                'job_idx': job_idx,
                'drugbank_id': drugbank_id,
                'uniprot_id': uniprot_id,
                'gene_name': gene_name,
                'pocket_pdb': pocket_pdb,
                'current_outfolder': current_outfolder,
                'action': 'timeout',
                'message': f'Smina docking timed out after {timeout_seconds} seconds ({timeout_seconds/60:.1f} minutes)',
                'process_id': process_id
            }
        
        if returncode == 0:
            action_type = 'updated' if UPDATE_SMINA_ONLY else 'completed'
            return {
                'success': True,
                'job_idx': job_idx,
                'drugbank_id': drugbank_id,
                'uniprot_id': uniprot_id,
                'gene_name': gene_name,
                'pocket_pdb': pocket_pdb,
                'current_outfolder': current_outfolder,
                'action': action_type,
                'message': f'Successfully {action_type} smina docking for {drugbank_id} into {pocket_pdb}',
                'process_id': process_id
            }
        else:
            return {
                'success': False,
                'job_idx': job_idx,
                'drugbank_id': drugbank_id,
                'uniprot_id': uniprot_id,
                'gene_name': gene_name,
                'pocket_pdb': pocket_pdb,
                'current_outfolder': current_outfolder,
                'action': 'failed',
                'message': f'Smina docking failed. Return code: {returncode}',
                'stdout': stdout,
                'stderr': stderr,
                'process_id': process_id
            }
    
    except Exception as e:
        return {
            'success': False,
            'job_idx': job_idx,
            'drugbank_id': drugbank_id,
            'uniprot_id': uniprot_id,
            'gene_name': gene_name,
            'pocket_pdb': pocket_pdb,
            'current_outfolder': current_outfolder,
            'action': 'error',
            'message': f'Exception occurred in smina docking: {str(e)}',
            'process_id': process_id
        }

def run_single_gold_job(job_data):
    """
    Run a single gold docking job - Stage 2 of three-stage docking.
    
    Parameters
    ----------
    job_data : dict
        Dictionary containing all job parameters
        
    Returns
    -------
    dict
        Results of the gold docking job
    """
    # Extract job parameters
    job_idx = job_data['job_idx']
    drugbank_id = job_data['drugbank_id']
    uniprot_id = job_data['uniprot_id']
    gene_name = job_data['gene_name']
    ligand_sdf = job_data['ligand_sdf']
    receptor_pdb = job_data['receptor_pdb']
    receptor_pdbqt = job_data['receptor_pdbqt']
    pocket_pdb = job_data['pocket_pdb']
    current_outfolder = job_data['current_outfolder']
    
    # Get configuration from job_data
    CONSENSUS_DOCKER_SCRIPT = job_data['consensus_docker_script']
    GOLD_PATH = job_data['gold_path']
    NUM_THREADS = job_data['num_threads']
    CUTOFF_VALUE = job_data['cutoff_value']
    EXHAUSTIVENESS = job_data.get('exhaustiveness', 8)  # Default to 8 if not set
    
    process_id = os.getpid()
    
    try:
        # Check if gold output already exists
        if check_tool_completion(current_outfolder, 'gold'):
            return {
                'success': True,
                'job_idx': job_idx,
                'drugbank_id': drugbank_id,
                'uniprot_id': uniprot_id,
                'gene_name': gene_name,
                'pocket_pdb': pocket_pdb,
                'current_outfolder': current_outfolder,
                'action': 'skipped',
                'message': 'Gold job already completed with valid output',
                'process_id': process_id
            }
        
        # Build the gold-only command
        command = [
            "python", CONSENSUS_DOCKER_SCRIPT,
            "--use_gold",
            "--overwrite",  # Allow writing to existing directory
            "--outfolder", current_outfolder,
            "--gold_path", GOLD_PATH,
            "--ligand_sdf", ligand_sdf,
            "--receptor_pdb", receptor_pdb,
            "--pocket_pdb", pocket_pdb,
            "--num_threads", str(NUM_THREADS),
            "--cutoff_value", str(CUTOFF_VALUE),
            "--exhaustiveness", str(EXHAUSTIVENESS)
        ]
        
        # Skip RMSD calculation if USE_RMSD_CALCULATION is False
        if not job_data.get('use_rmsd_calculation', True):
            command.append("--skip_rmsd")
        
        # Add PDBQT file if available for faster processing
        if receptor_pdbqt and os.path.exists(receptor_pdbqt):
            command.extend(["--receptor_pdbqt", receptor_pdbqt])
        
        # Run the command with timeout
        timeout_seconds = job_data.get('timeout', 600)  # Default 10 minutes
        success, returncode, stdout, stderr, timed_out = run_command_with_timeout(
            command, timeout_seconds
        )
        
        if timed_out:
            return {
                'success': False,
                'job_idx': job_idx,
                'drugbank_id': drugbank_id,
                'uniprot_id': uniprot_id,
                'gene_name': gene_name,
                'pocket_pdb': pocket_pdb,
                'current_outfolder': current_outfolder,
                'action': 'timeout',
                'message': f'Gold docking timed out after {timeout_seconds} seconds ({timeout_seconds/60:.1f} minutes)',
                'process_id': process_id
            }
        
        if returncode == 0:
            return {
                'success': True,
                'job_idx': job_idx,
                'drugbank_id': drugbank_id,
                'uniprot_id': uniprot_id,
                'gene_name': gene_name,
                'pocket_pdb': pocket_pdb,
                'current_outfolder': current_outfolder,
                'action': 'completed',
                'message': f'Successfully completed gold docking for {drugbank_id} into {pocket_pdb}',
                'process_id': process_id
            }
        else:
            return {
                'success': False,
                'job_idx': job_idx,
                'drugbank_id': drugbank_id,
                'uniprot_id': uniprot_id,
                'gene_name': gene_name,
                'pocket_pdb': pocket_pdb,
                'current_outfolder': current_outfolder,
                'action': 'failed',
                'message': f'Gold docking failed. Return code: {returncode}',
                'stdout': stdout,
                'stderr': stderr,
                'process_id': process_id
            }
    
    except Exception as e:
        return {
            'success': False,
            'job_idx': job_idx,
            'drugbank_id': drugbank_id,
            'uniprot_id': uniprot_id,
            'gene_name': gene_name,
            'pocket_pdb': pocket_pdb,
            'current_outfolder': current_outfolder,
            'action': 'error',
            'message': f'Exception occurred in gold docking: {str(e)}',
            'process_id': process_id
        }

def run_single_ledock_job(job_data):
    """
    Run a single ledock docking job - Stage 3 of three-stage docking.
    
    Parameters
    ----------
    job_data : dict
        Dictionary containing all job parameters
        
    Returns
    -------
    dict
        Results of the ledock docking job
    """
    # Extract job parameters
    job_idx = job_data['job_idx']
    drugbank_id = job_data['drugbank_id']
    uniprot_id = job_data['uniprot_id']
    gene_name = job_data['gene_name']
    ligand_sdf = job_data['ligand_sdf']
    receptor_pdb = job_data['receptor_pdb']
    receptor_pdbqt = job_data['receptor_pdbqt']
    pocket_pdb = job_data['pocket_pdb']
    current_outfolder = job_data['current_outfolder']
    
    # Get configuration from job_data
    CONSENSUS_DOCKER_SCRIPT = job_data['consensus_docker_script']
    LEDOCK_PATH = job_data['ledock_path']
    LEPRO_PATH = job_data['lepro_path']
    NUM_THREADS = job_data['num_threads']
    CUTOFF_VALUE = job_data['cutoff_value']
    EXHAUSTIVENESS = job_data.get('exhaustiveness', 8)  # Default to 8 if not set
    
    process_id = os.getpid()
    
    try:
        # Check if ledock output already exists
        if check_tool_completion(current_outfolder, 'ledock'):
            return {
                'success': True,
                'job_idx': job_idx,
                'drugbank_id': drugbank_id,
                'uniprot_id': uniprot_id,
                'gene_name': gene_name,
                'pocket_pdb': pocket_pdb,
                'current_outfolder': current_outfolder,
                'action': 'skipped',
                'message': 'LeDock job already completed with valid output',
                'process_id': process_id
            }
        
        # Build the ledock-only command
        command = [
            "python", CONSENSUS_DOCKER_SCRIPT,
            "--use_ledock",
            "--overwrite",  # Allow writing to existing directory
            "--outfolder", current_outfolder,
            "--ledock_path", LEDOCK_PATH,
            "--lepro_path", LEPRO_PATH,
            "--ligand_sdf", ligand_sdf,
            "--receptor_pdb", receptor_pdb,
            "--pocket_pdb", pocket_pdb,
            "--num_threads", str(NUM_THREADS),
            "--cutoff_value", str(CUTOFF_VALUE),
            "--exhaustiveness", str(EXHAUSTIVENESS)
        ]
        
        # Skip RMSD calculation if USE_RMSD_CALCULATION is False
        if not job_data.get('use_rmsd_calculation', True):
            command.append("--skip_rmsd")
        
        # Add PDBQT file if available for faster processing
        if receptor_pdbqt and os.path.exists(receptor_pdbqt):
            command.extend(["--receptor_pdbqt", receptor_pdbqt])
        
        # Run the command with timeout
        timeout_seconds = job_data.get('timeout', 600)  # Default 10 minutes
        success, returncode, stdout, stderr, timed_out = run_command_with_timeout(
            command, timeout_seconds
        )
        
        if timed_out:
            return {
                'success': False,
                'job_idx': job_idx,
                'drugbank_id': drugbank_id,
                'uniprot_id': uniprot_id,
                'gene_name': gene_name,
                'pocket_pdb': pocket_pdb,
                'current_outfolder': current_outfolder,
                'action': 'timeout',
                'message': f'LeDock docking timed out after {timeout_seconds} seconds ({timeout_seconds/60:.1f} minutes)',
                'process_id': process_id
            }
        
        if returncode == 0:
            return {
                'success': True,
                'job_idx': job_idx,
                'drugbank_id': drugbank_id,
                'uniprot_id': uniprot_id,
                'gene_name': gene_name,
                'pocket_pdb': pocket_pdb,
                'current_outfolder': current_outfolder,
                'action': 'completed',
                'message': f'Successfully completed ledock docking for {drugbank_id} into {pocket_pdb}',
                'process_id': process_id
            }
        else:
            return {
                'success': False,
                'job_idx': job_idx,
                'drugbank_id': drugbank_id,
                'uniprot_id': uniprot_id,
                'gene_name': gene_name,
                'pocket_pdb': pocket_pdb,
                'current_outfolder': current_outfolder,
                'action': 'failed',
                'message': f'LeDock docking failed. Return code: {returncode}',
                'stdout': stdout,
                'stderr': stderr,
                'process_id': process_id
            }
    
    except Exception as e:
        return {
            'success': False,
            'job_idx': job_idx,
            'drugbank_id': drugbank_id,
            'uniprot_id': uniprot_id,
            'gene_name': gene_name,
            'pocket_pdb': pocket_pdb,
            'current_outfolder': current_outfolder,
            'action': 'error',
            'message': f'Exception occurred in ledock docking: {str(e)}',
            'process_id': process_id
        }

def run_single_rmsd_job(job_data):
    """
    Run RMSD calculation for a job where all tools completed but final results are missing.
    
    Parameters
    ----------
    job_data : dict
        Dictionary containing all job parameters
        
    Returns
    -------
    dict
        Results of the RMSD calculation
    """
    # Extract job parameters
    job_idx = job_data['job_idx']
    drugbank_id = job_data['drugbank_id']
    uniprot_id = job_data['uniprot_id']
    gene_name = job_data['gene_name']
    ligand_sdf = job_data['ligand_sdf']
    receptor_pdb = job_data['receptor_pdb']
    receptor_pdbqt = job_data['receptor_pdbqt']
    pocket_pdb = job_data['pocket_pdb']
    current_outfolder = job_data['current_outfolder']
    
    # Get configuration from job_data
    CONSENSUS_DOCKER_SCRIPT = job_data['consensus_docker_script']
    NUM_THREADS = job_data['num_threads']
    CUTOFF_VALUE = job_data['cutoff_value']
    FORCE_RMSD_RECALCULATION = job_data.get('force_rmsd_recalculation', False)
    
    process_id = os.getpid()
    
    try:
        # If FORCE_RMSD_RECALCULATION is True, remove existing final results
        if FORCE_RMSD_RECALCULATION:
            final_results_file = os.path.join(current_outfolder, 'final_results.csv')
            if os.path.exists(final_results_file):
                os.remove(final_results_file)
                logging.debug(f"Removed final results file for recalculation: {final_results_file}")
                os.remove(final_results_file)
                logging.debug(f"Job {job_idx}: Removed existing final results for forced recalculation")
        
        # Check if final results already exist (after potential removal)
        if check_final_results_completion(current_outfolder) and not FORCE_RMSD_RECALCULATION:
            return {
                'success': True,
                'job_idx': job_idx,
                'drugbank_id': drugbank_id,
                'uniprot_id': uniprot_id,
                'gene_name': gene_name,
                'pocket_pdb': pocket_pdb,
                'current_outfolder': current_outfolder,
                'action': 'skipped',
                'message': 'Final results already completed with valid RMSD data',
                'process_id': process_id
            }
        
        # Build the RMSD calculation command (run with minimal docking tools to trigger RMSD calculation)
        # Since there's no --skip_docking flag, we'll run with minimal setup to just calculate RMSD
        command = [
            "python", CONSENSUS_DOCKER_SCRIPT,
            "--overwrite",  # Allow writing to existing directory
            "--outfolder", current_outfolder,
            "--ligand_sdf", ligand_sdf,
            "--receptor_pdb", receptor_pdb,
            "--pocket_pdb", pocket_pdb,
            "--num_threads", str(NUM_THREADS),
            "--cutoff_value", str(CUTOFF_VALUE)
            # Note: No docking tool flags specified, so it should only do RMSD calculation
        ]
        
        # Add PDBQT file if available
        if receptor_pdbqt and os.path.exists(receptor_pdbqt):
            command.extend(["--receptor_pdbqt", receptor_pdbqt])
        
        # Run the command with timeout
        timeout_seconds = job_data.get('timeout', 300)  # Default 5 minutes
        success, returncode, stdout, stderr, timed_out = run_command_with_timeout(
            command, timeout_seconds
        )
        
        if timed_out:
            return {
                'success': False,
                'job_idx': job_idx,
                'drugbank_id': drugbank_id,
                'uniprot_id': uniprot_id,
                'gene_name': gene_name,
                'pocket_pdb': pocket_pdb,
                'current_outfolder': current_outfolder,
                'action': 'timeout',
                'message': f'RMSD calculation timed out after {timeout_seconds} seconds ({timeout_seconds/60:.1f} minutes)',
                'process_id': process_id
            }
        
        if returncode == 0:
            action_type = 'recalculated' if FORCE_RMSD_RECALCULATION else 'completed'
            return {
                'success': True,
                'job_idx': job_idx,
                'drugbank_id': drugbank_id,
                'uniprot_id': uniprot_id,
                'gene_name': gene_name,
                'pocket_pdb': pocket_pdb,
                'current_outfolder': current_outfolder,
                'action': action_type,
                'message': f'Successfully {action_type} RMSD calculation for {drugbank_id} into {pocket_pdb}',
                'process_id': process_id
            }
        else:
            return {
                'success': False,
                'job_idx': job_idx,
                'drugbank_id': drugbank_id,
                'uniprot_id': uniprot_id,
                'gene_name': gene_name,
                'pocket_pdb': pocket_pdb,
                'current_outfolder': current_outfolder,
                'action': 'failed',
                'message': f'RMSD calculation failed. Return code: {returncode}',
                'stdout': stdout,
                'stderr': stderr,
                'process_id': process_id
            }
    
    except Exception as e:
        return {
            'success': False,
            'job_idx': job_idx,
            'drugbank_id': drugbank_id,
            'uniprot_id': uniprot_id,
            'gene_name': gene_name,
            'pocket_pdb': pocket_pdb,
            'current_outfolder': current_outfolder,
            'action': 'error',
            'message': f'Exception occurred in RMSD calculation: {str(e)}',
            'process_id': process_id
        }

# --- Part 3: Main Docking Execution Logic ---

def run_stage_jobs(job_data_list, stage_name, job_function, max_workers, timeout, exhaustiveness=None):
    """
    Run a stage of docking jobs in parallel.
    
    Parameters
    ----------
    job_data_list : list
        List of job data dictionaries
    stage_name : str
        Name of the stage (for logging)
    job_function : callable
        Function to run each job
    max_workers : int
        Maximum number of parallel workers
    timeout : int
        Timeout for each job in seconds
    exhaustiveness : int, optional
        Exhaustiveness parameter for the docking tool
        
    Returns
    -------
    dict
        Statistics about the stage execution
    """
    logging.info(f"\n=== {stage_name.upper()} ===")
    logging.info(f"Starting {stage_name} with {max_workers} processes...")
    logging.info(f"Timeout per job: {timeout/60:.1f} minutes")
    if exhaustiveness is not None:
        logging.info(f"Exhaustiveness: {exhaustiveness}")
    
    stage_start_time = time.time()
    completed_jobs = 0
    failed_jobs = 0
    timeout_jobs = 0
    skipped_jobs = 0
    unique_processes = set()
    last_progress_log = time.time()
    progress_log_interval = 30  # Log progress every 30 seconds
    
    # Update job data with correct timeout and exhaustiveness
    stage_job_data_list = []
    for job_data in job_data_list:
        stage_job_data = job_data.copy()
        stage_job_data['timeout'] = timeout
        if exhaustiveness is not None:
            stage_job_data['exhaustiveness'] = exhaustiveness
            logging.debug(f"Setting exhaustiveness to {exhaustiveness} for job {stage_job_data.get('job_idx', 'unknown')}")
        else:
            logging.debug(f"No exhaustiveness set for job {stage_job_data.get('job_idx', 'unknown')}")
        stage_job_data_list.append(stage_job_data)
    
    with ProcessPoolExecutor(max_workers=max_workers) as executor:
        # Submit all jobs
        future_to_job = {executor.submit(job_function, job_data): job_data for job_data in stage_job_data_list}
        
        # Process results with progress bar
        completed_futures = 0
        for future in tqdm(as_completed(future_to_job), total=len(stage_job_data_list), 
                         desc=f"{stage_name}", unit="job"):
            try:
                result = future.result()
                completed_futures += 1
                
                # Track unique processes
                if 'process_id' in result:
                    unique_processes.add(result['process_id'])
                
                if result['success']:
                    if result['action'] == 'completed':
                        completed_jobs += 1
                        logging.info(f"{stage_name} Job {result['job_idx']+1}: {result['message']} (Process: {result['process_id']})")
                    elif result['action'] == 'skipped':
                        skipped_jobs += 1
                        # Log skipped jobs at INFO level to ensure they're visible
                        logging.info(f"{stage_name} Job {result['job_idx']+1}: SKIPPED - {result['message']} (Process: {result['process_id']})")
                        # Check output folder structure and verify the results file does exist
                        output_folder = result.get('current_outfolder', 'unknown')
                        if 'current_outfolder' in result:
                            tool_result_file = os.path.join(output_folder, stage_name.split(':')[-1].strip().lower(), "results.csv")
                            logging.info(f"Verified skipping - Results file exists: {os.path.exists(tool_result_file)}")
                else:
                    if result['action'] == 'timeout':
                        timeout_jobs += 1
                        logging.warning(f"{stage_name} Job {result['job_idx']+1}: {result['message']} (Process: {result['process_id']})")
                    else:
                        failed_jobs += 1
                        logging.error(f"{stage_name} Job {result['job_idx']+1}: {result['message']} (Process: {result['process_id']})")
                        if 'stdout' in result and result['stdout']:
                            logging.error(f"STDOUT: {result['stdout']}")
                        if 'stderr' in result and result['stderr']:
                            logging.error(f"STDERR: {result['stderr']}")
                
                # Log progress periodically
                current_time = time.time()
                if current_time - last_progress_log >= progress_log_interval:
                    percent_complete = (completed_futures / len(stage_job_data_list)) * 100
                    elapsed_time = current_time - stage_start_time
                    avg_time_per_job = elapsed_time / completed_futures if completed_futures > 0 else 0
                    remaining_jobs = len(stage_job_data_list) - completed_futures
                    estimated_time_remaining = remaining_jobs * avg_time_per_job
                    
                    # Format elapsed time and ETA
                    def format_time(seconds):
                        if seconds < 60:
                            return f"{seconds:.0f}s"
                        elif seconds < 3600:
                            return f"{seconds/60:.1f}m"
                        else:
                            return f"{seconds/3600:.1f}h"
                    
                    elapsed_str = format_time(elapsed_time)
                    eta_str = format_time(estimated_time_remaining) if estimated_time_remaining > 0 else "N/A"
                    
                    logging.info(f"{stage_name.upper()} PROGRESS: {percent_complete:.1f}% complete "
                               f"({completed_futures}/{len(stage_job_data_list)} jobs processed) | "
                               f"✓{completed_jobs} completed, ✗{failed_jobs} failed, ⏱{timeout_jobs} timeout, ◊{skipped_jobs} skipped | "
                               f"Elapsed: {elapsed_str}, ETA: {eta_str}")
                    last_progress_log = current_time
                        
            except Exception as e:
                failed_jobs += 1
                completed_futures += 1
                job_data = future_to_job[future]
                logging.error(f"Exception in {stage_name} job {job_data['job_idx']+1}: {e}")
    
    # Stage summary
    stage_elapsed_time = time.time() - stage_start_time
    logging.info(f"\n=== {stage_name.upper()} COMPLETED ===")
    logging.info(f"{stage_name} jobs completed successfully: {completed_jobs}")
    logging.info(f"{stage_name} jobs skipped (already completed): {skipped_jobs}")
    logging.info(f"{stage_name} jobs failed: {failed_jobs}")
    logging.info(f"{stage_name} jobs timed out: {timeout_jobs}")
    logging.info(f"{stage_name} execution time: {stage_elapsed_time:.2f} seconds")
    logging.info(f"Used {len(unique_processes)} unique processes out of {max_workers} configured")
    
    return {
        'completed': completed_jobs,
        'skipped': skipped_jobs,
        'failed': failed_jobs,
        'timeout': timeout_jobs,
        'elapsed_time': stage_elapsed_time,
        'unique_processes': len(unique_processes)
    }

def run_docking(
    drug_to_protein_df, 
    uniprot_map_df, 
    pdb_info_dict, 
    processed_ligand_sdf_folder,
    output_base_folder="/media/onur/Elements/cavity_space_consensus_docking/2025_06_29_batch_dock/consensus_docking_results"
):
    """
    Iterates through drug-protein pairs, constructs commands, and runs three-stage docking.
    """
    logging.info("Starting three-stage docking execution.")
    logging.info(f"Using output base folder: {output_base_folder}")
    
    # Check if output folder exists
    if not os.path.exists(output_base_folder):
        logging.warning(f"Output base folder does not exist: {output_base_folder}")
        logging.info(f"Creating output base folder: {output_base_folder}")
    elif os.path.isdir(output_base_folder):
        # List a few example folders to verify correct path
        try:
            example_folders = os.listdir(output_base_folder)[:5]
            logging.info(f"Found {len(os.listdir(output_base_folder))} items in output folder")
            if example_folders:
                logging.info(f"Example output folders: {example_folders}")
        except Exception as e:
            logging.warning(f"Error examining output folder: {e}")
    
    total_docking_jobs = 0
    executed_docking_jobs = 0
    skipped_jobs = 0
    
    os.makedirs(output_base_folder, exist_ok=True)

    # Pre-build mappings for faster lookup
    uniprot_gene_map = dict(zip(uniprot_map_df['Mapped_Gene_Name'], uniprot_map_df['Entry']))
    
    # Debug: Show some sample mappings
    logging.info(f"UniProt-Gene mapping contains {len(uniprot_gene_map)} entries")
    sample_gene_names = list(uniprot_gene_map.keys())[:5]
    logging.info(f"Sample gene names in UniProt mapping: {sample_gene_names}")
    sample_uniprot_ids = [uniprot_gene_map[gene] for gene in sample_gene_names]
    logging.info(f"Corresponding UniProt IDs: {sample_uniprot_ids}")

    docking_jobs = [] # List to store job dictionaries

    logging.info("Preparing list of docking jobs...")
    for index, row in tqdm(drug_to_protein_df.iterrows(), total=len(drug_to_protein_df), desc="Preparing Jobs"):
        drugbank_id = row['node_1']
        gene_name = row['node_2_name']
        
        ligand_sdf_path = os.path.join(processed_ligand_sdf_folder, f"{drugbank_id}.sdf")
        if not os.path.exists(ligand_sdf_path):
            tqdm.write(f"Warning: Ligand SDF '{ligand_sdf_path}' not found. Skipping {drugbank_id}-{gene_name} pair.")
            skipped_jobs += 1
            continue

        uniprot_id = uniprot_gene_map.get(gene_name)
        if not uniprot_id:
            tqdm.write(f"Warning: UniProt ID not found for gene '{gene_name}'. Skipping {drugbank_id}-{gene_name} pair.")
            skipped_jobs += 1
            continue
        
        if uniprot_id not in pdb_info_dict:
            logging.debug(f"UniProt ID '{uniprot_id}' not found in cavity mapping. Gene: '{gene_name}', DrugBank: '{drugbank_id}'")
            tqdm.write(f"Warning: No PDB information found for UniProt ID '{uniprot_id}'. Skipping {drugbank_id}-{gene_name} pair.")
            skipped_jobs += 1
            continue

        # Each UniProt ID can have multiple pocket/receptor pairs
        for receptor_pdb, pocket_pdb, receptor_pdbqt in pdb_info_dict[uniprot_id]:
            # Create unique job identifier
            pocket_filename = Path(pocket_pdb).stem
            cavity_match = re.search(r'_cavity_(\d+)', pocket_filename)
            cavity_num = cavity_match.group(1) if cavity_match else "unknown"
            job_signature = f"{drugbank_id}_{uniprot_id}_{cavity_num}"
            
            total_docking_jobs += 1
            docking_jobs.append({
                'drugbank_id': drugbank_id,
                'uniprot_id': uniprot_id,
                'gene_name': gene_name,
                'ligand_sdf': ligand_sdf_path,
                'receptor_pdb': receptor_pdb,
                'receptor_pdbqt': receptor_pdbqt,  # May be None if not available
                'pocket_pdb': pocket_pdb,
                'job_signature': job_signature  # For duplicate detection
            })
    
    logging.info(f"Total potential docking jobs: {total_docking_jobs}")
    logging.info(f"Skipped {skipped_jobs} jobs due to missing files or mappings.")
    
    # Remove duplicate jobs
    docking_jobs = remove_duplicate_jobs(docking_jobs)
    
    # Save job preparation summary
    save_job_preparation_summary(total_docking_jobs, skipped_jobs, len(docking_jobs))
    
    # Preview jobs before execution
    if docking_jobs:
        preview_df = preview_docking_jobs(docking_jobs, "docking_jobs_preview.csv")
        
        # Ask user for confirmation before proceeding
        print(f"\n{'='*60}")
        print(f"DOCKING JOBS PREVIEW")
        print(f"{'='*60}")
        print(f"Total jobs to execute: {len(docking_jobs)}")
        print(f"Preview saved to: docking_jobs_preview.csv")
        print(f"{'='*60}")
        
        if not TEST_MODE and not SKIP_CONFIRMATION:
            response = input("Do you want to proceed with these docking jobs? (y/n): ").lower().strip()
            if response not in ['y', 'yes']:
                logging.info("User chose not to proceed. Exiting.")
                sys.exit(0)
        elif TEST_MODE:
            logging.info("TEST MODE: Proceeding automatically")
        elif SKIP_CONFIRMATION:
            logging.info("SKIP_CONFIRMATION enabled: Proceeding automatically with all jobs")
    
    # Limit jobs for testing if TEST_MODE is enabled
    if TEST_MODE and len(docking_jobs) > MAX_TEST_JOBS:
        logging.info(f"TEST MODE: Limiting to first {MAX_TEST_JOBS} jobs out of {len(docking_jobs)} available jobs.")
        docking_jobs = docking_jobs[:MAX_TEST_JOBS]
        # Update preview with limited jobs
        if docking_jobs:
            preview_df = preview_docking_jobs(docking_jobs, "docking_jobs_preview_test_mode.csv")

    # Prepare job data for three-stage multiprocessing
    logging.info(f"Preparing {len(docking_jobs)} jobs for three-stage parallel execution...")
    
    # Log which tools are enabled/disabled
    logging.info("=== DOCKING TOOLS CONFIGURATION ===")
    logging.info(f"Stage 1 - Smina: {'ENABLED' if USE_SMINA else 'DISABLED'}")
    if USE_SMINA:
        logging.info(f"  - Max parallel jobs: {SMINA_MAX_PARALLEL_JOBS}")
        if USE_ADAPTIVE_EXHAUSTIVENESS:
            logging.info(f"  - Exhaustiveness: ADAPTIVE (convergence-based)")
        else:
            logging.info(f"  - Exhaustiveness: {SMINA_EXHAUSTIVENESS} (fixed)")
        logging.info(f"  - Timeout: {SMINA_TIMEOUT/60:.1f} minutes")
        if UPDATE_SMINA_ONLY:
            logging.info(f"  - Mode: UPDATE EXISTING (preserve Gold/LeDock results)")
        else:
            logging.info(f"  - Mode: NORMAL")
    
    logging.info(f"Stage 2 - Gold: {'ENABLED' if USE_GOLD else 'DISABLED'}")
    if USE_GOLD:
        logging.info(f"  - Max parallel jobs: {GOLD_MAX_PARALLEL_JOBS}")
        logging.info(f"  - Exhaustiveness: {GOLD_EXHAUSTIVENESS}")
        logging.info(f"  - Timeout: {GOLD_TIMEOUT/60:.1f} minutes")
    
    logging.info(f"Stage 3 - LeDock: {'ENABLED' if USE_LEDOCK else 'DISABLED'}")
    if USE_LEDOCK:
        logging.info(f"  - Max parallel jobs: {LEDOCK_MAX_PARALLEL_JOBS}")
        logging.info(f"  - Exhaustiveness: {LEDOCK_EXHAUSTIVENESS}")
        logging.info(f"  - Timeout: {LEDOCK_TIMEOUT/60:.1f} minutes")
    
    logging.info(f"Stage 4 - RMSD Calculation: {'ENABLED' if USE_RMSD_CALCULATION else 'DISABLED'}")
    if USE_RMSD_CALCULATION:
        logging.info(f"  - Max parallel jobs: {RMSD_MAX_PARALLEL_JOBS}")
        logging.info(f"  - Timeout: {RMSD_TIMEOUT/60:.1f} minutes")
        if FORCE_RMSD_RECALCULATION:
            logging.info(f"  - Mode: FORCE RECALCULATION")
        else:
            logging.info(f"  - Mode: NORMAL")
    
    logging.info("=" * 40)
    
    job_data_list = []
    
    for job_idx, job in enumerate(docking_jobs):
        drugbank_id = job['drugbank_id']
        uniprot_id = job['uniprot_id']
        gene_name = job['gene_name']
        ligand_sdf = job['ligand_sdf']
        receptor_pdb = job['receptor_pdb']
        receptor_pdbqt = job['receptor_pdbqt']  # May be None
        pocket_pdb = job['pocket_pdb']

        # Determine output folder name for this specific job
        pocket_filename = Path(pocket_pdb).stem
        # Extract cavity number using regex
        cavity_match = re.search(r'_cavity_(\d+)', pocket_filename)
        cavity_num = cavity_match.group(1) if cavity_match else "unknown"
        
        # Create a cleaner suffix
        pocket_suffix = re.sub(r'AF-[A-Z0-9]+(?:-F1-model_v1_)?', '', pocket_filename)
        if len(pocket_suffix) > 50:  # Arbitrary length limit
            pocket_suffix = f"cavity_{cavity_num}"
        
        output_folder_name = f"{drugbank_id}_{gene_name}_{uniprot_id}_{pocket_suffix}"
        current_outfolder = os.path.join(output_base_folder, output_folder_name)
        
        # Ensure we have absolute paths for all directory operations
        current_outfolder = os.path.abspath(current_outfolder)
        
        # Debug output to verify directory structure before starting jobs
        if job_idx < 3:  # Only show for first few jobs to avoid log spam
            logging.info(f"Job {job_idx}: Output folder path: {current_outfolder}")
            # Check if any tool already has results
            if os.path.exists(current_outfolder):
                status = get_job_completion_status(current_outfolder)
                logging.info(f"Job {job_idx}: Current status - smina: {status['smina']}, gold: {status['gold']}, ledock: {status['ledock']}, final: {status['final_results']}")
        
        # Prepare job data dictionary
        job_data = {
            'job_idx': job_idx,
            'drugbank_id': drugbank_id,
            'uniprot_id': uniprot_id,
            'gene_name': gene_name,
            'ligand_sdf': ligand_sdf,
            'receptor_pdb': receptor_pdb,
            'receptor_pdbqt': receptor_pdbqt,
            'pocket_pdb': pocket_pdb,
            'current_outfolder': current_outfolder,
            'consensus_docker_script': CONSENSUS_DOCKER_SCRIPT,
            'smina_path': SMINA_PATH,
            'ledock_path': LEDOCK_PATH,
            'lepro_path': LEPRO_PATH,
            'gold_path': GOLD_PATH,
            'num_threads': NUM_THREADS,
            'cutoff_value': CUTOFF_VALUE,
            # New adaptive exhaustiveness and update mode parameters
            'use_adaptive_exhaustiveness': USE_ADAPTIVE_EXHAUSTIVENESS,
            'update_smina_only': UPDATE_SMINA_ONLY,
            'force_rmsd_recalculation': FORCE_RMSD_RECALCULATION,
            'use_rmsd_calculation': USE_RMSD_CALCULATION
        }
        job_data_list.append(job_data)
    
    # Start overall timer
    start_time = time.time()
    
    # Initialize stage statistics
    stage1_stats = {'completed': 0, 'skipped': 0, 'failed': 0, 'timeout': 0, 'elapsed_time': 0, 'unique_processes': 0}
    stage2_stats = {'completed': 0, 'skipped': 0, 'failed': 0, 'timeout': 0, 'elapsed_time': 0, 'unique_processes': 0}
    stage3_stats = {'completed': 0, 'skipped': 0, 'failed': 0, 'timeout': 0, 'elapsed_time': 0, 'unique_processes': 0}
    stage4_stats = {'completed': 0, 'skipped': 0, 'failed': 0, 'timeout': 0, 'elapsed_time': 0, 'unique_processes': 0}
    
    # === STAGE 1: RUN SMINA DOCKING ===
    if USE_SMINA:
        logging.info("Stage 1: Smina docking is ENABLED")
        
        # Initialize resource monitor for adaptive execution
        resource_monitor = None
        if ENABLE_DYNAMIC_RESOURCE_MANAGEMENT:
            resource_monitor = ResourceMonitor(
                cpu_threshold=CPU_THRESHOLD,
                memory_threshold=MEMORY_THRESHOLD,
                check_interval=RESOURCE_CHECK_INTERVAL
            )
            logging.info("Dynamic resource management ENABLED for Smina stage")
            logging.info(f"Resource thresholds - CPU: {CPU_THRESHOLD}%, Memory: {MEMORY_THRESHOLD}%")
        else:
            logging.info("Dynamic resource management DISABLED - using fixed parallelism")
        
        # Use adaptive execution for Smina stage
        stage1_stats = run_stage_jobs_adaptive(
            stage_name="Stage 1: Smina Docking", 
            jobs=job_data_list,
            job_function=run_single_smina_job,
            resource_monitor=resource_monitor
        )
    else:
        logging.info("Stage 1: Smina docking is DISABLED - skipping")
    
    # === STAGE 2: RUN GOLD DOCKING ===
    if USE_GOLD:
        logging.info("Stage 2: Gold docking is ENABLED")
        stage2_stats = run_stage_jobs(
            job_data_list=job_data_list, 
            stage_name="Stage 2: Gold Docking", 
            job_function=run_single_gold_job,
            max_workers=GOLD_MAX_PARALLEL_JOBS,
            timeout=GOLD_TIMEOUT,
            exhaustiveness=GOLD_EXHAUSTIVENESS
        )
    else:
        logging.info("Stage 2: Gold docking is DISABLED - skipping")
    
    # === STAGE 3: RUN LEDOCK DOCKING ===
    if USE_LEDOCK:
        logging.info("Stage 3: LeDock docking is ENABLED")
        stage3_stats = run_stage_jobs(
            job_data_list=job_data_list, 
            stage_name="Stage 3: LeDock Docking", 
            job_function=run_single_ledock_job,
            max_workers=LEDOCK_MAX_PARALLEL_JOBS,
            timeout=LEDOCK_TIMEOUT,
            exhaustiveness=LEDOCK_EXHAUSTIVENESS
        )
    else:
        logging.info("Stage 3: LeDock docking is DISABLED - skipping")
    
    # === STAGE 4: RUN RMSD CALCULATION FOR INCOMPLETE JOBS ===
    if USE_RMSD_CALCULATION:
        logging.info("Stage 4: RMSD calculation is ENABLED")
        # Filter jobs that need RMSD calculation
        # Only require enabled tools to be complete for RMSD calculation
        rmsd_jobs = []
        for job_data in job_data_list:
            status = get_job_completion_status(job_data['current_outfolder'])
            
            # Check if all enabled tools are complete
            tools_complete = True
            if USE_SMINA and not status['smina']:
                tools_complete = False
            if USE_GOLD and not status['gold']:
                tools_complete = False
            if USE_LEDOCK and not status['ledock']:
                tools_complete = False
            
            # Only add to RMSD jobs if all enabled tools are complete but final results don't exist
            if tools_complete and not status['final_results']:
                rmsd_jobs.append(job_data)
        
        if rmsd_jobs:
            logging.info(f"Found {len(rmsd_jobs)} jobs needing RMSD calculation")
            stage4_stats = run_stage_jobs(
                job_data_list=rmsd_jobs, 
                stage_name="Stage 4: RMSD Calculation", 
                job_function=run_single_rmsd_job,
                max_workers=RMSD_MAX_PARALLEL_JOBS,
                timeout=RMSD_TIMEOUT
            )
        else:
            logging.info("No jobs need RMSD calculation - all are either incomplete or already have final results")
    else:
        logging.info("Stage 4: RMSD calculation is DISABLED - skipping")
    
    # Calculate final statistics
    total_elapsed_time = time.time() - start_time
    
    # Final summary
    logging.info(f"\n=== FINAL THREE-STAGE DOCKING SUMMARY ===")
    if TEST_MODE:
        logging.info(f"*** TEST MODE COMPLETED - RAN {min(len(docking_jobs), MAX_TEST_JOBS)} OUT OF {total_docking_jobs} POTENTIAL JOBS ***")
    
    logging.info(f"Total potential docking jobs (before checking existence): {total_docking_jobs}")
    logging.info(f"Total jobs attempted: {len(docking_jobs)}")
    logging.info(f"Total jobs skipped initially (missing ligand/uniprot/pdb info): {skipped_jobs}")
    
    # Show results only for enabled tools
    if USE_SMINA:
        logging.info(f"=== STAGE 1 (SMINA) RESULTS ===")
        logging.info(f"Smina jobs completed successfully: {stage1_stats['completed']}")
        logging.info(f"Smina jobs skipped (already completed): {stage1_stats['skipped']}")
        logging.info(f"Smina jobs failed: {stage1_stats['failed']}")
        logging.info(f"Smina jobs timed out (>{SMINA_TIMEOUT/60:.1f} minutes): {stage1_stats['timeout']}")
    else:
        logging.info(f"=== STAGE 1 (SMINA) DISABLED ===")
    
    if USE_GOLD:
        logging.info(f"=== STAGE 2 (GOLD) RESULTS ===")
        logging.info(f"Gold jobs completed successfully: {stage2_stats['completed']}")
        logging.info(f"Gold jobs skipped (already completed): {stage2_stats['skipped']}")
        logging.info(f"Gold jobs failed: {stage2_stats['failed']}")
        logging.info(f"Gold jobs timed out (>{GOLD_TIMEOUT/60:.1f} minutes): {stage2_stats['timeout']}")
    else:
        logging.info(f"=== STAGE 2 (GOLD) DISABLED ===")
    
    if USE_LEDOCK:
        logging.info(f"=== STAGE 3 (LEDOCK) RESULTS ===")
        logging.info(f"LeDock jobs completed successfully: {stage3_stats['completed']}")
        logging.info(f"LeDock jobs skipped (already completed): {stage3_stats['skipped']}")
        logging.info(f"LeDock jobs failed: {stage3_stats['failed']}")
        logging.info(f"LeDock jobs timed out (>{LEDOCK_TIMEOUT/60:.1f} minutes): {stage3_stats['timeout']}")
    else:
        logging.info(f"=== STAGE 3 (LEDOCK) DISABLED ===")
    
    if USE_RMSD_CALCULATION:
        logging.info(f"=== STAGE 4 (RMSD) RESULTS ===")
        logging.info(f"RMSD jobs completed successfully: {stage4_stats['completed']}")
        logging.info(f"RMSD jobs skipped (already completed): {stage4_stats['skipped']}")
        logging.info(f"RMSD jobs failed: {stage4_stats['failed']}")
        logging.info(f"RMSD jobs timed out (>{RMSD_TIMEOUT/60:.1f} minutes): {stage4_stats['timeout']}")
    else:
        logging.info(f"=== STAGE 4 (RMSD) DISABLED ===")
    
    logging.info(f"=== OVERALL TIMING ===")
    if USE_SMINA:
        logging.info(f"Stage 1 execution time: {stage1_stats['elapsed_time']:.2f} seconds")
    if USE_GOLD:
        logging.info(f"Stage 2 execution time: {stage2_stats['elapsed_time']:.2f} seconds")
    if USE_LEDOCK:
        logging.info(f"Stage 3 execution time: {stage3_stats['elapsed_time']:.2f} seconds")
    if USE_RMSD_CALCULATION:
        logging.info(f"Stage 4 execution time: {stage4_stats['elapsed_time']:.2f} seconds")
    logging.info(f"Total execution time: {total_elapsed_time:.2f} seconds")
    logging.info(f"Average time per job: {total_elapsed_time/len(docking_jobs):.2f} seconds")
    logging.info(f"Three-stage docking workflow finished.")

def preview_docking_jobs(docking_jobs, preview_file="docking_jobs_preview.csv"):
    """
    Create a preview of all docking jobs and save to CSV file.
    
    Parameters
    ----------
    docking_jobs : list
        List of docking job dictionaries
    preview_file : str
        Path to save the preview CSV file
        
    Returns
    -------
    pd.DataFrame
        DataFrame containing the preview information
    """
    if not docking_jobs:
        logging.warning("No docking jobs to preview")
        return pd.DataFrame()
    
    # Create preview data
    preview_data = []
    for i, job in enumerate(docking_jobs):
        # Extract cavity number from pocket filename
        pocket_filename = Path(job['pocket_pdb']).stem
        cavity_match = re.search(r'_cavity_(\d+)', pocket_filename)
        cavity_num = cavity_match.group(1) if cavity_match else "unknown"
        
        # Check if PDBQT file exists
        pdbqt_exists = job['receptor_pdbqt'] and os.path.exists(job['receptor_pdbqt'])
        
        preview_data.append({
            'Job_Index': i + 1,
            'DrugBank_ID': job['drugbank_id'],
            'Gene_Name': job['gene_name'],
            'UniProt_ID': job['uniprot_id'],
            'Cavity_Number': cavity_num,
            'Job_Signature': job['job_signature'],
            'Ligand_SDF': job['ligand_sdf'],
            'Receptor_PDB': job['receptor_pdb'],
            'Receptor_PDBQT': job['receptor_pdbqt'] if job['receptor_pdbqt'] else 'N/A',
            'PDBQT_Exists': pdbqt_exists,
            'Pocket_PDB': job['pocket_pdb'],
            'Ligand_Exists': os.path.exists(job['ligand_sdf']),
            'Receptor_Exists': os.path.exists(job['receptor_pdb']),
            'Pocket_Exists': os.path.exists(job['pocket_pdb'])
        })
    
    # Create DataFrame
    preview_df = pd.DataFrame(preview_data)
    
    # Save to CSV
    preview_df.to_csv(preview_file, index=False)
    
    # Print summary statistics
    total_jobs = len(preview_df)
    unique_ligands = preview_df['DrugBank_ID'].nunique()
    unique_proteins = preview_df['UniProt_ID'].nunique()
    unique_cavities = len(preview_df.groupby(['UniProt_ID', 'Cavity_Number']))
    pdbqt_available = preview_df['PDBQT_Exists'].sum()
    
    print(f"\n{'='*60}")
    print(f"DOCKING JOBS PREVIEW SUMMARY")
    print(f"{'='*60}")
    print(f"Total jobs to execute: {total_jobs}")
    print(f"Unique ligands (DrugBank IDs): {unique_ligands}")
    print(f"Unique proteins (UniProt IDs): {unique_proteins}")
    print(f"Unique protein-cavity combinations: {unique_cavities}")
    print(f"Jobs with pre-converted PDBQT files: {pdbqt_available}")
    print(f"Preview saved to: {preview_file}")
    print(f"{'='*60}")
    
    return preview_df

def remove_duplicate_jobs(docking_jobs):
    """
    Remove duplicate docking jobs based on job signature.
    
    Parameters
    ----------
    docking_jobs : list
        List of docking job dictionaries
        
    Returns
    -------
    list
        List of unique docking jobs
    """
    seen_signatures = set()
    unique_jobs = []
    duplicates_removed = 0
    
    for job in docking_jobs:
        signature = job['job_signature']
        if signature not in seen_signatures:
            seen_signatures.add(signature)
            unique_jobs.append(job)
        else:
            duplicates_removed += 1
            logging.debug(f"Removed duplicate job: {signature}")
    
    if duplicates_removed > 0:
        logging.info(f"Removed {duplicates_removed} duplicate jobs")
        logging.info(f"Unique jobs remaining: {len(unique_jobs)}")
    
    return unique_jobs

def save_job_preparation_summary(total_jobs, skipped_jobs, final_jobs):
    """
    Save a summary of job preparation statistics.
    
    Parameters
    ----------
    total_jobs : int
        Total number of potential jobs
    skipped_jobs : int
        Number of jobs skipped due to missing files
    final_jobs : int
        Number of jobs after deduplication
    """
    summary_data = {
        'Metric': [
            'Total potential jobs',
            'Jobs skipped (missing files)',
            'Jobs after deduplication',
            'Duplicates removed'
        ],
        'Count': [
            total_jobs,
            skipped_jobs,
            final_jobs,
            total_jobs - skipped_jobs - final_jobs
        ]
    }
    
    summary_df = pd.DataFrame(summary_data)
    summary_file = "job_preparation_summary.csv"
    summary_df.to_csv(summary_file, index=False)
    
    logging.info(f"Job preparation summary saved to: {summary_file}")

# --- Main Execution Block ---
if __name__ == "__main__":
    # 1. Import necessary modules
    import os
    import sys
    import pandas as pd
    import subprocess
    import re
    import time
    import logging
    import glob
    import multiprocessing
    import signal
    import psutil
    from tqdm import tqdm
    from pathlib import Path
    from concurrent.futures import ProcessPoolExecutor, as_completed
    
    try:
        # Check for psutil availability
        import psutil
        logging.info("psutil module found - using robust process tree termination")
    except ImportError:
        logging.warning("psutil module not found - install with 'pip install psutil' for robust process termination")
        
    # 2. Parse command-line arguments if needed
    # (none for now, using config variables)
    
    # 3. Load necessary data for docking
    try:
        # Load drug-to-protein mapping
        drug_to_protein_df = pd.read_csv(DRUG_TO_PROTEIN_TSV, sep='\t')
        logging.info(f"Loaded drug-to-protein mapping with {len(drug_to_protein_df)} rows")
        
        # Load UniProt mapping
        uniprot_map_df = load_uniprot_mapping(UNIPROT_MAPPING_CSV)
        
        # Load small molecule drugs
        small_molecules = load_small_molecule_drugs()
        
        # Load cavity mapping with PDBQT support
        pdb_info_dict, mapping_source = load_best_mapping_with_pdbqt()
        
        # Filter drug_to_protein_df to include only small molecules
        initial_rows = len(drug_to_protein_df)
        drug_to_protein_df = drug_to_protein_df[drug_to_protein_df['node_1'].isin(small_molecules)]
        logging.info(f"Filtered to {len(drug_to_protein_df)} drug-protein pairs with small molecules (from {initial_rows})")
        
        # Run the main docking workflow
        run_docking(drug_to_protein_df, uniprot_map_df, pdb_info_dict, PROCESSED_LIGAND_SDF_FOLDER)
        
    except Exception as e:
        logging.critical(f"Critical error in main execution: {e}")
        import traceback
        logging.critical(traceback.format_exc())
        sys.exit(1)
        sys.exit(1)